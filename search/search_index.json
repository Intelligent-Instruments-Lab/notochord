{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"notochord","text":""},{"location":"#notochord-paper-video","title":"Notochord (Paper | Video)","text":"<p>Notochord is a neural network model for MIDI performances. This package contains the training and inference model implemented in pytorch, as well as interactive MIDI processing apps using iipyper. </p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Using your python environment manager of choice (i.e. virtualenv, conda), make a new environment with a Python version at least 3.10. Then <code>pip install notochord</code>.</p> <p>For developing <code>notochord</code>, see our dev repo</p>"},{"location":"#install-fluidsynth-optional","title":"Install fluidsynth (optional)","text":"<p>fluidsynth is a General MIDI synthesizer which you can install from the package manager. On macOS: <pre><code>brew install fluidsynth\n</code></pre> fluidsynth needs a soundfont to run, like this one: https://drive.google.com/file/d/1-cwBWZIYYTxFwzcWFaoGA7Kjx5SEjVAa/view</p> <p>run fluidsynth in a terminal. For example, <code>fluidsynth -v -o midi.portname=\"fluidsynth\" -o synth.midi-bank-select=mma ~/'Downloads/soundfonts/Timbres of Heaven (XGM) 4.00(G).sf2'</code></p>"},{"location":"#notochord-midi-apps","title":"Notochord MIDI Apps","text":"<p>Notochord includes several iipyper apps which can be run in a terminal. They have a clickable text-mode user interface and connect directly to MIDI ports, so you can wire them up to your controllers, DAW, etc.</p> <p>The Notochord harmonizer adds extra concurrent notes for each MIDI note you play in. In a terminal, make sure the <code>iil-python-tools</code> conda environment is active (<code>conda activate iil-python-tools</code>) and run: <pre><code>python -m notochord harmonizer\n</code></pre> try <code>python -m notochord harmonizer --help</code> to see more options.</p> <p>the <code>`homunculus'' gives you a UI to manage multiple input, harmonizing or autonomous notochord channels: <pre><code>python -m notochord homunculus\n</code></pre> You can set the MIDI in and out ports with</code>--midi-in<code>and</code>--midi-out<code>. If you use a General MIDI synthesizer like fluidsynth, you can add</code>--send-pc` to also send program change messages.</p> <p>If you are using fluidsynth, try: <pre><code>python -m notochord homunculus --send-pc --midi-out fluidsynth --thru\n</code></pre></p>"},{"location":"#python-api","title":"Python API","text":"<p>See the docstrings for <code>Notochord.feed</code> and <code>Notochord.query</code> in <code>notochord/model.py</code> for the low-level Notochord inference API which can be used from Python code. <code>notochord/app/simple_harmonizer.py</code> provides a minimal example of how to build an interactive app.</p>"},{"location":"#osc-server","title":"OSC server","text":"<p>You can also expose the inference API over Open Sound Control: <pre><code>python -m notochord server\n</code></pre> this will run notochord and listen continously for OSC messages.</p>"},{"location":"#tidal-interface","title":"Tidal interface","text":"<p>see <code>examples/notochord/tidalcycles</code> in the archived iil-python-tools repo (updated examples coming soon):</p> <p>add <code>Notochord.hs</code> to your tidal boot file. Probably replace the <code>tidal &lt;- startTidal</code> line with something like: <pre><code>:script ~/iil-python-tools/examples/notochord/tidalcycles/Notochord.hs\n\nlet sdOscMap = (superdirtTarget, [superdirtShape])\nlet oscMap = [sdOscMap,ncOscMap]\n\ntidal &lt;- startStream defaultConfig {cFrameTimespan = 1/240} oscMap\n</code></pre></p> <p>In a terminal, start the python server as described above.</p> <p>In Supercollider, step through <code>examples/notochord/tidalcycles/tidal-notochord-demo.scd</code> which will receive from Tidal, talk to the python server, and send MIDI on to a synthesizer. There are two options, either send to fluidsynth to synthesize General MIDI, or specify your own mapping of instruments to channels and send on to your own DAW or synth.</p>"},{"location":"#train-your-own-notochord-model-gpu-recommended","title":"Train your own Notochord model (GPU recommended)","text":"<p>preprocess the data: <pre><code>python notochord/scripts/lakh_prep.py --data_path /path/to/midi/files --dest_path /path/to/data/storage\n</code></pre> launch a training job: <pre><code>python notochord/train.py --data_dir /path/to/data/storage --log_dir /path/for/tensorboard/logs --model_dir /path/for/checkpoints --results_dir /path/for/other/logs train\n</code></pre> progress can be monitored via tensorboard.</p>"},{"location":"reference/notochord/__init__/","title":"init","text":""},{"location":"reference/notochord/data/","title":"Data","text":""},{"location":"reference/notochord/data/#notochord.data.MIDIDataset","title":"<code>MIDIDataset</code>","text":"<p>             Bases: <code>Dataset</code></p> Source code in <code>src/notochord/data.py</code> <pre><code>class MIDIDataset(Dataset):\n    def __init__(self, data_dir, batch_len, \n        transpose=5, speed=0.1, glob='**/*.pkl', test_len=2048,\n        onsets_only=False, remap_instruments=True):\n        \"\"\"\n        \"\"\"\n        super().__init__()\n        dirs = data_dir.split(',')\n        self.files = []\n        for d in dirs:\n            self.files.extend(list(Path(d).glob(glob)))\n            # print(self.files)\n        self.batch_len = batch_len\n        self.transpose = transpose\n        self.speed = speed\n        self.start_token = 128\n        self.n_anon = 32 # this needs to match n_instruments in model.py\n        self.prog_start_token = 0\n        self.testing = False\n        self.max_test_len = test_len\n        self.onsets_only = onsets_only\n        self.remap_instruments = remap_instruments\n\n    def __len__(self):\n        return len(self.files)\n\n    def is_melodic(self, program):\n        orig_program = program%1000\n        return (orig_program&lt;=128) | (orig_program&gt;256)\n\n    def is_anon(self, program):\n        return program &gt; 256\n\n    def _remap_anonymous_instruments(self, program: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Randomly map instruments to additional \u2018anonymous\u2019 melodic and drum identities\n        with a probability of 10% per instrument, without replacement. \n        Also map any parts &gt; 256 to appropriate anonymous ids.\n        \"\"\"\n        is_melodic = self.is_melodic(program)\n        is_anon = self.is_anon(program)\n        named_melodic = list(program.masked_select(is_melodic &amp; ~is_anon).unique())\n        anon_melodic = list(program.masked_select(is_melodic &amp; is_anon).unique())\n        named_drum = list(program.masked_select(~is_melodic &amp; ~is_anon).unique())\n        anon_drum = list(program.masked_select(~is_melodic &amp; is_anon).unique())\n\n        anon_melodic_start = 257\n        anon_drum_start = anon_melodic_start + self.n_anon\n        perm_anon_melodic = torch.randperm(self.n_anon) + anon_melodic_start \n        perm_anon_drum = torch.randperm(self.n_anon) + anon_drum_start \n\n        for pr in named_melodic:\n            if torch.rand((1,)) &lt; 0.1:\n                anon_melodic.append(pr)\n        for pr in named_drum:\n            if torch.rand((1,)) &lt; 0.1:\n                anon_drum.append(pr)\n\n        new_program = program.clone()\n\n        if len(anon_melodic)&gt;self.n_anon:\n            print(f'warning: {len(anon_melodic)} &gt; {self.n_anon} anon melodic instruments')\n        if len(anon_drum)&gt;self.n_anon:\n            print(f'warning: {len(anon_drum)} &gt; {self.n_anon} anon drum instruments')\n\n        i = 0\n        for pr in anon_melodic:\n            new_program[program==pr] = perm_anon_melodic[i%self.n_anon]\n            i += 1\n        i = 0\n        for pr in anon_drum:\n            new_program[program==pr] = perm_anon_drum[i%self.n_anon]\n            i += 1\n\n        # print(new_program.unique())\n\n        return new_program\n\n    def __getitem__(self, idx):\n        f = self.files[idx]\n        item = torch.load(f)\n        program = item['program'] # 1-d LongTensor of MIDI programs\n        # 0 is unused\n        # (128-256 are drums)\n        # 257+ are 'true anonymous' (no program change on track)\n        # (drums with no PC are just mapped to 129)\n        # N + 1000*K is the Kth additional part for instrument N\n        pitch = item['pitch'] # 1-d LongTensor of MIDI pitches 0-127\n        time = item['time'] # 1-d DoubleTensor of absolute times in seconds\n        velocity = item['velocity'] # 1-d LongTensor of MIDI velocities 0-127\n\n        assert len(pitch) == len(time)\n\n        if self.onsets_only:\n            b = velocity &gt; 0\n            program, pitch, time, velocity = (\n                program[b], pitch[b], time[b], velocity[b])\n\n        program, pitch, time, velocity = self.data_augmentation(\n            program, pitch, time, velocity)\n\n        # sort (using argsort on time and indexing the rest)\n        # compute delta time\n        time, idx = time.sort()\n        time = torch.cat((time.new_zeros((1,)), time)).diff(1).float()\n        velocity = velocity[idx]\n        program = program[idx]\n        pitch = pitch[idx]\n\n        # pad with start tokens, zeros\n        # always pad with batch_len so that end tokens don't appear in a biased\n        # location\n        pad = 0 if self.testing else self.batch_len-1#max(0, self.batch_len-len(pitch))\n        program = torch.cat((\n            program.new_full((1,), self.prog_start_token),\n            program,\n            program.new_zeros((pad,))))\n        pitch = torch.cat((\n            pitch.new_full((1,), self.start_token),\n            pitch,\n            pitch.new_zeros((pad,))))\n        time = torch.cat((\n            time.new_zeros((1,)),\n            time,\n            time.new_zeros((pad,))))\n        velocity = torch.cat((\n            velocity.new_zeros((1,)),\n            velocity,\n            velocity.new_zeros((pad,))))\n        # end signal: nonzero for last event\n        end = torch.zeros_like(program)\n        end[-pad-1:] = 1\n        # compute binary mask for the loss\n        mask = torch.ones_like(program, dtype=torch.bool)\n        if pad &gt; 0:\n            mask[-pad:] = False\n\n        if self.testing:\n            sl = slice(0, self.max_test_len)\n        else:\n            # random slice\n            i = random.randint(0, len(pitch)-self.batch_len)\n            sl = slice(i, i+self.batch_len)\n        program = program[sl]\n        pitch = pitch[sl]\n        time = time[sl]\n        velocity = velocity[sl]\n        end = end[sl]\n        mask = mask[sl]\n\n        return {\n            'mask':mask,\n            'end':end,\n            'instrument':program,\n            'pitch':pitch,\n            'time':time,\n            'velocity':velocity\n        }\n\n    def velocity_dequantize(self, velocity):\n        velocity = velocity.float()\n        velocity = (\n            velocity + \n            (torch.rand_like(velocity, dtype=torch.float)-0.5) * ((velocity&gt;0) &amp; (velocity&lt;127)).float()\n            ).clamp(0., 127.)\n        return velocity\n\n    def velocity_curve(self, velocity):\n        # take care not to map any positive values closer to 0 than 1\n        to_curve = (velocity &gt;= 0.5)\n        velocity[to_curve] -= 0.5\n        velocity[to_curve] /= 126.5\n        velocity[to_curve] = velocity[to_curve] ** (2**(torch.randn((1,))/3))\n        velocity[to_curve] *= 126.5\n        velocity[to_curve] += 0.5\n        return velocity\n\n    def data_augmentation(self, program, pitch, time, velocity):\n        \"\"\"override this in subclass for different data augmentation\"\"\"\n        # random transpose avoiding out of range notes\n        transpose_down = min(self.transpose, pitch.min().item())\n        transpose_up = min(self.transpose, 127-pitch.max())\n        transpose = (\n            random.randint(-transpose_down, transpose_up)\n            * self.is_melodic(program).long() # don't transpose drums\n        )\n        pitch = pitch + transpose\n\n        # scramble anonymous and extra parts to 'anonymous melodic' and 'anonymous drum' parts\n        if self.remap_instruments:\n            program = self._remap_anonymous_instruments(program)\n\n        time_margin = 1e-3\n\n        # dequantize: add noise up to +/- margin\n        # move note-ons later, note-offs earlier\n        time = (time + \n            torch.rand_like(time) * ((velocity==0).double()*2-1) * time_margin\n        )\n        # random augment tempo\n        time = time * (1 + random.random()*self.speed*2 - self.speed)\n\n        velocity = self.velocity_dequantize(velocity)\n        velocity = self.velocity_curve(velocity)\n\n        return program, pitch, time, velocity\n</code></pre>"},{"location":"reference/notochord/data/#notochord.data.MIDIDataset.__init__","title":"<code>__init__(data_dir, batch_len, transpose=5, speed=0.1, glob='**/*.pkl', test_len=2048, onsets_only=False, remap_instruments=True)</code>","text":"Source code in <code>src/notochord/data.py</code> <pre><code>def __init__(self, data_dir, batch_len, \n    transpose=5, speed=0.1, glob='**/*.pkl', test_len=2048,\n    onsets_only=False, remap_instruments=True):\n    \"\"\"\n    \"\"\"\n    super().__init__()\n    dirs = data_dir.split(',')\n    self.files = []\n    for d in dirs:\n        self.files.extend(list(Path(d).glob(glob)))\n        # print(self.files)\n    self.batch_len = batch_len\n    self.transpose = transpose\n    self.speed = speed\n    self.start_token = 128\n    self.n_anon = 32 # this needs to match n_instruments in model.py\n    self.prog_start_token = 0\n    self.testing = False\n    self.max_test_len = test_len\n    self.onsets_only = onsets_only\n    self.remap_instruments = remap_instruments\n</code></pre>"},{"location":"reference/notochord/data/#notochord.data.MIDIDataset.data_augmentation","title":"<code>data_augmentation(program, pitch, time, velocity)</code>","text":"<p>override this in subclass for different data augmentation</p> Source code in <code>src/notochord/data.py</code> <pre><code>def data_augmentation(self, program, pitch, time, velocity):\n    \"\"\"override this in subclass for different data augmentation\"\"\"\n    # random transpose avoiding out of range notes\n    transpose_down = min(self.transpose, pitch.min().item())\n    transpose_up = min(self.transpose, 127-pitch.max())\n    transpose = (\n        random.randint(-transpose_down, transpose_up)\n        * self.is_melodic(program).long() # don't transpose drums\n    )\n    pitch = pitch + transpose\n\n    # scramble anonymous and extra parts to 'anonymous melodic' and 'anonymous drum' parts\n    if self.remap_instruments:\n        program = self._remap_anonymous_instruments(program)\n\n    time_margin = 1e-3\n\n    # dequantize: add noise up to +/- margin\n    # move note-ons later, note-offs earlier\n    time = (time + \n        torch.rand_like(time) * ((velocity==0).double()*2-1) * time_margin\n    )\n    # random augment tempo\n    time = time * (1 + random.random()*self.speed*2 - self.speed)\n\n    velocity = self.velocity_dequantize(velocity)\n    velocity = self.velocity_curve(velocity)\n\n    return program, pitch, time, velocity\n</code></pre>"},{"location":"reference/notochord/distributions/","title":"Distributions","text":""},{"location":"reference/notochord/distributions/#notochord.distributions.CensoredMixtureLogistic","title":"<code>CensoredMixtureLogistic</code>","text":"<p>             Bases: <code>Module</code></p> Source code in <code>src/notochord/distributions.py</code> <pre><code>class CensoredMixtureLogistic(nn.Module):\n    def __init__(self, n, res=1e-2, lo='-inf', hi='inf', \n            sharp_bounds=(1e-4,2e3), init=None):\n        super().__init__()\n        self.n = n\n        self.res = res\n        self.sharp_bounds = sharp_bounds\n        self.register_buffer('lo', torch.tensor(float(lo)))\n        self.register_buffer('hi', torch.tensor(float(hi)))\n        # TODO: init is not general-purpose\n        #TODO\n        if init=='time':\n            self.bias = nn.Parameter(torch.cat((\n                torch.zeros(n), torch.logspace(-3,1,n), torch.zeros(n)\n                )))\n        elif init=='velocity':\n            self.bias = nn.Parameter(torch.cat((\n                torch.zeros(n), torch.linspace(0,127,n), torch.zeros(n)\n                )))\n        else:\n            self.bias = nn.Parameter(torch.cat((\n                torch.zeros(n), torch.randn(n), torch.zeros(n)\n                )))\n\n    @property\n    def n_params(self):\n        return self.n*3\n\n    def get_params(self, h):\n        assert h.shape[-1] == self.n_params\n        h = h+self.bias\n        # get parameters from unconstrained hidden state:\n        logit_pi, loc, log_s = torch.chunk(h, 3, -1)\n        # mixture coefficients\n        log_pi = logit_pi - logit_pi.logsumexp(-1,keepdim=True)\n        # location\n        loc = loc.clamp(self.lo-10*self.res, self.hi+10*self.res)\n        # sharpness\n        s = F.softplus(log_s).clamp(*self.sharp_bounds)\n        return log_pi, loc, s\n\n\n    def forward(self, h, x):\n        \"\"\"log prob of x under distribution parameterized by h\n        Args:\n            h: Tensor[...,n_params]\n            x: Tensor[...]\n            \"...\" dims must broadcast\n        \"\"\"\n        log_pi, loc, s = self.get_params(h)    \n\n        d = self.res/2\n        x = x.clamp(self.lo, self.hi)[...,None]\n        x_ = (x - loc) * s\n        sd = s*d\n\n        # # censoring\n        lo_cens = x &lt;= self.lo+d\n        hi_cens = x &gt;= self.hi-d\n        ones = torch.ones_like(s)\n        zeros = torch.zeros_like(s)\n\n        diff_term = torch.where(lo_cens | hi_cens, \n            ones, sd.exp() - (-sd).exp()\n            ).log()\n        minus_sp_term = torch.where(hi_cens, -sd, F.softplus(-sd-x_))\n        plus_sp_term = torch.where(lo_cens, zeros, x_ + F.softplus(sd-x_))\n\n        log_delta_cdf = diff_term - minus_sp_term - plus_sp_term\n\n        # log prob\n        r = {\n            'log_prob': (log_pi + log_delta_cdf).logsumexp(-1)\n        }\n        # diagnostics\n        with torch.no_grad():\n            ent = D.Categorical(logits=log_pi).entropy()\n            r |= {\n                # 'min_sharpness': s.min(),\n                'max_sharpness': s.max(),\n                'mean_sharpness': (s*log_pi.exp()).sum(-1).mean(),\n                # 'min_entropy': ent.min(),\n                # 'max_entropy': ent.max(),\n                'mean_cmp_entropy': ent.mean(),\n                'marginal_cmp_entropy': D.Categorical(\n                    log_pi.exp().mean(list(range(log_pi.ndim-1)))).entropy(),\n                # 'min_loc': loc.min(),\n                # 'max_loc': loc.max()\n            }\n        return r\n\n    def cdf(self, h, x):\n        \"\"\"\n        Args:\n            h: Tensor[...,n_params]\n            x: Tensor[...]\n                `h` should broadcast with `x[...,None]`\n        Returns:\n            cdf: Tensor[...] (shape of `x` broadcasted with `h[...,0]`)\n        \"\"\"\n        if not isinstance(x, torch.Tensor):\n            x = torch.tensor(x)\n        log_pi, loc, s = self.get_params(h)  \n        cdfs = self.cdf_components(loc, s, x)\n        cdf = (cdfs * log_pi.softmax(-1)).sum(-1)\n        return cdf\n\n    def cdf_components(self, loc, s, x):\n        x_ = (x[...,None] - loc) * s\n        return x_.sigmoid()        \n\n    # TODO: 'discrete_sample' method which would re-quantize and then allow\n    # e.g. nucleus sampling on the categorical distribution?\n    def sample(self, h, truncate=None, shape=None, \n        weight_top_p=None, component_temp=None, bias=None, \n        truncate_quantile=None, quantile_k=1024, eps=1e-9\n        ):\n        \"\"\"\n        Args:\n            h: Tensor[..., n_params]\n            truncate: Optional[Tuple[float, float]]. lower and upper bound for truncation.\n            shape: Optional[int]. additional sample shape to be prepended to dims.\n            weight_top_p: top_p (\"nucleus\") filtering for mixture weights.\n                default is 1 (no change to distribution). 0 would sample top\n                component (after truncation) only.\n            component_temp: Optional[float]. sampling temperature of each mixture \n                component. default is 1. 0 would sample component location only,\n                ignoring sharpness.\n            bias: applied outside of truncation but inside of clamping,\n                useful e.g. for latency correction when sampling delta-time\n            truncate_quantile: truncate the distribution \n            quantile_k: truncate_quantile is implemented by drawing this many\n                samples and sorting them  \n        Returns:\n            Tensor[*shape,...] (h without last dimension, prepended with `shape`)\n        \"\"\"\n        if shape is None:\n            unwrap = True\n            shape = 1\n        else:\n            unwrap = False\n\n        if truncate_quantile is not None:\n            # draw k samples\n            shape = shape * quantile_k\n\n        if truncate is None:\n            truncate = (-torch.inf, torch.inf)\n        truncate = torch.tensor(truncate)\n\n        if component_temp is None:\n            component_temp = 1\n\n        if bias is None:\n            bias = 0\n\n        log_pi, loc, s = self.get_params(h)\n        s = s/component_temp\n        scale = 1/s\n\n        # cdfs: [...,bound,component]\n        cdfs = self.cdf_components(loc[...,None,:], s[...,None,:], truncate) \n        # prob. mass of each component witin bounds\n        trunc_probs = cdfs[...,1,:] - cdfs[...,0,:] # [...,component]\n        probs = log_pi.exp() * trunc_probs # reweighted mixture component probs\n        if weight_top_p is not None:\n            # reweight with top_p\n            probs = reweight_top_p(probs+eps, weight_top_p)\n\n        ## DEBUG\n        # print(loc)\n        # print(s)\n        # print(trunc_probs)\n        # print(probs)\n        #, log_pi.exp(), trunc_probs)\n        # print(probs+eps)\n        c = D.Categorical(probs).sample((shape,))\n        # move sample dimension first\n        loc = loc.movedim(-1, 0).gather(0, c)\n        scale = scale.movedim(-1, 0).gather(0, c)\n        upper = cdfs[...,1,:].movedim(-1, 0).gather(0, c)\n        lower = cdfs[...,0,:].movedim(-1, 0).gather(0, c)\n\n        u = torch.rand(shape, *h.shape[:-1])\n        # truncate\n        u = u * (upper-lower) + lower\n\n        # x = loc + scale * (u.log() - (1 - u).log())\n        x = loc + bias - scale * (1/u - 1).log()\n\n        if truncate_quantile is not None:\n            x = x.sort(dim=0).values\n\n            idx = categorical_sample(\n                x.new_zeros(x.shape[0]), \n                truncate_quantile=truncate_quantile)\n\n            x = x[idx]\n\n        x = x.clamp(self.lo, self.hi)\n        return x[0] if unwrap else x\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.CensoredMixtureLogistic.cdf","title":"<code>cdf(h, x)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>h</code> <p>Tensor[...,n_params]</p> required <code>x</code> <p>Tensor[...] <code>h</code> should broadcast with <code>x[...,None]</code></p> required <p>Returns:     cdf: Tensor[...] (shape of <code>x</code> broadcasted with <code>h[...,0]</code>)</p> Source code in <code>src/notochord/distributions.py</code> <pre><code>def cdf(self, h, x):\n    \"\"\"\n    Args:\n        h: Tensor[...,n_params]\n        x: Tensor[...]\n            `h` should broadcast with `x[...,None]`\n    Returns:\n        cdf: Tensor[...] (shape of `x` broadcasted with `h[...,0]`)\n    \"\"\"\n    if not isinstance(x, torch.Tensor):\n        x = torch.tensor(x)\n    log_pi, loc, s = self.get_params(h)  \n    cdfs = self.cdf_components(loc, s, x)\n    cdf = (cdfs * log_pi.softmax(-1)).sum(-1)\n    return cdf\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.CensoredMixtureLogistic.forward","title":"<code>forward(h, x)</code>","text":"<p>log prob of x under distribution parameterized by h Args:     h: Tensor[...,n_params]     x: Tensor[...]     \"...\" dims must broadcast</p> Source code in <code>src/notochord/distributions.py</code> <pre><code>def forward(self, h, x):\n    \"\"\"log prob of x under distribution parameterized by h\n    Args:\n        h: Tensor[...,n_params]\n        x: Tensor[...]\n        \"...\" dims must broadcast\n    \"\"\"\n    log_pi, loc, s = self.get_params(h)    \n\n    d = self.res/2\n    x = x.clamp(self.lo, self.hi)[...,None]\n    x_ = (x - loc) * s\n    sd = s*d\n\n    # # censoring\n    lo_cens = x &lt;= self.lo+d\n    hi_cens = x &gt;= self.hi-d\n    ones = torch.ones_like(s)\n    zeros = torch.zeros_like(s)\n\n    diff_term = torch.where(lo_cens | hi_cens, \n        ones, sd.exp() - (-sd).exp()\n        ).log()\n    minus_sp_term = torch.where(hi_cens, -sd, F.softplus(-sd-x_))\n    plus_sp_term = torch.where(lo_cens, zeros, x_ + F.softplus(sd-x_))\n\n    log_delta_cdf = diff_term - minus_sp_term - plus_sp_term\n\n    # log prob\n    r = {\n        'log_prob': (log_pi + log_delta_cdf).logsumexp(-1)\n    }\n    # diagnostics\n    with torch.no_grad():\n        ent = D.Categorical(logits=log_pi).entropy()\n        r |= {\n            # 'min_sharpness': s.min(),\n            'max_sharpness': s.max(),\n            'mean_sharpness': (s*log_pi.exp()).sum(-1).mean(),\n            # 'min_entropy': ent.min(),\n            # 'max_entropy': ent.max(),\n            'mean_cmp_entropy': ent.mean(),\n            'marginal_cmp_entropy': D.Categorical(\n                log_pi.exp().mean(list(range(log_pi.ndim-1)))).entropy(),\n            # 'min_loc': loc.min(),\n            # 'max_loc': loc.max()\n        }\n    return r\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.CensoredMixtureLogistic.sample","title":"<code>sample(h, truncate=None, shape=None, weight_top_p=None, component_temp=None, bias=None, truncate_quantile=None, quantile_k=1024, eps=1e-09)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>h</code> <p>Tensor[..., n_params]</p> required <code>truncate</code> <p>Optional[Tuple[float, float]]. lower and upper bound for truncation.</p> <code>None</code> <code>shape</code> <p>Optional[int]. additional sample shape to be prepended to dims.</p> <code>None</code> <code>weight_top_p</code> <p>top_p (\"nucleus\") filtering for mixture weights. default is 1 (no change to distribution). 0 would sample top component (after truncation) only.</p> <code>None</code> <code>component_temp</code> <p>Optional[float]. sampling temperature of each mixture  component. default is 1. 0 would sample component location only, ignoring sharpness.</p> <code>None</code> <code>bias</code> <p>applied outside of truncation but inside of clamping, useful e.g. for latency correction when sampling delta-time</p> <code>None</code> <code>truncate_quantile</code> <p>truncate the distribution </p> <code>None</code> <code>quantile_k</code> <p>truncate_quantile is implemented by drawing this many samples and sorting them  </p> <code>1024</code> <p>Returns:     Tensor[*shape,...] (h without last dimension, prepended with <code>shape</code>)</p> Source code in <code>src/notochord/distributions.py</code> <pre><code>def sample(self, h, truncate=None, shape=None, \n    weight_top_p=None, component_temp=None, bias=None, \n    truncate_quantile=None, quantile_k=1024, eps=1e-9\n    ):\n    \"\"\"\n    Args:\n        h: Tensor[..., n_params]\n        truncate: Optional[Tuple[float, float]]. lower and upper bound for truncation.\n        shape: Optional[int]. additional sample shape to be prepended to dims.\n        weight_top_p: top_p (\"nucleus\") filtering for mixture weights.\n            default is 1 (no change to distribution). 0 would sample top\n            component (after truncation) only.\n        component_temp: Optional[float]. sampling temperature of each mixture \n            component. default is 1. 0 would sample component location only,\n            ignoring sharpness.\n        bias: applied outside of truncation but inside of clamping,\n            useful e.g. for latency correction when sampling delta-time\n        truncate_quantile: truncate the distribution \n        quantile_k: truncate_quantile is implemented by drawing this many\n            samples and sorting them  \n    Returns:\n        Tensor[*shape,...] (h without last dimension, prepended with `shape`)\n    \"\"\"\n    if shape is None:\n        unwrap = True\n        shape = 1\n    else:\n        unwrap = False\n\n    if truncate_quantile is not None:\n        # draw k samples\n        shape = shape * quantile_k\n\n    if truncate is None:\n        truncate = (-torch.inf, torch.inf)\n    truncate = torch.tensor(truncate)\n\n    if component_temp is None:\n        component_temp = 1\n\n    if bias is None:\n        bias = 0\n\n    log_pi, loc, s = self.get_params(h)\n    s = s/component_temp\n    scale = 1/s\n\n    # cdfs: [...,bound,component]\n    cdfs = self.cdf_components(loc[...,None,:], s[...,None,:], truncate) \n    # prob. mass of each component witin bounds\n    trunc_probs = cdfs[...,1,:] - cdfs[...,0,:] # [...,component]\n    probs = log_pi.exp() * trunc_probs # reweighted mixture component probs\n    if weight_top_p is not None:\n        # reweight with top_p\n        probs = reweight_top_p(probs+eps, weight_top_p)\n\n    ## DEBUG\n    # print(loc)\n    # print(s)\n    # print(trunc_probs)\n    # print(probs)\n    #, log_pi.exp(), trunc_probs)\n    # print(probs+eps)\n    c = D.Categorical(probs).sample((shape,))\n    # move sample dimension first\n    loc = loc.movedim(-1, 0).gather(0, c)\n    scale = scale.movedim(-1, 0).gather(0, c)\n    upper = cdfs[...,1,:].movedim(-1, 0).gather(0, c)\n    lower = cdfs[...,0,:].movedim(-1, 0).gather(0, c)\n\n    u = torch.rand(shape, *h.shape[:-1])\n    # truncate\n    u = u * (upper-lower) + lower\n\n    # x = loc + scale * (u.log() - (1 - u).log())\n    x = loc + bias - scale * (1/u - 1).log()\n\n    if truncate_quantile is not None:\n        x = x.sort(dim=0).values\n\n        idx = categorical_sample(\n            x.new_zeros(x.shape[0]), \n            truncate_quantile=truncate_quantile)\n\n        x = x[idx]\n\n    x = x.clamp(self.lo, self.hi)\n    return x[0] if unwrap else x\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.CensoredMixturePointyBoi","title":"<code>CensoredMixturePointyBoi</code>","text":"<p>             Bases: <code>Module</code></p> Source code in <code>src/notochord/distributions.py</code> <pre><code>class CensoredMixturePointyBoi(nn.Module):\n    def __init__(self, n, res=1e-2, lo='-inf', hi='inf', sharp_bounds=(1e-5,2e3)):\n        super().__init__()\n        self.n = n\n        self.res = res\n        self.sharp_bounds = sharp_bounds\n        # self.register_buffer('max_sharp', torch.tensor(float(max_sharp)))\n        self.register_buffer('lo', torch.tensor(float(lo)))\n        self.register_buffer('hi', torch.tensor(float(hi)))\n        # TODO: init is not general-purpose\n        self.bias = nn.Parameter(torch.cat((\n            torch.zeros(n), torch.logspace(-3,1,n), torch.zeros(n)\n            )))\n\n    @property\n    def n_params(self):\n        return self.n*3\n\n    def get_params(self, h):\n        assert h.shape[-1] == self.n_params\n        h = h+self.bias\n        # get parameters fron unconstrained hidden state:\n        logit_pi, loc, log_s = torch.chunk(h, 3, -1)\n        # mixture coefficients\n        log_pi = logit_pi - logit_pi.logsumexp(-1,keepdim=True)\n        # location\n        loc = loc.clamp(self.lo-10*self.res, self.hi+10*self.res)\n        # sharpness\n        # s = log_s.exp()\n        # s = torch.min(F.softplus(log_s), self.max_sharp)\n        s = F.softplus(log_s).clamp(*self.sharp_bounds)\n        # s = log_s.exp().clamp(*self.sharp_bounds)\n        return log_pi, loc, s\n\n    def forward(self, h, x):\n        \"\"\"log prob of x under distribution parameterized by h\"\"\"\n        log_pi, loc, s = self.get_params(h)    \n\n        x = x.clamp(self.lo, self.hi)[...,None]\n        xp, xm = x+self.res/2, x-self.res/2\n\n        # numerical crimes follow\n\n        # censoring\n        lo_cens = x &lt;= self.lo\n        xm_ = torch.where(lo_cens, -h.new_ones([]), (xm-loc)*s)\n        axm_ = torch.where(lo_cens, h.new_zeros([]), xm_.abs())\n        hi_cens = x &gt;= self.hi\n        xp_ = torch.where(hi_cens, h.new_ones([]), (xp-loc)*s)\n        axp_ = torch.where(hi_cens, h.new_zeros([]), xp_.abs())\n\n        log_delta_cdf = (\n            (xp_ - xm_ + xp_*axm_ - axp_*xm_).log() \n            - (axp_ + axm_ + axp_*axm_).log1p() \n            - math.log(2))\n\n        # log prob\n        r = {\n            'log_prob': (log_pi + log_delta_cdf).logsumexp(-1)\n        }\n        # diagnostics\n        with torch.no_grad():\n            ent = D.Categorical(logits=log_pi).entropy()\n            r |= {\n                'min_sharpness': s.min(),\n                'max_sharpness': s.max(),\n                'min_entropy': ent.min(),\n                'max_entropy': ent.max(),\n                'marginal_entropy': D.Categorical(\n                    log_pi.exp().mean(list(range(log_pi.ndim-1)))).entropy(),\n                'min_loc': loc.min(),\n                'max_loc': loc.max()\n            }\n        return r\n\n    def cdf(self, h, x):\n        log_pi, loc, s = self.get_params(h)  \n        x_ = (x[...,None] - loc) * s \n        cdfs = x_ / (1+x_.abs()) * 0.5 + 0.5\n        cdf = (cdfs * log_pi.softmax(-1)).sum(-1)\n        return cdf\n\n\n    def sample(self, h, shape=1):\n        \"\"\"\n        Args:\n            shape: additional sample shape to be prepended to dims\n        \"\"\"\n        # if shape is None: shape = []\n\n        log_pi, loc, s = self.get_params(h)\n        c = D.Categorical(logits=log_pi).sample((shape,))\n        # move sample dimension first\n        loc = loc.movedim(-1, 0).gather(0, c)\n        s = s.movedim(-1, 0).gather(0, c)\n\n        u = torch.rand(shape, *h.shape[:-1])*2-1\n        x_ = u / (1 - u.abs())\n        x = x_ / s + loc\n\n        return x.clamp(self.lo, self.hi)\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.CensoredMixturePointyBoi.forward","title":"<code>forward(h, x)</code>","text":"<p>log prob of x under distribution parameterized by h</p> Source code in <code>src/notochord/distributions.py</code> <pre><code>def forward(self, h, x):\n    \"\"\"log prob of x under distribution parameterized by h\"\"\"\n    log_pi, loc, s = self.get_params(h)    \n\n    x = x.clamp(self.lo, self.hi)[...,None]\n    xp, xm = x+self.res/2, x-self.res/2\n\n    # numerical crimes follow\n\n    # censoring\n    lo_cens = x &lt;= self.lo\n    xm_ = torch.where(lo_cens, -h.new_ones([]), (xm-loc)*s)\n    axm_ = torch.where(lo_cens, h.new_zeros([]), xm_.abs())\n    hi_cens = x &gt;= self.hi\n    xp_ = torch.where(hi_cens, h.new_ones([]), (xp-loc)*s)\n    axp_ = torch.where(hi_cens, h.new_zeros([]), xp_.abs())\n\n    log_delta_cdf = (\n        (xp_ - xm_ + xp_*axm_ - axp_*xm_).log() \n        - (axp_ + axm_ + axp_*axm_).log1p() \n        - math.log(2))\n\n    # log prob\n    r = {\n        'log_prob': (log_pi + log_delta_cdf).logsumexp(-1)\n    }\n    # diagnostics\n    with torch.no_grad():\n        ent = D.Categorical(logits=log_pi).entropy()\n        r |= {\n            'min_sharpness': s.min(),\n            'max_sharpness': s.max(),\n            'min_entropy': ent.min(),\n            'max_entropy': ent.max(),\n            'marginal_entropy': D.Categorical(\n                log_pi.exp().mean(list(range(log_pi.ndim-1)))).entropy(),\n            'min_loc': loc.min(),\n            'max_loc': loc.max()\n        }\n    return r\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.CensoredMixturePointyBoi.sample","title":"<code>sample(h, shape=1)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>shape</code> <p>additional sample shape to be prepended to dims</p> <code>1</code> Source code in <code>src/notochord/distributions.py</code> <pre><code>def sample(self, h, shape=1):\n    \"\"\"\n    Args:\n        shape: additional sample shape to be prepended to dims\n    \"\"\"\n    # if shape is None: shape = []\n\n    log_pi, loc, s = self.get_params(h)\n    c = D.Categorical(logits=log_pi).sample((shape,))\n    # move sample dimension first\n    loc = loc.movedim(-1, 0).gather(0, c)\n    s = s.movedim(-1, 0).gather(0, c)\n\n    u = torch.rand(shape, *h.shape[:-1])*2-1\n    x_ = u / (1 - u.abs())\n    x = x_ / s + loc\n\n    return x.clamp(self.lo, self.hi)\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.reweight_quantile","title":"<code>reweight_quantile(probs, min_q=0, max_q=1)</code>","text":"<p>reweight ordinal discrete distribution to have mass only between quantiles</p> Source code in <code>src/notochord/distributions.py</code> <pre><code>def reweight_quantile(probs, min_q=0, max_q=1):\n    \"\"\"\n    reweight ordinal discrete distribution to have mass only between quantiles\n    \"\"\"\n    # TODO\n    cdf = probs.cumsum(-1)\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/notochord/distributions/#notochord.distributions.reweight_top_p","title":"<code>reweight_top_p(probs, top_p)</code>","text":"<p>given tensor of probabilities, apply top p / \"nucleus\" filtering, or temperature if <code>top_p</code> is greater than 1</p> Source code in <code>src/notochord/distributions.py</code> <pre><code>def reweight_top_p(probs, top_p):\n    \"\"\"\n    given tensor of probabilities, apply top p / \"nucleus\" filtering,\n    or temperature if `top_p` is greater than 1\n    \"\"\"\n    if top_p &gt; 1:\n        probs = probs**(1/top_p)\n        return probs / probs.sum(-1)\n\n    # NOTE: this is fudged slightly, it doesn't 'interpolate' the cutoff bin\n    desc_probs, idx = probs.sort(-1, descending=True)\n    iidx = idx.argsort(-1)\n    cumprob = desc_probs.cumsum(-1)\n    # first index where cumprob &gt;= top_p is the last index we don't zero\n    to_zero = (cumprob &gt;= top_p).roll(1, -1)\n    to_zero[...,0] = False\n    # unsort\n    to_zero = to_zero.gather(-1, iidx)\n    weighted_probs = torch.zeros_like(probs).where(to_zero, probs)\n    return weighted_probs / weighted_probs.sum(-1, keepdim=True)\n</code></pre>"},{"location":"reference/notochord/model/","title":"Model","text":""},{"location":"reference/notochord/model/#notochord.model.MixEmbedding","title":"<code>MixEmbedding</code>","text":"<p>             Bases: <code>Module</code></p> Source code in <code>src/notochord/model.py</code> <pre><code>class MixEmbedding(nn.Module):\n    def __init__(self, n, domain=(0,1)):\n        \"\"\"\n        Args:\n            n (int): number of channels\n            domain (Tuple[float])\n        \"\"\"\n        super().__init__()\n        self.domain = domain\n        self.lo = nn.Parameter(torch.randn(n))\n        self.hi = nn.Parameter(torch.randn(n))\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: Tensor[...]\n        Returns:\n            Tensor[...,n]\n        \"\"\"\n        x = (x - self.domain[0])/(self.domain[1] - self.domain[0])\n        x = x[...,None]\n        return self.hi * x + self.lo * (1-x)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.MixEmbedding.__init__","title":"<code>__init__(n, domain=(0, 1))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>number of channels</p> required Source code in <code>src/notochord/model.py</code> <pre><code>def __init__(self, n, domain=(0,1)):\n    \"\"\"\n    Args:\n        n (int): number of channels\n        domain (Tuple[float])\n    \"\"\"\n    super().__init__()\n    self.domain = domain\n    self.lo = nn.Parameter(torch.randn(n))\n    self.hi = nn.Parameter(torch.randn(n))\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.MixEmbedding.forward","title":"<code>forward(x)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>x</code> <p>Tensor[...]</p> required <p>Returns:     Tensor[...,n]</p> Source code in <code>src/notochord/model.py</code> <pre><code>def forward(self, x):\n    \"\"\"\n    Args:\n        x: Tensor[...]\n    Returns:\n        Tensor[...,n]\n    \"\"\"\n    x = (x - self.domain[0])/(self.domain[1] - self.domain[0])\n    x = x[...,None]\n    return self.hi * x + self.lo * (1-x)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord","title":"<code>Notochord</code>","text":"<p>             Bases: <code>Module</code></p> Source code in <code>src/notochord/model.py</code> <pre><code>class Notochord(nn.Module):\n    # note: use named arguments only for benefit of training script\n    def __init__(self, \n            emb_size=256, \n            rnn_hidden=2048, rnn_layers=1, kind='gru', \n            mlp_layers=0,\n            dropout=0.1, norm=None,\n            num_pitches=128, \n            num_instruments=320,\n            time_sines=128, vel_sines=128,\n            time_bounds=(0,10), time_components=32, time_res=1e-2,\n            vel_components=16\n            ):\n        \"\"\"\n        \"\"\"\n        super().__init__()\n\n        self.note_dim = 4 # instrument, pitch, time, velocity\n\n        self.instrument_start_token = 0\n        self.instrument_domain = num_instruments+1\n\n        self.pitch_start_token = num_pitches\n        self.pitch_domain = num_pitches+1\n\n        self.max_dt = time_bounds[1]\n        self.time_dist = CensoredMixtureLogistic(\n            time_components, time_res, \n            sharp_bounds=(1e-4,2e3),\n            lo=time_bounds[0], hi=time_bounds[1], init='time')\n        self.vel_dist = CensoredMixtureLogistic(\n            vel_components, 1.0,\n            sharp_bounds=(1e-3,128),\n            lo=0, hi=127, init='velocity')\n\n        # embeddings for inputs\n        self.instrument_emb = nn.Embedding(self.instrument_domain, emb_size)\n        self.pitch_emb = nn.Embedding(self.pitch_domain, emb_size)\n        self.time_emb = (#torch.jit.script(\n            SineEmbedding(\n            time_sines, emb_size, 1e-3, 30, scale='log'))\n        # self.vel_emb = MixEmbedding(emb_size, (0, 127))\n        self.vel_emb = (#torch.jit.script(\n            SineEmbedding(\n            vel_sines, emb_size, 2, 512, scale='lin'))\n\n        # RNN backbone\n        self.rnn = GenericRNN(kind, \n            emb_size, rnn_hidden, \n            num_layers=rnn_layers, batch_first=True, dropout=dropout)\n\n        # learnable initial RNN state\n        self.initial_state = nn.ParameterList([\n             # layer x batch x hidden\n            nn.Parameter(torch.randn(rnn_layers,1,rnn_hidden)*rnn_hidden**-0.5)\n            for _ in range(2 if kind=='lstm' else 1)\n        ])\n\n        mlp_cls = GLUMLP#lambda *a: torch.jit.script(GLUMLP(*a))\n        # projection from RNN state to distribution parameters\n        self.h_proj = mlp_cls(\n                rnn_hidden, emb_size, emb_size, \n                mlp_layers, dropout, norm)\n        self.projections = nn.ModuleList([\n            mlp_cls(\n                emb_size, emb_size, self.instrument_domain, \n                mlp_layers, dropout, norm),\n            mlp_cls(\n                emb_size, emb_size, self.pitch_domain, \n                mlp_layers, dropout, norm),\n            mlp_cls(\n                emb_size, emb_size, self.time_dist.n_params,\n                mlp_layers, dropout, norm),\n            mlp_cls(\n                emb_size, emb_size, self.vel_dist.n_params, \n                mlp_layers, dropout, norm),\n        ])\n\n        self.end_proj = nn.Linear(rnn_hidden, 2)\n\n        with torch.no_grad():\n            for p in self.projections:\n                p.net[-1].weight.mul_(1e-2)\n            self.end_proj.weight.mul(1e-2)\n\n        # persistent RNN state for inference\n        for n,t in zip(self.cell_state_names(), self.initial_state):\n            self.register_buffer(n, t.clone())\n        self.step = 0\n\n        # volatile hidden states for caching purposes\n        self.h = None\n        self.h_query = None      \n\n    def cell_state_names(self):\n        return tuple(f'cell_state_{i}' for i in range(len(self.initial_state)))\n\n    @property\n    def cell_state(self):\n        return tuple(getattr(self, n) for n in self.cell_state_names())\n\n    @property\n    def embeddings(self):\n        return (\n            self.instrument_emb,\n            self.pitch_emb,\n            self.time_emb,\n            self.vel_emb\n        )\n\n    def forward(self, instruments, pitches, times, velocities, ends,\n            validation=False, ar_mask=None):\n        \"\"\"\n        teacher-forced probabilistic loss and diagnostics for training.\n\n        Args:\n            instruments: LongTensor[batch, time]\n            pitches: LongTensor[batch, time]\n            times: FloatTensor[batch, time]\n            velocities: FloatTensor[batch, time]\n            ends: LongTensor[batch, time]\n            validation: bool (computes some extra diagnostics)\n            ar_mask: Optional[Tensor[note_dim x note_dim]] if None, generate random\n                masks for training\n        \"\"\"\n        batch_size, batch_len = pitches.shape\n\n        # embed data to input vectors\n        inst_emb = self.instrument_emb(instruments) # batch, time, emb_size\n        pitch_emb = self.pitch_emb(pitches) # batch, time, emb_size\n        time_emb = self.time_emb(times) # batch, time, emb_size\n        vel_emb = self.vel_emb(velocities) # batch, time, emb_size\n\n        embs = (inst_emb, pitch_emb, time_emb, vel_emb)\n\n        # feed to RNN backbone\n        x = sum(embs)\n        ## broadcast initial state to batch size\n        initial_state = tuple(\n            t.expand(self.rnn.num_layers, x.shape[0], -1).contiguous() # 1 x batch x hidden\n            for t in self.initial_state)\n        h, _ = self.rnn(x, initial_state) #batch, time, hidden_size\n\n        # fit all note factorizations \n        # e.g. inst-&gt;pitch-&gt;time-&gt;vel vs vel-&gt;time-&gt;inst-&gt;pitch\n        trim_h = h[:,:-1]\n        # always include hidden state, never include same modality,\n        # other dependencies are random per time and position\n        n = self.note_dim\n        if ar_mask is None:\n            # random binary mask\n            ar_mask = torch.randint(2, (*trim_h.shape[:2],n,n), dtype=torch.bool, device=h.device)\n            # zero diagonal\n            ar_mask &amp;= ~torch.eye(n,n, dtype=torch.bool, device=h.device)\n        # include hidden state\n        ar_mask = torch.cat((ar_mask.new_ones(*ar_mask.shape[:-2],1,n), ar_mask), -2).float()\n\n        to_mask = torch.stack((\n            self.h_proj(trim_h),\n            *(emb[:,1:] for emb in embs)\n        ), -1)\n        # TODO: try without this tanh?\n        mode_hs = (to_mask @ ar_mask).tanh().unbind(-1)\n\n        # final projections to raw distribution parameters\n        inst_params, pitch_params, time_params, vel_params = [\n            proj(h) for proj,h in zip(self.projections, mode_hs)]\n\n        # get likelihood of data for each modality\n        inst_logits = F.log_softmax(inst_params, -1)\n        inst_targets = instruments[:,1:,None] #batch, time, 1\n        inst_log_probs = inst_logits.gather(-1, inst_targets)[...,0]\n\n        pitch_logits = F.log_softmax(pitch_params, -1)\n        pitch_targets = pitches[:,1:,None] #batch, time, 1\n        pitch_log_probs = pitch_logits.gather(-1, pitch_targets)[...,0]\n\n        time_targets = times[:,1:] # batch, time\n        time_result = self.time_dist(time_params, time_targets)\n        time_log_probs = time_result.pop('log_prob')\n\n        vel_targets = velocities[:,1:] # batch, time\n        vel_result = self.vel_dist(vel_params, vel_targets)\n        vel_log_probs = vel_result.pop('log_prob')\n\n        # end prediction\n        # skip the first position for convenience \n        # (so masking is the same for end as for note parts)\n        end_params = self.end_proj(h[:,1:])\n        end_logits = F.log_softmax(end_params, -1)\n        end_log_probs = end_logits.gather(-1, ends[:,1:,None])[...,0]\n\n        r = {\n            'end_log_probs': end_log_probs,\n            'instrument_log_probs': inst_log_probs,\n            'pitch_log_probs': pitch_log_probs,\n            'time_log_probs': time_log_probs,\n            'velocity_log_probs': vel_log_probs,\n            **{'time_'+k:v for k,v in time_result.items()},\n            **{'velocity_'+k:v for k,v in vel_result.items()}\n        }\n        # this just computes some extra diagnostics which are inconvenient to do in the\n        # training script. should be turned off during training for performance.\n        if validation:\n            with torch.no_grad():\n                r['time_acc_30ms'] = (\n                    self.time_dist.cdf(time_params, time_targets + 0.03)\n                    - torch.where(time_targets - 0.03 &gt;= 0,\n                        self.time_dist.cdf(time_params, time_targets - 0.03),\n                        time_targets.new_zeros([]))\n                )\n        return r\n\n\n    def is_drum(self, inst):\n        # TODO: add a constructor argument to specify which are drums\n        # hardcoded for now\n        return inst &gt; 128 and inst &lt; 257 or inst &gt; 288\n\n\n    def feed(self, inst, pitch, time, vel, **kw):\n        \"\"\"consume an event and advance hidden state\n\n        Args:\n            inst: int. instrument of current note.\n                0 is start token\n                1-128 are General MIDI instruments\n                129-256 are drumkits (MIDI 1-128 on channel 13)\n                257-288 are 'anonymous' melodic instruments\n                289-320 are 'anonymous' drumkits\n            pitch: int. MIDI pitch of current note.\n                0-127 are MIDI pitches / drums\n                128 is start token\n            time: float. elapsed time in seconds since previous event.\n            vel: float. (possibly dequantized) MIDI velocity from 0-127 inclusive.\n                0 indicates a note-off event\n            **kw: ignored (allows doing e.g. noto.feed(**noto.query(...)))\n        \"\"\"\n        # print(f'FEED from {threading.get_ident()}') \n\n        with torch.inference_mode():\n            inst = torch.LongTensor([[inst]]) # 1x1 (batch, time)\n            pitch = torch.LongTensor([[pitch]]) # 1x1 (batch, time)\n            time = torch.FloatTensor([[time]]) # 1x1 (batch, time)\n            vel = torch.FloatTensor([[vel]]) # 1x1 (batch, time)\n\n            embs = [\n                self.instrument_emb(inst), # 1, 1, emb_size\n                self.pitch_emb(pitch), # 1, 1, emb_size\n                self.time_emb(time),# 1, 1, emb_size\n                self.vel_emb(vel)# 1, 1, emb_size\n            ]\n            x = sum(embs)\n\n            self.h, new_state = self.rnn(x, self.cell_state)\n            for t,new_t in zip(self.cell_state, new_state):\n                t[:] = new_t\n\n            self.h_query = None\n\n            self.step += 1\n\n\n    # TODO: add end prediction to deep_query\n    def deep_query(self, query, predict_end=True):\n        \"\"\"flexible querying with nested Query objects.\n        see query_vtip for an example.\n\n        Args:\n            query: Query object\n        \"\"\"\n        if self.h_query is None:\n            with torch.inference_mode():\n                self.h_query = self.h_proj(self.h)\n        event = self._deep_query(\n            query, hidden=self.h_query[:,0], event={})\n\n        if predict_end:\n            # print('END')\n            # print(f'{self.h}')\n            with torch.inference_mode():\n                end_params = self.end_proj(self.h)\n                event['end'] = end_params.softmax(-1)[...,1].item()\n                # event['end'] = D.Categorical(logits=end_params).sample().item()\n        else:\n            event['end'] = 0#torch.zeros(self.h.shape[:-1])\n\n        return event\n\n    def _deep_query(self, query, hidden, event):\n        m = query.modality\n        sq = query.then\n        try:\n            idx = ('inst','pitch','time','vel').index(m)\n        except ValueError:\n            raise ValueError(f'unknown modality \"{m}\"')\n\n        project = self.projections[idx]\n        embed = self.embeddings[idx]\n\n        if m=='time':\n            dist = self.time_dist\n            sample = dist.sample\n        elif m=='vel':\n            dist = self.vel_dist\n            sample = dist.sample\n        else:\n            sample = categorical_sample\n\n        # Query.then can be:\n\n        # None (no further sub-queries)\n        # or str (no further sub-queries, set the 'path' property of the event)\n\n        # Query describing what to do next\n\n        # pair of Number, Query\n        # setting a deterministic value for the current query,\n        # and the query to execute next\n\n        # list of Range, Query pairs\n        # or list of Subset, Query pairs\n        #    describing what to do next given where the sampled value falls\n        #    Range and Subset can also carry weights\n\n\n        with torch.inference_mode():\n            #\n            if sq is None or isinstance(sq, str) or isinstance(sq, Query):\n                # this is the final query (sq is None or a path tag)\n                # or there are no cases, just proceed to next subquery\n                action = sq\n                params = project(hidden.tanh())\n                result = sample(params, **query.kw)\n\n            elif len(sq)==0:\n                raise ValueError(f\"subquery has no cases: {sq}\")\n\n            # deterministic single value cases\n            # elif len(sq)==1 and len(sq[0])==3 and isinstance(sq[0][0], Number):\n            #     # singleton list case\n            #     key, action = sq[0]\n            #     result = key\n            elif len(sq)==2 and isinstance(sq[0], Number):\n                # bare pair case\n                key, action = sq\n                result = key\n\n            elif m in ('inst', 'pitch'):\n                # weighted subsets case\n                try:\n                    assert all(isinstance(s, Subset) for s,_ in sq)\n                except Exception:\n                    raise ValueError(f\"\"\"\n                    subqueries should all be Subset, Query tuples here: {sq}\n                    \"\"\")\n\n                params = project(hidden.tanh())\n\n                 # sample subset\n                if len(sq) &gt; 1:\n                    all_probs = params.softmax(-1)\n                    probs = [\n                        all_probs[...,s.values].sum(-1) * s.weight\n                        for s,_ in sq]\n                    # print(f'deep_query {m} {sq=} {probs=}')\n                    idx = categorical_sample(torch.tensor(probs).log())\n                else:\n                    idx = 0\n                s,action = sq[idx]\n                # sample from range\n                result = sample(params, whitelist=s.values, **query.kw)\n\n            elif m in ('time', 'vel'):\n                # weighted ranges case\n                assert all(isinstance(r, Range) for r,_ in sq)\n\n                params = project(hidden.tanh())\n                # sample range\n                if len(sq) &gt; 1:\n                    probs = [\n                        (dist.cdf(params, r.hi) - dist.cdf(params, r.lo)\n                        ) * r.weight\n                        for r,_ in sq]\n                    # print(f'deep_query {m} {probs=}')\n                    idx = categorical_sample(torch.tensor(probs).log())\n                else:\n                    idx = 0\n                r,action = sq[idx]\n                # sample from range\n                result = sample(params, truncate=(r.lo, r.hi), **query.kw)\n\n            try:\n                event[m] = result.item()\n            except Exception:\n                event[m] = result\n\n            # embed, add to hidden, recurse into subquery\n            if isinstance(action, Query):\n                emb = embed(result)\n                hidden = hidden + emb\n                return self._deep_query(action, hidden, event)\n            else:\n                event['path'] = action\n                return event\n\n    def query_tipv_onsets(self,\n        min_time=None, max_time=None, \n        include_inst=None,\n        include_pitch=None,\n        truncate_quantile_time=None,\n        truncate_quantile_pitch=None,\n        rhythm_temp=None, timing_temp=None,\n        min_vel=None, max_vel=None\n        ):\n        \"\"\"\n        for onset-only_models\n        \"\"\"\n        q = Query(\n            'time',\n            truncate=(min_time or -torch.inf, max_time or torch.inf), \n            truncate_quantile=truncate_quantile_time,\n            weight_top_p=rhythm_temp, component_temp=timing_temp,\n            then=Query(\n                'inst',\n                whitelist=include_inst,\n                then=Query(\n                    'pitch',\n                    whitelist=include_pitch,\n                    truncate_quantile=truncate_quantile_pitch,\n                    then=Query(\n                        'vel',\n                        truncate=(min_vel or 0.5, max_vel or torch.inf),\n                    )\n                )\n            )\n        )\n        return self.deep_query(q)\n\n    def query_itpv_onsets(self,\n        min_time=None, max_time=None, \n        include_inst=None,\n        include_pitch=None,\n        truncate_quantile_time=None,\n        truncate_quantile_pitch=None,\n        rhythm_temp=None, timing_temp=None,\n        min_vel=None, max_vel=None\n        ):\n        \"\"\"\n        for onset-only_models\n        \"\"\"\n        q = Query(\n            'inst',\n            whitelist=include_inst,\n            then=Query(\n                'time',\n                truncate=(min_time or -torch.inf, max_time or torch.inf), \n                truncate_quantile=truncate_quantile_time,\n                weight_top_p=rhythm_temp, component_temp=timing_temp,\n                then=Query(\n                    'pitch',\n                    whitelist=include_pitch,\n                    truncate_quantile=truncate_quantile_pitch,\n                    then=Query(\n                        'vel',\n                        truncate=(min_vel or 0.5, max_vel or torch.inf),\n                    )\n                )\n            )\n        )\n        return self.deep_query(q)\n\n\n    def query_vtip(self,\n            note_on_map:Dict[int,List[int]], \n            note_off_map:Dict[int,List[int]], \n            min_time=None, max_time=None, \n            truncate_quantile_time=None,\n            truncate_quantile_pitch=None,\n            steer_density=None, # truncate_quantile_type ? \n            inst_weights=None,\n            no_steer=None, # TODO\n            ):\n        \"\"\" Query in velocity-time-instrument-pitch order,\n            efficiently truncating the joint distribution to just allowable\n            (velocity&gt;0)/instrument/pitch triples.\n\n            Args:\n                note_on_map: possible note-ons as {instrument: [pitch]} \n                note_off_map: possible note-offs as {instrument: [pitch]} \n        \"\"\"\n\n        no_on = all(len(ps)==0 for ps in note_on_map.values())\n        no_off = all(len(ps)==0 for ps in note_off_map.values())\n        if no_on and no_off:\n            raise ValueError(f\"\"\"\n                no possible notes {note_on_map=} {note_off_map=}\"\"\")\n\n        def get_subquery(ipm, path, weights=None):\n            return Query(\n                'time',\n                Query(\n                    'inst', [(\n                        Subset([i], 1 if weights is None else weights[i]), \n                        Query('pitch', path, \n                            whitelist=list(ps), \n                            truncate_quantile=None if self.is_drum(i) else truncate_quantile_pitch)\n                    ) for i,ps in ipm.items() if len(ps)]\n                ),\n                truncate=(min_time or -torch.inf, max_time or torch.inf), truncate_quantile=truncate_quantile_time\n            )\n        w = 1 if steer_density is None else 2**(steer_density*2-1)\n\n        w_on = 0 if no_on else w\n        w_off = 0 if no_off else 1/w\n\n        return self.deep_query(Query('vel', [\n            (Range(-torch.inf,0.5,w_off), get_subquery(note_off_map, 'note off')),\n            (Range(0.5,torch.inf,w_on), get_subquery(note_on_map, 'note on', inst_weights))\n        ]))\n\n    def query_vipt(self,\n        note_on_map, note_off_map,\n        min_time=None, max_time=None, \n        truncate_quantile_time=None,\n        truncate_quantile_pitch=None,\n        steer_density=None,\n        inst_weights=None,\n        no_steer=None,\n        ):\n        \"\"\"\n        Query in velocity-instrument-pitch-time order,\n            efficiently truncating the joint distribution to just allowable\n            (velocity&gt;0)/instrument/pitch triples.\n\n            Args:\n                note_on_map: possible note-ons as {instrument: [pitch]} \n                note_off_map: possible note-offs as {instrument: [pitch]} \n        \"\"\"\n\n        no_on = all(len(ps)==0 for ps in note_on_map.values())\n        no_off = all(len(ps)==0 for ps in note_off_map.values())\n        if no_on and no_off:\n            raise ValueError(f\"\"\"\n                no possible notes {note_on_map=} {note_off_map=}\"\"\")\n\n        def get_subquery(note_map, path, weights=None):\n            return Query(\n                'inst', \n                then=[(Subset([i], 1 if weights is None else weights[i]), Query(\n                    'pitch', \n                    whitelist=list(ps), \n                    truncate_quantile=None if self.is_drum(i) else truncate_quantile_pitch,\n                    then=Query(\n                        'time', path,         \n                        truncate=(min_time or -torch.inf, max_time or torch.inf), truncate_quantile=None if (no_steer is not None and i in no_steer) else truncate_quantile_time\n                    )\n                )) for i,ps in note_map.items() if len(ps)]\n            )\n\n        w = 1 if steer_density is None else 2**(steer_density*2-1)\n\n        w_on = 0 if no_on else w\n        w_off = 0 if no_off else 1/w\n\n        return self.deep_query(Query('vel', [\n            (Range(-torch.inf,0.5,w_off), get_subquery(note_off_map, 'note off')),\n            (Range(0.5,torch.inf,w_on), get_subquery(note_on_map, 'note on', inst_weights))\n        ]))\n\n    # def query_ipvt(self,\n    #     note_map, \n    #     min_time=-torch.inf, max_time=torch.inf, \n    #     min_vel=-torch.inf, max_vel=torch.inf,\n    #     truncate_quantile_time=None,\n    #     truncate_quantile_pitch=None,\n    #     ):\n    #     \"\"\"\n    #     \"\"\"\n\n    #     return self.deep_query(Query(\n    #         'inst', then=[(\n    #             Subset([i]), Query(\n    #                 'pitch', \n    #                 whitelist=list(ps), \n    #                 truncate_quantile=truncate_quantile_pitch,\n    #                 then=Query(\n    #                     'vel',\n    #                     truncate=(min_vel or -torch.inf, max_vel or torch.inf),\n    #                     then=Query(\n    #                         'time',         \n    #                         truncate=(min_time or -torch.inf, max_time or torch.inf), truncate_quantile=truncate_quantile_time\n    #                     )\n    #                 )\n    #             )\n    #         ) for i,ps in note_map.items() if len(ps)]\n    #     ))\n\n    # TODO: remove pitch_topk and sweep_time?\n    # TODO: rewrite this to build queries and dispatch to deep_query\n    def query(self,\n            next_inst:int=None, next_pitch:int=None, \n            next_time:float=None, next_vel:int=None,\n\n            allow_end:bool=False,\n\n            include_inst:List[int]=None, exclude_inst:List[int]=None,\n            allow_anon:bool=True, \n            instrument_temp:float=None, \n\n            include_pitch:List[int]=None, exclude_pitch:List[int]=None,\n            include_drum:List[int]=None,\n            truncate_quantile_pitch:Tuple[float,float]=None,\n            pitch_temp:float=None, \n            index_pitch:int=None,\n\n            min_time:float=None, max_time:float=None,\n            truncate_quantile_time:Tuple[float, float]=None,\n            rhythm_temp:float=None, timing_temp:float=None,\n\n            min_vel:int=None, max_vel:int=None,\n            velocity_temp:float=None,\n\n            pitch_topk:int=None, sweep_time:bool=False, \n\n            handle:str=None, return_params:bool=False\n            ) -&gt; dict:\n        \"\"\"\n        return a prediction for the next note.\n\n        various constraints on the the next note can be requested.\n\n        Args:\n            # hard constraints\n\n            next_inst: fix a particular instrument for the predicted note.\n                sampled values will always condition on fixed values, so passing\n                `next_inst=1`, for example, will make the event appropriate\n                for the piano (instrument 1) to play.\n            next_pitch: fix a particular MIDI number for the predicted note.\n                sampled values will always condition on fixed values, so passing\n                `next_pitch=60`, for example, will make the event appropriate\n                for a middle C.\n            next_time: fix a particular delta time for the predicted note.\n                sampled values will always condition on fixed values, so passing\n                `next_time=0`, for example, will make the event appropriate\n                for one which is concurrent with the previous event.\n            next_vel: fix a particular velocity for the predicted note.\n                sampled values will always condition on fixed values, so passing\n                `next_inst=0`, for example, will make the event appropriate\n                for a noteOff (i.e., something which is currently playing).\n\n            # partial constraints\n\n            include_inst: instrument id(s) to include in sampling.\n                (if not None, all others will be excluded)\n            exclude_inst: instrument id(s) to exclude from sampling.\n            allow_anon: bool. if False, zero probability of anon instruments\n\n            include_pitch: pitch(es) to include in sampling.\n                (if not None, all others will be excluded)\n            exclude_pitch: pitch(es) to exclude from sampling.\n            include_drum: like `include_pitch`, but only in effect when \n                instrument is a drumkit\n\n            min_time: if not None, truncate the time distribution below\n            max_time: if not None, truncate the time distribution above\n\n            min_vel: if not None, truncate the velocity distribution below\n                e.g., `min_vel=1` prevents NoteOff events\n            max_vel: if not None, truncate the velocity distribution above\n\n            allow_end: if False, zero probability of sampling the end marker\n\n            # sampling strategies\n\n            instrument_temp: if not None, apply top_p sampling to instrument. 0 is\n                deterministic, 1 is 'natural' according to the model\n\n            pitch_temp: if not None, apply top_p sampling to pitch. 0 is\n                deterministic, 1 is 'natural' according to the model\n            truncate_quantile_pitch: applied after include_pitch, exclude_pitch\n                truncate the remaining pitch distribution by quantile.\n                e.g. truncate_quantile_pitch=(0.25, 0.75)\n                excludes the lowest- and highest- pitch 25% of probability mass\n            index_pitch: if not None, deterministically take the\n                nth most likely pitch instead of sampling.\n\n            timing_temp: if not None, apply temperature sampling to the time\n                component. this affects fine timing; 0 is deterministic and \n                precise, 1 is 'natural' according to the model.\n            rhythm_temp: if not None, apply top_p sampling to the weighting\n                of mixture components. this affects coarse rhythmic patterns;\n                0 is deterministic, 1 is 'natural' according to the model\n            truncate_quantile_time: applied after min_time, max_time\n                truncate the remaining delta time distribution by quantile.\n                e.g. truncate_quantile_time=(0.25, 0.75)\n                excludes the soonest- and furthest- 25% of probability mass\n\n            velocity_temp: if not None, apply temperature sampling to the velocity\n                component.\n\n            # multiple predictions\n\n            pitch_topk: Optional[int]. if not None, instead of sampling pitch, \n                stack the top k most likely pitches along the batch dimension\n            sweep_time: if True, instead of sampling time, choose a diverse set\n                of times and stack along the batch dimension\n\n            # other\n\n            handle: metadata to be included in the returned dict, if not None\n            return_params: if True, return tensors of distribution parameters\n                under the keys `inst_params`, `pitch_params`, `time_params`,\n                and `vel_params`.\n\n        Returns:\n            'inst': int. id of predicted instrument.\n                1-128 are General MIDI standard melodic instruments\n                129-256 are drumkits for MIDI programs 1-128\n                257-288 are 'anonymous' melodic instruments\n                289-320 are 'anonymous' drumkits\n            'pitch': int. predicted MIDI number of next note, 0-128.\n            'time': float. predicted time to next note in seconds.\n            'vel': float. unquantized predicted velocity of next note.\n                0-127; hard 0 indicates a note-off event.\n            'end': int. value of 1 indicates the *current* event (the one \n                passed as arguments to `predict`) was the last event, and the\n                predicted event should *not* be played. if `allow end` is false, \n                this will always be 0.\n            'step': int. number of steps since calling `reset`.\n            '*_params': tensor. distribution parameters for visualization\n                and debugging purposes. present if `return_params` is True.\n\n        NOTE: `instrument`, `pitch`, `time`, `velocity` may return lists,\n            when using `sweep_time` or `pitch_topk`. that part of the API \n            is very experimental and likely to break.\n        \"\"\"\n         # validate options:\n        if (index_pitch is not None) and (pitch_temp is not None):\n            print(\"warning: `index pitch` overrides `pitch_temp`\")\n\n        inst_intervention = any(p is not None for p in (\n            instrument_temp, include_inst, exclude_inst))\n\n        pitch_intervention = (pitch_topk or any(p is not None for p in (\n            pitch_temp, include_pitch, exclude_pitch, include_drum)))\n\n        time_intervention = any(p is not None for p in (\n            min_time, max_time, rhythm_temp, timing_temp))\n\n        vel_intervention = any(p is not None for p in (\n            min_vel, max_vel, velocity_temp))\n\n        exclude_inst = arg_to_set(exclude_inst)\n        if not allow_anon:\n            exclude_inst |= set(range(257, 321))\n        constrain_inst = list((\n            set(range(self.instrument_domain)) - {self.instrument_start_token}\n            if include_inst is None \n            else arg_to_set(include_inst)\n        ) - exclude_inst)\n        if len(constrain_inst)==0:\n            raise ValueError(\"\"\"\n            every instrument has been excluded. check values of \n            `include_inst` and `exclude_inst`\n            \"\"\")\n        # elif len(constrain_inst)==1:\n        #     print(\"\"\"\n        #     warning: recommended to use `next_inst`, not \n        #     `include_inst` to allow only one specific instrument\n        #     \"\"\")\n\n        constrain_pitch = list((\n            set(range(self.pitch_domain)) - {self.pitch_start_token}\n            if include_pitch is None \n            else arg_to_set(include_pitch)\n        ) - arg_to_set(exclude_pitch))\n        if len(constrain_pitch)==0:\n            raise ValueError(\"\"\"\n            every pitch has been excluded. check values of \n            `include_pitch` and `exclude_pitch`\n            \"\"\")\n        elif len(constrain_pitch)==1:\n            print(\"\"\"\n            warning: recommended to use `next_pitch`, not \n            `include_pitch` to allow only one specific pitch\n            \"\"\")\n\n        # TODO: this got really complicated to support include_drum...\n        # really want to edit the whole joint distribution of pitch,inst in \n        # cases where certain pitches or drums need to be excluded...\n        # would that be practical? if there are ~40000 inst x pitch combos?\n        # would need to run the instrument head for a whole batch of all\n        # allowable pitches or vice-versa...\n        def sample_instrument(x):\n            # if include_drum is supplied, make sure to exclude drum instruments\n            # when no pitch is in the allowed drums\n            if include_drum is not None:\n                pit = predicted_by_name('pitch')\n                pits = [pit] if pit is not None else constrain_pitch\n                if pits is not None and all(pit not in include_drum for pit in pits):\n                    nonlocal constrain_inst\n                    if constrain_inst is None:\n                        constrain_inst = range(1,self.instrument_domain)\n                    constrain_inst = [\n                        i for i in constrain_inst if not self.is_drum(i)]\n\n            # if constrain_inst is not None:\n            #     preserve_x = x[...,constrain_inst]\n            #     x = torch.full_like(x, -torch.inf)\n            #     x[...,constrain_inst] = preserve_x\n            # probs = x.softmax(-1)\n            # if instrument_temp is not None:\n            #     probs = reweight_top_p(probs, instrument_temp)\n            # return D.Categorical(probs).sample()\n\n            return categorical_sample(x, \n                whitelist=constrain_inst,\n                top_p=instrument_temp)\n\n        def sample_pitch(x):\n            # conditional constraint\n            if include_drum is not None:\n                # if this event is / must be a drum,\n                # use include_drum instead of constrain_inst\n                inst = predicted_by_name('instrument')\n                insts = [inst] if inst is not None else constrain_inst\n                if insts is not None and all(self.is_drum(i) for i in insts):\n                    nonlocal constrain_pitch\n                    constrain_pitch = include_drum\n\n            if pitch_topk is not None:\n                raise NotImplementedError\n\n            return categorical_sample(x,\n                whitelist=constrain_pitch, \n                index=index_pitch,\n                top_p=pitch_temp,\n                truncate_quantile=truncate_quantile_pitch\n                )\n            # if constrain_pitch is not None:\n            #     preserve_x = x[...,constrain_pitch]\n            #     x = torch.full_like(x, -torch.inf)\n            #     x[...,constrain_pitch] = preserve_x\n            # # x is modified logits\n\n            # if index_pitch is not None:\n            #     return x.argsort(-1, True)[...,index_pitch]\n            # elif pitch_topk is not None:\n            #     return x.argsort(-1, True)[...,:pitch_topk].transpose(0,-1)\n\n            # probs = x.softmax(-1)\n            # if pitch_temp is not None:\n            #     probs = reweight_top_p(probs, pitch_temp)\n\n            # if steer_pitch is not None:\n            #     return steer_categorical(probs, steer_pitch)\n            # else:\n            #     return D.Categorical(probs).sample()\n\n        def sample_time(x):\n            # TODO: respect trunc_time when sweep_time is True\n            if sweep_time:\n                if min_time is not None or max_time is not None:\n                    raise NotImplementedError(\"\"\"\n                    trunc_time with sweep_time needs implementation\n                    \"\"\")\n                assert x.shape[0]==1, \"batch size should be 1 here\"\n                log_pi, loc, s = self.time_dist.get_params(x)\n                idx = log_pi.squeeze().argsort()[:9]\n                loc = loc.squeeze()[idx].sort().values[...,None] \n                # multiple times in batch dim\n                # print(loc.shape)\n                return loc\n\n            trunc = (\n                -torch.inf if min_time is None else min_time,\n                torch.inf if max_time is None else max_time)\n\n            return self.time_dist.sample(x, \n                truncate=trunc,\n                component_temp=timing_temp, \n                weight_top_p=rhythm_temp,\n                truncate_quantile=truncate_quantile_time\n                )\n\n        def sample_velocity(x):\n            trunc = (\n                -torch.inf if min_vel is None else min_vel,\n                torch.inf if max_vel is None else max_vel)\n            return self.vel_dist.sample(\n                x, component_temp=velocity_temp, truncate=trunc,\n                # truncate_quantile=truncate_quantile_vel\n                )\n\n        with torch.inference_mode():\n            if self.h_query is None:\n                self.h_query = self.h_proj(self.h)\n\n            modalities = list(zip(\n                self.projections,\n                (sample_instrument, sample_pitch, sample_time, sample_velocity),\n                self.embeddings,\n                ))\n\n            context = [self.h_query] # embedded outputs for autoregressive prediction\n            predicted = [] # raw outputs\n            params = [] # distribution parameters for visualization\n\n            fix = [\n                None if item is None else torch.tensor([[item]], dtype=dtype)\n                for item, dtype in zip(\n                    [next_inst, next_pitch, next_time, next_vel],\n                    [torch.long, torch.long, torch.float, torch.float])]\n\n            # if any modalities are determined, embed them\n            # sort constrained modalities before unconstrained\n            # TODO: option to skip modalities\n            det_idx, cons_idx, uncons_idx = [], [], []\n            for i,(item, embed) in enumerate(zip(fix, self.embeddings)):\n                if item is None:\n                    if (\n                        i==0 and inst_intervention or\n                        i==1 and pitch_intervention or\n                        i==2 and time_intervention or\n                        i==3 and vel_intervention):\n                        cons_idx.append(i)\n                    else:\n                        uncons_idx.append(i)\n                else:\n                    det_idx.append(i)\n                    context.append(embed(item))\n                    predicted.append(item)\n                    params.append(None)\n            undet_idx = cons_idx + uncons_idx\n            perm = det_idx + undet_idx # permutation from the canonical order\n            iperm = np.argsort(perm) # inverse permutation back to canonical order\n\n            mode_names = ['instrument', 'pitch', 'time', 'velocity']\n            name_to_idx = {k:v for k,v in zip(mode_names, iperm)}\n            def predicted_by_name(name):\n                idx = name_to_idx[name]\n                if len(predicted) &gt; idx:\n                    return predicted[idx]\n                return None\n            # print('sampling order:', [mode_names[i] for i in perm])\n\n            # for each undetermined modality, \n            # sample a new value conditioned on already determined ones\n\n            running_ctx = sum(context)\n            # print(running_ctx)\n            # perm_h_tgt = [h_tgt[i] for i in perm]\n            while len(undet_idx):\n                # print(running_ctx.norm())\n                i = undet_idx.pop(0) # index of modality to determine\n                # j = len(det_idx) # number already determined\n                project, sample, embed = modalities[i]\n                # determine value for the next modality\n                hidden = running_ctx.tanh()\n                params.append(project(hidden))\n                pred = sample(params[-1])\n                predicted.append(pred)\n                # prepare for next iteration\n                if len(undet_idx):\n                    # context.append(embed(pred))\n                    running_ctx += embed(pred)\n                det_idx.append(i)\n\n            pred_inst = predicted_by_name('instrument')\n            pred_pitch = predicted_by_name('pitch')\n            pred_time = predicted_by_name('time')\n            pred_vel = predicted_by_name('velocity')\n\n            if allow_end:\n                end_params = self.end_proj(self.h)\n                # print(end_params)\n                end = D.Categorical(logits=end_params).sample()\n            else:\n                end = torch.zeros(self.h.shape[:-1])\n\n            if sweep_time or pitch_topk:\n                # return lists of predictions\n                pred_inst = [x.item() for x in pred_inst]\n                pred_pitch = [x.item() for x in pred_pitch]\n                pred_time = [x.item() for x in pred_time]\n                pred_vel = [x.item() for x in pred_vel]\n                end = [x.item() for x in end]\n                # print(pred_time, pred_pitch, pred_vel)\n            else:\n                # return single predictions\n                pred_inst = pred_inst.item()\n                pred_pitch = pred_pitch.item()\n                pred_time = pred_time.item()\n                pred_vel = pred_vel.item()\n                end = end.item()\n\n            r = {\n                'inst': pred_inst,\n                'pitch': pred_pitch, \n                'time': pred_time,\n                'vel': pred_vel,\n\n                'end': end,\n                'step': self.step,\n            }\n\n            if handle is not None:\n                r['handle'] = handle\n\n            if return_params:\n                r |= {\n                    'inst_params': params[iperm[0]],\n                    'pitch_params': params[iperm[1]],\n                    'time_params': params[iperm[2]],\n                    'vel_params': params[iperm[3]]\n                }\n\n            return r\n\n\n    def predict(self, inst, pitch, time, vel, **kw):\n        \"\"\"\n        DEPRECATED: alias for feed_query\n        \"\"\"\n        self.feed(inst, pitch, time, vel)\n        return self.query(**kw)\n\n    def feed_query(self, inst, pitch, time, vel, **kw):\n        \"\"\"\n        call self.feed with *args, then self.query with **kwargs.\n        \"\"\"\n        self.feed(inst, pitch, time, vel)\n        return self.query(**kw)\n\n    def query_feed(self, *a, **kw):\n        \"\"\"\n        call self.query with *args **kwargs, then self.feed with result,\n            and return result\n        \"\"\"\n        r = self.query(*a, **kw)\n        self.feed(r['inst'], r['pitch'], r['time'], r['vel'])\n        return r\n\n    def feed_query_feed(self, inst, pitch, time, vel, **kw):\n        \"\"\"\n        call self.feed with *args, then self.query with **kwargs.\n        \"\"\"\n        self.feed(inst, pitch, time, vel)\n        return self.query_feed(**kw)\n\n    def reset(self, start=True):\n        \"\"\"\n        resets internal model state.\n        Args:\n            start: if True, send start tokens through the model\n        \"\"\"\n        self.step = 0\n        for n,t in zip(self.cell_state_names(), self.initial_state):\n            getattr(self, n)[:] = t.detach()\n        if start:\n            self.feed(\n                self.instrument_start_token, self.pitch_start_token, 0., 0.)\n\n    @classmethod\n    def from_checkpoint(cls, path):\n        \"\"\"\n        create a Notochord from a checkpoint file containing \n        hyperparameters and model weights.\n        \"\"\"\n        if path==\"notochord-latest.ckpt\":\n            import appdirs\n            d = Path(appdirs.user_data_dir('Notochord', 'IIL'))\n            d.mkdir(exist_ok=True)\n            path = d / path\n            # maybe download\n            if not path.is_file():\n                while True:\n                    answer = input(\"Do you want to download a notochord model? (y/n)\")\n                    if answer.lower() in [\"y\",\"yes\"]:\n                        download_url('https://github.com/Intelligent-Instruments-Lab/iil-python-tools/releases/download/notochord-v0.4.0/notochord_lakh_50G_deep.pt', path)\n                        print(f'saved to {path}')\n                        break\n                    if answer.lower() in [\"n\",\"no\"]:\n                        break\n            # path = \n        checkpoint = torch.load(path, map_location=torch.device('cpu'))\n        model = cls(**checkpoint['kw']['model'])\n        model.load_state_dict(checkpoint['model_state'], strict=False)\n        return model\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.__init__","title":"<code>__init__(emb_size=256, rnn_hidden=2048, rnn_layers=1, kind='gru', mlp_layers=0, dropout=0.1, norm=None, num_pitches=128, num_instruments=320, time_sines=128, vel_sines=128, time_bounds=(0, 10), time_components=32, time_res=0.01, vel_components=16)</code>","text":"Source code in <code>src/notochord/model.py</code> <pre><code>def __init__(self, \n        emb_size=256, \n        rnn_hidden=2048, rnn_layers=1, kind='gru', \n        mlp_layers=0,\n        dropout=0.1, norm=None,\n        num_pitches=128, \n        num_instruments=320,\n        time_sines=128, vel_sines=128,\n        time_bounds=(0,10), time_components=32, time_res=1e-2,\n        vel_components=16\n        ):\n    \"\"\"\n    \"\"\"\n    super().__init__()\n\n    self.note_dim = 4 # instrument, pitch, time, velocity\n\n    self.instrument_start_token = 0\n    self.instrument_domain = num_instruments+1\n\n    self.pitch_start_token = num_pitches\n    self.pitch_domain = num_pitches+1\n\n    self.max_dt = time_bounds[1]\n    self.time_dist = CensoredMixtureLogistic(\n        time_components, time_res, \n        sharp_bounds=(1e-4,2e3),\n        lo=time_bounds[0], hi=time_bounds[1], init='time')\n    self.vel_dist = CensoredMixtureLogistic(\n        vel_components, 1.0,\n        sharp_bounds=(1e-3,128),\n        lo=0, hi=127, init='velocity')\n\n    # embeddings for inputs\n    self.instrument_emb = nn.Embedding(self.instrument_domain, emb_size)\n    self.pitch_emb = nn.Embedding(self.pitch_domain, emb_size)\n    self.time_emb = (#torch.jit.script(\n        SineEmbedding(\n        time_sines, emb_size, 1e-3, 30, scale='log'))\n    # self.vel_emb = MixEmbedding(emb_size, (0, 127))\n    self.vel_emb = (#torch.jit.script(\n        SineEmbedding(\n        vel_sines, emb_size, 2, 512, scale='lin'))\n\n    # RNN backbone\n    self.rnn = GenericRNN(kind, \n        emb_size, rnn_hidden, \n        num_layers=rnn_layers, batch_first=True, dropout=dropout)\n\n    # learnable initial RNN state\n    self.initial_state = nn.ParameterList([\n         # layer x batch x hidden\n        nn.Parameter(torch.randn(rnn_layers,1,rnn_hidden)*rnn_hidden**-0.5)\n        for _ in range(2 if kind=='lstm' else 1)\n    ])\n\n    mlp_cls = GLUMLP#lambda *a: torch.jit.script(GLUMLP(*a))\n    # projection from RNN state to distribution parameters\n    self.h_proj = mlp_cls(\n            rnn_hidden, emb_size, emb_size, \n            mlp_layers, dropout, norm)\n    self.projections = nn.ModuleList([\n        mlp_cls(\n            emb_size, emb_size, self.instrument_domain, \n            mlp_layers, dropout, norm),\n        mlp_cls(\n            emb_size, emb_size, self.pitch_domain, \n            mlp_layers, dropout, norm),\n        mlp_cls(\n            emb_size, emb_size, self.time_dist.n_params,\n            mlp_layers, dropout, norm),\n        mlp_cls(\n            emb_size, emb_size, self.vel_dist.n_params, \n            mlp_layers, dropout, norm),\n    ])\n\n    self.end_proj = nn.Linear(rnn_hidden, 2)\n\n    with torch.no_grad():\n        for p in self.projections:\n            p.net[-1].weight.mul_(1e-2)\n        self.end_proj.weight.mul(1e-2)\n\n    # persistent RNN state for inference\n    for n,t in zip(self.cell_state_names(), self.initial_state):\n        self.register_buffer(n, t.clone())\n    self.step = 0\n\n    # volatile hidden states for caching purposes\n    self.h = None\n    self.h_query = None      \n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.deep_query","title":"<code>deep_query(query, predict_end=True)</code>","text":"<p>flexible querying with nested Query objects. see query_vtip for an example.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>Query object</p> required Source code in <code>src/notochord/model.py</code> <pre><code>def deep_query(self, query, predict_end=True):\n    \"\"\"flexible querying with nested Query objects.\n    see query_vtip for an example.\n\n    Args:\n        query: Query object\n    \"\"\"\n    if self.h_query is None:\n        with torch.inference_mode():\n            self.h_query = self.h_proj(self.h)\n    event = self._deep_query(\n        query, hidden=self.h_query[:,0], event={})\n\n    if predict_end:\n        # print('END')\n        # print(f'{self.h}')\n        with torch.inference_mode():\n            end_params = self.end_proj(self.h)\n            event['end'] = end_params.softmax(-1)[...,1].item()\n            # event['end'] = D.Categorical(logits=end_params).sample().item()\n    else:\n        event['end'] = 0#torch.zeros(self.h.shape[:-1])\n\n    return event\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.feed","title":"<code>feed(inst, pitch, time, vel, **kw)</code>","text":"<p>consume an event and advance hidden state</p> <p>Parameters:</p> Name Type Description Default <code>inst</code> <p>int. instrument of current note. 0 is start token 1-128 are General MIDI instruments 129-256 are drumkits (MIDI 1-128 on channel 13) 257-288 are 'anonymous' melodic instruments 289-320 are 'anonymous' drumkits</p> required <code>pitch</code> <p>int. MIDI pitch of current note. 0-127 are MIDI pitches / drums 128 is start token</p> required <code>time</code> <p>float. elapsed time in seconds since previous event.</p> required <code>vel</code> <p>float. (possibly dequantized) MIDI velocity from 0-127 inclusive. 0 indicates a note-off event</p> required <code>**kw</code> <p>ignored (allows doing e.g. noto.feed(**noto.query(...)))</p> <code>{}</code> Source code in <code>src/notochord/model.py</code> <pre><code>def feed(self, inst, pitch, time, vel, **kw):\n    \"\"\"consume an event and advance hidden state\n\n    Args:\n        inst: int. instrument of current note.\n            0 is start token\n            1-128 are General MIDI instruments\n            129-256 are drumkits (MIDI 1-128 on channel 13)\n            257-288 are 'anonymous' melodic instruments\n            289-320 are 'anonymous' drumkits\n        pitch: int. MIDI pitch of current note.\n            0-127 are MIDI pitches / drums\n            128 is start token\n        time: float. elapsed time in seconds since previous event.\n        vel: float. (possibly dequantized) MIDI velocity from 0-127 inclusive.\n            0 indicates a note-off event\n        **kw: ignored (allows doing e.g. noto.feed(**noto.query(...)))\n    \"\"\"\n    # print(f'FEED from {threading.get_ident()}') \n\n    with torch.inference_mode():\n        inst = torch.LongTensor([[inst]]) # 1x1 (batch, time)\n        pitch = torch.LongTensor([[pitch]]) # 1x1 (batch, time)\n        time = torch.FloatTensor([[time]]) # 1x1 (batch, time)\n        vel = torch.FloatTensor([[vel]]) # 1x1 (batch, time)\n\n        embs = [\n            self.instrument_emb(inst), # 1, 1, emb_size\n            self.pitch_emb(pitch), # 1, 1, emb_size\n            self.time_emb(time),# 1, 1, emb_size\n            self.vel_emb(vel)# 1, 1, emb_size\n        ]\n        x = sum(embs)\n\n        self.h, new_state = self.rnn(x, self.cell_state)\n        for t,new_t in zip(self.cell_state, new_state):\n            t[:] = new_t\n\n        self.h_query = None\n\n        self.step += 1\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.feed_query","title":"<code>feed_query(inst, pitch, time, vel, **kw)</code>","text":"<p>call self.feed with args, then self.query with *kwargs.</p> Source code in <code>src/notochord/model.py</code> <pre><code>def feed_query(self, inst, pitch, time, vel, **kw):\n    \"\"\"\n    call self.feed with *args, then self.query with **kwargs.\n    \"\"\"\n    self.feed(inst, pitch, time, vel)\n    return self.query(**kw)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.feed_query_feed","title":"<code>feed_query_feed(inst, pitch, time, vel, **kw)</code>","text":"<p>call self.feed with args, then self.query with *kwargs.</p> Source code in <code>src/notochord/model.py</code> <pre><code>def feed_query_feed(self, inst, pitch, time, vel, **kw):\n    \"\"\"\n    call self.feed with *args, then self.query with **kwargs.\n    \"\"\"\n    self.feed(inst, pitch, time, vel)\n    return self.query_feed(**kw)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.forward","title":"<code>forward(instruments, pitches, times, velocities, ends, validation=False, ar_mask=None)</code>","text":"<p>teacher-forced probabilistic loss and diagnostics for training.</p> <p>Parameters:</p> Name Type Description Default <code>instruments</code> <p>LongTensor[batch, time]</p> required <code>pitches</code> <p>LongTensor[batch, time]</p> required <code>times</code> <p>FloatTensor[batch, time]</p> required <code>velocities</code> <p>FloatTensor[batch, time]</p> required <code>ends</code> <p>LongTensor[batch, time]</p> required <code>validation</code> <p>bool (computes some extra diagnostics)</p> <code>False</code> <code>ar_mask</code> <p>Optional[Tensor[note_dim x note_dim]] if None, generate random masks for training</p> <code>None</code> Source code in <code>src/notochord/model.py</code> <pre><code>def forward(self, instruments, pitches, times, velocities, ends,\n        validation=False, ar_mask=None):\n    \"\"\"\n    teacher-forced probabilistic loss and diagnostics for training.\n\n    Args:\n        instruments: LongTensor[batch, time]\n        pitches: LongTensor[batch, time]\n        times: FloatTensor[batch, time]\n        velocities: FloatTensor[batch, time]\n        ends: LongTensor[batch, time]\n        validation: bool (computes some extra diagnostics)\n        ar_mask: Optional[Tensor[note_dim x note_dim]] if None, generate random\n            masks for training\n    \"\"\"\n    batch_size, batch_len = pitches.shape\n\n    # embed data to input vectors\n    inst_emb = self.instrument_emb(instruments) # batch, time, emb_size\n    pitch_emb = self.pitch_emb(pitches) # batch, time, emb_size\n    time_emb = self.time_emb(times) # batch, time, emb_size\n    vel_emb = self.vel_emb(velocities) # batch, time, emb_size\n\n    embs = (inst_emb, pitch_emb, time_emb, vel_emb)\n\n    # feed to RNN backbone\n    x = sum(embs)\n    ## broadcast initial state to batch size\n    initial_state = tuple(\n        t.expand(self.rnn.num_layers, x.shape[0], -1).contiguous() # 1 x batch x hidden\n        for t in self.initial_state)\n    h, _ = self.rnn(x, initial_state) #batch, time, hidden_size\n\n    # fit all note factorizations \n    # e.g. inst-&gt;pitch-&gt;time-&gt;vel vs vel-&gt;time-&gt;inst-&gt;pitch\n    trim_h = h[:,:-1]\n    # always include hidden state, never include same modality,\n    # other dependencies are random per time and position\n    n = self.note_dim\n    if ar_mask is None:\n        # random binary mask\n        ar_mask = torch.randint(2, (*trim_h.shape[:2],n,n), dtype=torch.bool, device=h.device)\n        # zero diagonal\n        ar_mask &amp;= ~torch.eye(n,n, dtype=torch.bool, device=h.device)\n    # include hidden state\n    ar_mask = torch.cat((ar_mask.new_ones(*ar_mask.shape[:-2],1,n), ar_mask), -2).float()\n\n    to_mask = torch.stack((\n        self.h_proj(trim_h),\n        *(emb[:,1:] for emb in embs)\n    ), -1)\n    # TODO: try without this tanh?\n    mode_hs = (to_mask @ ar_mask).tanh().unbind(-1)\n\n    # final projections to raw distribution parameters\n    inst_params, pitch_params, time_params, vel_params = [\n        proj(h) for proj,h in zip(self.projections, mode_hs)]\n\n    # get likelihood of data for each modality\n    inst_logits = F.log_softmax(inst_params, -1)\n    inst_targets = instruments[:,1:,None] #batch, time, 1\n    inst_log_probs = inst_logits.gather(-1, inst_targets)[...,0]\n\n    pitch_logits = F.log_softmax(pitch_params, -1)\n    pitch_targets = pitches[:,1:,None] #batch, time, 1\n    pitch_log_probs = pitch_logits.gather(-1, pitch_targets)[...,0]\n\n    time_targets = times[:,1:] # batch, time\n    time_result = self.time_dist(time_params, time_targets)\n    time_log_probs = time_result.pop('log_prob')\n\n    vel_targets = velocities[:,1:] # batch, time\n    vel_result = self.vel_dist(vel_params, vel_targets)\n    vel_log_probs = vel_result.pop('log_prob')\n\n    # end prediction\n    # skip the first position for convenience \n    # (so masking is the same for end as for note parts)\n    end_params = self.end_proj(h[:,1:])\n    end_logits = F.log_softmax(end_params, -1)\n    end_log_probs = end_logits.gather(-1, ends[:,1:,None])[...,0]\n\n    r = {\n        'end_log_probs': end_log_probs,\n        'instrument_log_probs': inst_log_probs,\n        'pitch_log_probs': pitch_log_probs,\n        'time_log_probs': time_log_probs,\n        'velocity_log_probs': vel_log_probs,\n        **{'time_'+k:v for k,v in time_result.items()},\n        **{'velocity_'+k:v for k,v in vel_result.items()}\n    }\n    # this just computes some extra diagnostics which are inconvenient to do in the\n    # training script. should be turned off during training for performance.\n    if validation:\n        with torch.no_grad():\n            r['time_acc_30ms'] = (\n                self.time_dist.cdf(time_params, time_targets + 0.03)\n                - torch.where(time_targets - 0.03 &gt;= 0,\n                    self.time_dist.cdf(time_params, time_targets - 0.03),\n                    time_targets.new_zeros([]))\n            )\n    return r\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.from_checkpoint","title":"<code>from_checkpoint(path)</code>  <code>classmethod</code>","text":"<p>create a Notochord from a checkpoint file containing  hyperparameters and model weights.</p> Source code in <code>src/notochord/model.py</code> <pre><code>@classmethod\ndef from_checkpoint(cls, path):\n    \"\"\"\n    create a Notochord from a checkpoint file containing \n    hyperparameters and model weights.\n    \"\"\"\n    if path==\"notochord-latest.ckpt\":\n        import appdirs\n        d = Path(appdirs.user_data_dir('Notochord', 'IIL'))\n        d.mkdir(exist_ok=True)\n        path = d / path\n        # maybe download\n        if not path.is_file():\n            while True:\n                answer = input(\"Do you want to download a notochord model? (y/n)\")\n                if answer.lower() in [\"y\",\"yes\"]:\n                    download_url('https://github.com/Intelligent-Instruments-Lab/iil-python-tools/releases/download/notochord-v0.4.0/notochord_lakh_50G_deep.pt', path)\n                    print(f'saved to {path}')\n                    break\n                if answer.lower() in [\"n\",\"no\"]:\n                    break\n        # path = \n    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n    model = cls(**checkpoint['kw']['model'])\n    model.load_state_dict(checkpoint['model_state'], strict=False)\n    return model\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.predict","title":"<code>predict(inst, pitch, time, vel, **kw)</code>","text":"<p>DEPRECATED: alias for feed_query</p> Source code in <code>src/notochord/model.py</code> <pre><code>def predict(self, inst, pitch, time, vel, **kw):\n    \"\"\"\n    DEPRECATED: alias for feed_query\n    \"\"\"\n    self.feed(inst, pitch, time, vel)\n    return self.query(**kw)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.query","title":"<code>query(next_inst=None, next_pitch=None, next_time=None, next_vel=None, allow_end=False, include_inst=None, exclude_inst=None, allow_anon=True, instrument_temp=None, include_pitch=None, exclude_pitch=None, include_drum=None, truncate_quantile_pitch=None, pitch_temp=None, index_pitch=None, min_time=None, max_time=None, truncate_quantile_time=None, rhythm_temp=None, timing_temp=None, min_vel=None, max_vel=None, velocity_temp=None, pitch_topk=None, sweep_time=False, handle=None, return_params=False)</code>","text":"<p>return a prediction for the next note.</p> <p>various constraints on the the next note can be requested.</p> <p>Parameters:</p> Name Type Description Default <code>next_inst</code> <code>int</code> <p>fix a particular instrument for the predicted note. sampled values will always condition on fixed values, so passing <code>next_inst=1</code>, for example, will make the event appropriate for the piano (instrument 1) to play.</p> <code>None</code> <code>next_pitch</code> <code>int</code> <p>fix a particular MIDI number for the predicted note. sampled values will always condition on fixed values, so passing <code>next_pitch=60</code>, for example, will make the event appropriate for a middle C.</p> <code>None</code> <code>next_time</code> <code>float</code> <p>fix a particular delta time for the predicted note. sampled values will always condition on fixed values, so passing <code>next_time=0</code>, for example, will make the event appropriate for one which is concurrent with the previous event.</p> <code>None</code> <code>next_vel</code> <code>int</code> <p>fix a particular velocity for the predicted note. sampled values will always condition on fixed values, so passing <code>next_inst=0</code>, for example, will make the event appropriate for a noteOff (i.e., something which is currently playing).</p> <code>None</code> <code>include_inst</code> <code>List[int]</code> <p>instrument id(s) to include in sampling. (if not None, all others will be excluded)</p> <code>None</code> <code>exclude_inst</code> <code>List[int]</code> <p>instrument id(s) to exclude from sampling.</p> <code>None</code> <code>allow_anon</code> <code>bool</code> <p>bool. if False, zero probability of anon instruments</p> <code>True</code> <code>include_pitch</code> <code>List[int]</code> <p>pitch(es) to include in sampling. (if not None, all others will be excluded)</p> <code>None</code> <code>exclude_pitch</code> <code>List[int]</code> <p>pitch(es) to exclude from sampling.</p> <code>None</code> <code>include_drum</code> <code>List[int]</code> <p>like <code>include_pitch</code>, but only in effect when  instrument is a drumkit</p> <code>None</code> <code>min_time</code> <code>float</code> <p>if not None, truncate the time distribution below</p> <code>None</code> <code>max_time</code> <code>float</code> <p>if not None, truncate the time distribution above</p> <code>None</code> <code>min_vel</code> <code>int</code> <p>if not None, truncate the velocity distribution below e.g., <code>min_vel=1</code> prevents NoteOff events</p> <code>None</code> <code>max_vel</code> <code>int</code> <p>if not None, truncate the velocity distribution above</p> <code>None</code> <code>allow_end</code> <code>bool</code> <p>if False, zero probability of sampling the end marker</p> <code>False</code> <code>instrument_temp</code> <code>float</code> <p>if not None, apply top_p sampling to instrument. 0 is deterministic, 1 is 'natural' according to the model</p> <code>None</code> <code>pitch_temp</code> <code>float</code> <p>if not None, apply top_p sampling to pitch. 0 is deterministic, 1 is 'natural' according to the model</p> <code>None</code> <code>truncate_quantile_pitch</code> <code>Tuple[float, float]</code> <p>applied after include_pitch, exclude_pitch truncate the remaining pitch distribution by quantile. e.g. truncate_quantile_pitch=(0.25, 0.75) excludes the lowest- and highest- pitch 25% of probability mass</p> <code>None</code> <code>index_pitch</code> <code>int</code> <p>if not None, deterministically take the nth most likely pitch instead of sampling.</p> <code>None</code> <code>timing_temp</code> <code>float</code> <p>if not None, apply temperature sampling to the time component. this affects fine timing; 0 is deterministic and  precise, 1 is 'natural' according to the model.</p> <code>None</code> <code>rhythm_temp</code> <code>float</code> <p>if not None, apply top_p sampling to the weighting of mixture components. this affects coarse rhythmic patterns; 0 is deterministic, 1 is 'natural' according to the model</p> <code>None</code> <code>truncate_quantile_time</code> <code>Tuple[float, float]</code> <p>applied after min_time, max_time truncate the remaining delta time distribution by quantile. e.g. truncate_quantile_time=(0.25, 0.75) excludes the soonest- and furthest- 25% of probability mass</p> <code>None</code> <code>velocity_temp</code> <code>float</code> <p>if not None, apply temperature sampling to the velocity component.</p> <code>None</code> <code>pitch_topk</code> <code>int</code> <p>Optional[int]. if not None, instead of sampling pitch,  stack the top k most likely pitches along the batch dimension</p> <code>None</code> <code>sweep_time</code> <code>bool</code> <p>if True, instead of sampling time, choose a diverse set of times and stack along the batch dimension</p> <code>False</code> <code>handle</code> <code>str</code> <p>metadata to be included in the returned dict, if not None</p> <code>None</code> <code>return_params</code> <code>bool</code> <p>if True, return tensors of distribution parameters under the keys <code>inst_params</code>, <code>pitch_params</code>, <code>time_params</code>, and <code>vel_params</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>'inst': int. id of predicted instrument. 1-128 are General MIDI standard melodic instruments 129-256 are drumkits for MIDI programs 1-128 257-288 are 'anonymous' melodic instruments 289-320 are 'anonymous' drumkits</p> <code>dict</code> <p>'pitch': int. predicted MIDI number of next note, 0-128.</p> <code>dict</code> <p>'time': float. predicted time to next note in seconds.</p> <code>dict</code> <p>'vel': float. unquantized predicted velocity of next note. 0-127; hard 0 indicates a note-off event.</p> <code>dict</code> <p>'end': int. value of 1 indicates the current event (the one  passed as arguments to <code>predict</code>) was the last event, and the predicted event should not be played. if <code>allow end</code> is false,  this will always be 0.</p> <code>dict</code> <p>'step': int. number of steps since calling <code>reset</code>.</p> <code>dict</code> <p>'*_params': tensor. distribution parameters for visualization and debugging purposes. present if <code>return_params</code> is True.</p> <code>instrument</code>, <code>pitch</code>, <code>time</code>, <code>velocity</code> may return lists, <p>when using <code>sweep_time</code> or <code>pitch_topk</code>. that part of the API  is very experimental and likely to break.</p> Source code in <code>src/notochord/model.py</code> <pre><code>def query(self,\n        next_inst:int=None, next_pitch:int=None, \n        next_time:float=None, next_vel:int=None,\n\n        allow_end:bool=False,\n\n        include_inst:List[int]=None, exclude_inst:List[int]=None,\n        allow_anon:bool=True, \n        instrument_temp:float=None, \n\n        include_pitch:List[int]=None, exclude_pitch:List[int]=None,\n        include_drum:List[int]=None,\n        truncate_quantile_pitch:Tuple[float,float]=None,\n        pitch_temp:float=None, \n        index_pitch:int=None,\n\n        min_time:float=None, max_time:float=None,\n        truncate_quantile_time:Tuple[float, float]=None,\n        rhythm_temp:float=None, timing_temp:float=None,\n\n        min_vel:int=None, max_vel:int=None,\n        velocity_temp:float=None,\n\n        pitch_topk:int=None, sweep_time:bool=False, \n\n        handle:str=None, return_params:bool=False\n        ) -&gt; dict:\n    \"\"\"\n    return a prediction for the next note.\n\n    various constraints on the the next note can be requested.\n\n    Args:\n        # hard constraints\n\n        next_inst: fix a particular instrument for the predicted note.\n            sampled values will always condition on fixed values, so passing\n            `next_inst=1`, for example, will make the event appropriate\n            for the piano (instrument 1) to play.\n        next_pitch: fix a particular MIDI number for the predicted note.\n            sampled values will always condition on fixed values, so passing\n            `next_pitch=60`, for example, will make the event appropriate\n            for a middle C.\n        next_time: fix a particular delta time for the predicted note.\n            sampled values will always condition on fixed values, so passing\n            `next_time=0`, for example, will make the event appropriate\n            for one which is concurrent with the previous event.\n        next_vel: fix a particular velocity for the predicted note.\n            sampled values will always condition on fixed values, so passing\n            `next_inst=0`, for example, will make the event appropriate\n            for a noteOff (i.e., something which is currently playing).\n\n        # partial constraints\n\n        include_inst: instrument id(s) to include in sampling.\n            (if not None, all others will be excluded)\n        exclude_inst: instrument id(s) to exclude from sampling.\n        allow_anon: bool. if False, zero probability of anon instruments\n\n        include_pitch: pitch(es) to include in sampling.\n            (if not None, all others will be excluded)\n        exclude_pitch: pitch(es) to exclude from sampling.\n        include_drum: like `include_pitch`, but only in effect when \n            instrument is a drumkit\n\n        min_time: if not None, truncate the time distribution below\n        max_time: if not None, truncate the time distribution above\n\n        min_vel: if not None, truncate the velocity distribution below\n            e.g., `min_vel=1` prevents NoteOff events\n        max_vel: if not None, truncate the velocity distribution above\n\n        allow_end: if False, zero probability of sampling the end marker\n\n        # sampling strategies\n\n        instrument_temp: if not None, apply top_p sampling to instrument. 0 is\n            deterministic, 1 is 'natural' according to the model\n\n        pitch_temp: if not None, apply top_p sampling to pitch. 0 is\n            deterministic, 1 is 'natural' according to the model\n        truncate_quantile_pitch: applied after include_pitch, exclude_pitch\n            truncate the remaining pitch distribution by quantile.\n            e.g. truncate_quantile_pitch=(0.25, 0.75)\n            excludes the lowest- and highest- pitch 25% of probability mass\n        index_pitch: if not None, deterministically take the\n            nth most likely pitch instead of sampling.\n\n        timing_temp: if not None, apply temperature sampling to the time\n            component. this affects fine timing; 0 is deterministic and \n            precise, 1 is 'natural' according to the model.\n        rhythm_temp: if not None, apply top_p sampling to the weighting\n            of mixture components. this affects coarse rhythmic patterns;\n            0 is deterministic, 1 is 'natural' according to the model\n        truncate_quantile_time: applied after min_time, max_time\n            truncate the remaining delta time distribution by quantile.\n            e.g. truncate_quantile_time=(0.25, 0.75)\n            excludes the soonest- and furthest- 25% of probability mass\n\n        velocity_temp: if not None, apply temperature sampling to the velocity\n            component.\n\n        # multiple predictions\n\n        pitch_topk: Optional[int]. if not None, instead of sampling pitch, \n            stack the top k most likely pitches along the batch dimension\n        sweep_time: if True, instead of sampling time, choose a diverse set\n            of times and stack along the batch dimension\n\n        # other\n\n        handle: metadata to be included in the returned dict, if not None\n        return_params: if True, return tensors of distribution parameters\n            under the keys `inst_params`, `pitch_params`, `time_params`,\n            and `vel_params`.\n\n    Returns:\n        'inst': int. id of predicted instrument.\n            1-128 are General MIDI standard melodic instruments\n            129-256 are drumkits for MIDI programs 1-128\n            257-288 are 'anonymous' melodic instruments\n            289-320 are 'anonymous' drumkits\n        'pitch': int. predicted MIDI number of next note, 0-128.\n        'time': float. predicted time to next note in seconds.\n        'vel': float. unquantized predicted velocity of next note.\n            0-127; hard 0 indicates a note-off event.\n        'end': int. value of 1 indicates the *current* event (the one \n            passed as arguments to `predict`) was the last event, and the\n            predicted event should *not* be played. if `allow end` is false, \n            this will always be 0.\n        'step': int. number of steps since calling `reset`.\n        '*_params': tensor. distribution parameters for visualization\n            and debugging purposes. present if `return_params` is True.\n\n    NOTE: `instrument`, `pitch`, `time`, `velocity` may return lists,\n        when using `sweep_time` or `pitch_topk`. that part of the API \n        is very experimental and likely to break.\n    \"\"\"\n     # validate options:\n    if (index_pitch is not None) and (pitch_temp is not None):\n        print(\"warning: `index pitch` overrides `pitch_temp`\")\n\n    inst_intervention = any(p is not None for p in (\n        instrument_temp, include_inst, exclude_inst))\n\n    pitch_intervention = (pitch_topk or any(p is not None for p in (\n        pitch_temp, include_pitch, exclude_pitch, include_drum)))\n\n    time_intervention = any(p is not None for p in (\n        min_time, max_time, rhythm_temp, timing_temp))\n\n    vel_intervention = any(p is not None for p in (\n        min_vel, max_vel, velocity_temp))\n\n    exclude_inst = arg_to_set(exclude_inst)\n    if not allow_anon:\n        exclude_inst |= set(range(257, 321))\n    constrain_inst = list((\n        set(range(self.instrument_domain)) - {self.instrument_start_token}\n        if include_inst is None \n        else arg_to_set(include_inst)\n    ) - exclude_inst)\n    if len(constrain_inst)==0:\n        raise ValueError(\"\"\"\n        every instrument has been excluded. check values of \n        `include_inst` and `exclude_inst`\n        \"\"\")\n    # elif len(constrain_inst)==1:\n    #     print(\"\"\"\n    #     warning: recommended to use `next_inst`, not \n    #     `include_inst` to allow only one specific instrument\n    #     \"\"\")\n\n    constrain_pitch = list((\n        set(range(self.pitch_domain)) - {self.pitch_start_token}\n        if include_pitch is None \n        else arg_to_set(include_pitch)\n    ) - arg_to_set(exclude_pitch))\n    if len(constrain_pitch)==0:\n        raise ValueError(\"\"\"\n        every pitch has been excluded. check values of \n        `include_pitch` and `exclude_pitch`\n        \"\"\")\n    elif len(constrain_pitch)==1:\n        print(\"\"\"\n        warning: recommended to use `next_pitch`, not \n        `include_pitch` to allow only one specific pitch\n        \"\"\")\n\n    # TODO: this got really complicated to support include_drum...\n    # really want to edit the whole joint distribution of pitch,inst in \n    # cases where certain pitches or drums need to be excluded...\n    # would that be practical? if there are ~40000 inst x pitch combos?\n    # would need to run the instrument head for a whole batch of all\n    # allowable pitches or vice-versa...\n    def sample_instrument(x):\n        # if include_drum is supplied, make sure to exclude drum instruments\n        # when no pitch is in the allowed drums\n        if include_drum is not None:\n            pit = predicted_by_name('pitch')\n            pits = [pit] if pit is not None else constrain_pitch\n            if pits is not None and all(pit not in include_drum for pit in pits):\n                nonlocal constrain_inst\n                if constrain_inst is None:\n                    constrain_inst = range(1,self.instrument_domain)\n                constrain_inst = [\n                    i for i in constrain_inst if not self.is_drum(i)]\n\n        # if constrain_inst is not None:\n        #     preserve_x = x[...,constrain_inst]\n        #     x = torch.full_like(x, -torch.inf)\n        #     x[...,constrain_inst] = preserve_x\n        # probs = x.softmax(-1)\n        # if instrument_temp is not None:\n        #     probs = reweight_top_p(probs, instrument_temp)\n        # return D.Categorical(probs).sample()\n\n        return categorical_sample(x, \n            whitelist=constrain_inst,\n            top_p=instrument_temp)\n\n    def sample_pitch(x):\n        # conditional constraint\n        if include_drum is not None:\n            # if this event is / must be a drum,\n            # use include_drum instead of constrain_inst\n            inst = predicted_by_name('instrument')\n            insts = [inst] if inst is not None else constrain_inst\n            if insts is not None and all(self.is_drum(i) for i in insts):\n                nonlocal constrain_pitch\n                constrain_pitch = include_drum\n\n        if pitch_topk is not None:\n            raise NotImplementedError\n\n        return categorical_sample(x,\n            whitelist=constrain_pitch, \n            index=index_pitch,\n            top_p=pitch_temp,\n            truncate_quantile=truncate_quantile_pitch\n            )\n        # if constrain_pitch is not None:\n        #     preserve_x = x[...,constrain_pitch]\n        #     x = torch.full_like(x, -torch.inf)\n        #     x[...,constrain_pitch] = preserve_x\n        # # x is modified logits\n\n        # if index_pitch is not None:\n        #     return x.argsort(-1, True)[...,index_pitch]\n        # elif pitch_topk is not None:\n        #     return x.argsort(-1, True)[...,:pitch_topk].transpose(0,-1)\n\n        # probs = x.softmax(-1)\n        # if pitch_temp is not None:\n        #     probs = reweight_top_p(probs, pitch_temp)\n\n        # if steer_pitch is not None:\n        #     return steer_categorical(probs, steer_pitch)\n        # else:\n        #     return D.Categorical(probs).sample()\n\n    def sample_time(x):\n        # TODO: respect trunc_time when sweep_time is True\n        if sweep_time:\n            if min_time is not None or max_time is not None:\n                raise NotImplementedError(\"\"\"\n                trunc_time with sweep_time needs implementation\n                \"\"\")\n            assert x.shape[0]==1, \"batch size should be 1 here\"\n            log_pi, loc, s = self.time_dist.get_params(x)\n            idx = log_pi.squeeze().argsort()[:9]\n            loc = loc.squeeze()[idx].sort().values[...,None] \n            # multiple times in batch dim\n            # print(loc.shape)\n            return loc\n\n        trunc = (\n            -torch.inf if min_time is None else min_time,\n            torch.inf if max_time is None else max_time)\n\n        return self.time_dist.sample(x, \n            truncate=trunc,\n            component_temp=timing_temp, \n            weight_top_p=rhythm_temp,\n            truncate_quantile=truncate_quantile_time\n            )\n\n    def sample_velocity(x):\n        trunc = (\n            -torch.inf if min_vel is None else min_vel,\n            torch.inf if max_vel is None else max_vel)\n        return self.vel_dist.sample(\n            x, component_temp=velocity_temp, truncate=trunc,\n            # truncate_quantile=truncate_quantile_vel\n            )\n\n    with torch.inference_mode():\n        if self.h_query is None:\n            self.h_query = self.h_proj(self.h)\n\n        modalities = list(zip(\n            self.projections,\n            (sample_instrument, sample_pitch, sample_time, sample_velocity),\n            self.embeddings,\n            ))\n\n        context = [self.h_query] # embedded outputs for autoregressive prediction\n        predicted = [] # raw outputs\n        params = [] # distribution parameters for visualization\n\n        fix = [\n            None if item is None else torch.tensor([[item]], dtype=dtype)\n            for item, dtype in zip(\n                [next_inst, next_pitch, next_time, next_vel],\n                [torch.long, torch.long, torch.float, torch.float])]\n\n        # if any modalities are determined, embed them\n        # sort constrained modalities before unconstrained\n        # TODO: option to skip modalities\n        det_idx, cons_idx, uncons_idx = [], [], []\n        for i,(item, embed) in enumerate(zip(fix, self.embeddings)):\n            if item is None:\n                if (\n                    i==0 and inst_intervention or\n                    i==1 and pitch_intervention or\n                    i==2 and time_intervention or\n                    i==3 and vel_intervention):\n                    cons_idx.append(i)\n                else:\n                    uncons_idx.append(i)\n            else:\n                det_idx.append(i)\n                context.append(embed(item))\n                predicted.append(item)\n                params.append(None)\n        undet_idx = cons_idx + uncons_idx\n        perm = det_idx + undet_idx # permutation from the canonical order\n        iperm = np.argsort(perm) # inverse permutation back to canonical order\n\n        mode_names = ['instrument', 'pitch', 'time', 'velocity']\n        name_to_idx = {k:v for k,v in zip(mode_names, iperm)}\n        def predicted_by_name(name):\n            idx = name_to_idx[name]\n            if len(predicted) &gt; idx:\n                return predicted[idx]\n            return None\n        # print('sampling order:', [mode_names[i] for i in perm])\n\n        # for each undetermined modality, \n        # sample a new value conditioned on already determined ones\n\n        running_ctx = sum(context)\n        # print(running_ctx)\n        # perm_h_tgt = [h_tgt[i] for i in perm]\n        while len(undet_idx):\n            # print(running_ctx.norm())\n            i = undet_idx.pop(0) # index of modality to determine\n            # j = len(det_idx) # number already determined\n            project, sample, embed = modalities[i]\n            # determine value for the next modality\n            hidden = running_ctx.tanh()\n            params.append(project(hidden))\n            pred = sample(params[-1])\n            predicted.append(pred)\n            # prepare for next iteration\n            if len(undet_idx):\n                # context.append(embed(pred))\n                running_ctx += embed(pred)\n            det_idx.append(i)\n\n        pred_inst = predicted_by_name('instrument')\n        pred_pitch = predicted_by_name('pitch')\n        pred_time = predicted_by_name('time')\n        pred_vel = predicted_by_name('velocity')\n\n        if allow_end:\n            end_params = self.end_proj(self.h)\n            # print(end_params)\n            end = D.Categorical(logits=end_params).sample()\n        else:\n            end = torch.zeros(self.h.shape[:-1])\n\n        if sweep_time or pitch_topk:\n            # return lists of predictions\n            pred_inst = [x.item() for x in pred_inst]\n            pred_pitch = [x.item() for x in pred_pitch]\n            pred_time = [x.item() for x in pred_time]\n            pred_vel = [x.item() for x in pred_vel]\n            end = [x.item() for x in end]\n            # print(pred_time, pred_pitch, pred_vel)\n        else:\n            # return single predictions\n            pred_inst = pred_inst.item()\n            pred_pitch = pred_pitch.item()\n            pred_time = pred_time.item()\n            pred_vel = pred_vel.item()\n            end = end.item()\n\n        r = {\n            'inst': pred_inst,\n            'pitch': pred_pitch, \n            'time': pred_time,\n            'vel': pred_vel,\n\n            'end': end,\n            'step': self.step,\n        }\n\n        if handle is not None:\n            r['handle'] = handle\n\n        if return_params:\n            r |= {\n                'inst_params': params[iperm[0]],\n                'pitch_params': params[iperm[1]],\n                'time_params': params[iperm[2]],\n                'vel_params': params[iperm[3]]\n            }\n\n        return r\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.query_feed","title":"<code>query_feed(*a, **kw)</code>","text":"<p>call self.query with args *kwargs, then self.feed with result,     and return result</p> Source code in <code>src/notochord/model.py</code> <pre><code>def query_feed(self, *a, **kw):\n    \"\"\"\n    call self.query with *args **kwargs, then self.feed with result,\n        and return result\n    \"\"\"\n    r = self.query(*a, **kw)\n    self.feed(r['inst'], r['pitch'], r['time'], r['vel'])\n    return r\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.query_itpv_onsets","title":"<code>query_itpv_onsets(min_time=None, max_time=None, include_inst=None, include_pitch=None, truncate_quantile_time=None, truncate_quantile_pitch=None, rhythm_temp=None, timing_temp=None, min_vel=None, max_vel=None)</code>","text":"<p>for onset-only_models</p> Source code in <code>src/notochord/model.py</code> <pre><code>def query_itpv_onsets(self,\n    min_time=None, max_time=None, \n    include_inst=None,\n    include_pitch=None,\n    truncate_quantile_time=None,\n    truncate_quantile_pitch=None,\n    rhythm_temp=None, timing_temp=None,\n    min_vel=None, max_vel=None\n    ):\n    \"\"\"\n    for onset-only_models\n    \"\"\"\n    q = Query(\n        'inst',\n        whitelist=include_inst,\n        then=Query(\n            'time',\n            truncate=(min_time or -torch.inf, max_time or torch.inf), \n            truncate_quantile=truncate_quantile_time,\n            weight_top_p=rhythm_temp, component_temp=timing_temp,\n            then=Query(\n                'pitch',\n                whitelist=include_pitch,\n                truncate_quantile=truncate_quantile_pitch,\n                then=Query(\n                    'vel',\n                    truncate=(min_vel or 0.5, max_vel or torch.inf),\n                )\n            )\n        )\n    )\n    return self.deep_query(q)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.query_tipv_onsets","title":"<code>query_tipv_onsets(min_time=None, max_time=None, include_inst=None, include_pitch=None, truncate_quantile_time=None, truncate_quantile_pitch=None, rhythm_temp=None, timing_temp=None, min_vel=None, max_vel=None)</code>","text":"<p>for onset-only_models</p> Source code in <code>src/notochord/model.py</code> <pre><code>def query_tipv_onsets(self,\n    min_time=None, max_time=None, \n    include_inst=None,\n    include_pitch=None,\n    truncate_quantile_time=None,\n    truncate_quantile_pitch=None,\n    rhythm_temp=None, timing_temp=None,\n    min_vel=None, max_vel=None\n    ):\n    \"\"\"\n    for onset-only_models\n    \"\"\"\n    q = Query(\n        'time',\n        truncate=(min_time or -torch.inf, max_time or torch.inf), \n        truncate_quantile=truncate_quantile_time,\n        weight_top_p=rhythm_temp, component_temp=timing_temp,\n        then=Query(\n            'inst',\n            whitelist=include_inst,\n            then=Query(\n                'pitch',\n                whitelist=include_pitch,\n                truncate_quantile=truncate_quantile_pitch,\n                then=Query(\n                    'vel',\n                    truncate=(min_vel or 0.5, max_vel or torch.inf),\n                )\n            )\n        )\n    )\n    return self.deep_query(q)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.query_vipt","title":"<code>query_vipt(note_on_map, note_off_map, min_time=None, max_time=None, truncate_quantile_time=None, truncate_quantile_pitch=None, steer_density=None, inst_weights=None, no_steer=None)</code>","text":"<p>Query in velocity-instrument-pitch-time order,     efficiently truncating the joint distribution to just allowable     (velocity&gt;0)/instrument/pitch triples.</p> <pre><code>Args:\n    note_on_map: possible note-ons as {instrument: [pitch]} \n    note_off_map: possible note-offs as {instrument: [pitch]}\n</code></pre> Source code in <code>src/notochord/model.py</code> <pre><code>def query_vipt(self,\n    note_on_map, note_off_map,\n    min_time=None, max_time=None, \n    truncate_quantile_time=None,\n    truncate_quantile_pitch=None,\n    steer_density=None,\n    inst_weights=None,\n    no_steer=None,\n    ):\n    \"\"\"\n    Query in velocity-instrument-pitch-time order,\n        efficiently truncating the joint distribution to just allowable\n        (velocity&gt;0)/instrument/pitch triples.\n\n        Args:\n            note_on_map: possible note-ons as {instrument: [pitch]} \n            note_off_map: possible note-offs as {instrument: [pitch]} \n    \"\"\"\n\n    no_on = all(len(ps)==0 for ps in note_on_map.values())\n    no_off = all(len(ps)==0 for ps in note_off_map.values())\n    if no_on and no_off:\n        raise ValueError(f\"\"\"\n            no possible notes {note_on_map=} {note_off_map=}\"\"\")\n\n    def get_subquery(note_map, path, weights=None):\n        return Query(\n            'inst', \n            then=[(Subset([i], 1 if weights is None else weights[i]), Query(\n                'pitch', \n                whitelist=list(ps), \n                truncate_quantile=None if self.is_drum(i) else truncate_quantile_pitch,\n                then=Query(\n                    'time', path,         \n                    truncate=(min_time or -torch.inf, max_time or torch.inf), truncate_quantile=None if (no_steer is not None and i in no_steer) else truncate_quantile_time\n                )\n            )) for i,ps in note_map.items() if len(ps)]\n        )\n\n    w = 1 if steer_density is None else 2**(steer_density*2-1)\n\n    w_on = 0 if no_on else w\n    w_off = 0 if no_off else 1/w\n\n    return self.deep_query(Query('vel', [\n        (Range(-torch.inf,0.5,w_off), get_subquery(note_off_map, 'note off')),\n        (Range(0.5,torch.inf,w_on), get_subquery(note_on_map, 'note on', inst_weights))\n    ]))\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.query_vtip","title":"<code>query_vtip(note_on_map, note_off_map, min_time=None, max_time=None, truncate_quantile_time=None, truncate_quantile_pitch=None, steer_density=None, inst_weights=None, no_steer=None)</code>","text":"<p>Query in velocity-time-instrument-pitch order, efficiently truncating the joint distribution to just allowable (velocity&gt;0)/instrument/pitch triples.</p> <p>Parameters:</p> Name Type Description Default <code>note_on_map</code> <code>Dict[int, List[int]]</code> <p>possible note-ons as {instrument: [pitch]} </p> required <code>note_off_map</code> <code>Dict[int, List[int]]</code> <p>possible note-offs as {instrument: [pitch]}</p> required Source code in <code>src/notochord/model.py</code> <pre><code>def query_vtip(self,\n        note_on_map:Dict[int,List[int]], \n        note_off_map:Dict[int,List[int]], \n        min_time=None, max_time=None, \n        truncate_quantile_time=None,\n        truncate_quantile_pitch=None,\n        steer_density=None, # truncate_quantile_type ? \n        inst_weights=None,\n        no_steer=None, # TODO\n        ):\n    \"\"\" Query in velocity-time-instrument-pitch order,\n        efficiently truncating the joint distribution to just allowable\n        (velocity&gt;0)/instrument/pitch triples.\n\n        Args:\n            note_on_map: possible note-ons as {instrument: [pitch]} \n            note_off_map: possible note-offs as {instrument: [pitch]} \n    \"\"\"\n\n    no_on = all(len(ps)==0 for ps in note_on_map.values())\n    no_off = all(len(ps)==0 for ps in note_off_map.values())\n    if no_on and no_off:\n        raise ValueError(f\"\"\"\n            no possible notes {note_on_map=} {note_off_map=}\"\"\")\n\n    def get_subquery(ipm, path, weights=None):\n        return Query(\n            'time',\n            Query(\n                'inst', [(\n                    Subset([i], 1 if weights is None else weights[i]), \n                    Query('pitch', path, \n                        whitelist=list(ps), \n                        truncate_quantile=None if self.is_drum(i) else truncate_quantile_pitch)\n                ) for i,ps in ipm.items() if len(ps)]\n            ),\n            truncate=(min_time or -torch.inf, max_time or torch.inf), truncate_quantile=truncate_quantile_time\n        )\n    w = 1 if steer_density is None else 2**(steer_density*2-1)\n\n    w_on = 0 if no_on else w\n    w_off = 0 if no_off else 1/w\n\n    return self.deep_query(Query('vel', [\n        (Range(-torch.inf,0.5,w_off), get_subquery(note_off_map, 'note off')),\n        (Range(0.5,torch.inf,w_on), get_subquery(note_on_map, 'note on', inst_weights))\n    ]))\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.Notochord.reset","title":"<code>reset(start=True)</code>","text":"<p>resets internal model state. Args:     start: if True, send start tokens through the model</p> Source code in <code>src/notochord/model.py</code> <pre><code>def reset(self, start=True):\n    \"\"\"\n    resets internal model state.\n    Args:\n        start: if True, send start tokens through the model\n    \"\"\"\n    self.step = 0\n    for n,t in zip(self.cell_state_names(), self.initial_state):\n        getattr(self, n)[:] = t.detach()\n    if start:\n        self.feed(\n            self.instrument_start_token, self.pitch_start_token, 0., 0.)\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.SineEmbedding","title":"<code>SineEmbedding</code>","text":"<p>             Bases: <code>Module</code></p> Source code in <code>src/notochord/model.py</code> <pre><code>class SineEmbedding(nn.Module):\n    def __init__(self, n, hidden, w0=1e-3, w1=10, scale='log'):\n        \"\"\"\n        Args:\n            n (int): number of sinusoids\n            hidden (int): embedding size\n            w0 (float): minimum wavelength\n            w1 (float): maximum wavelength\n            scale (str): if 'log', more wavelengths close to w0\n        \"\"\"\n        super().__init__()\n        if scale=='log':\n            w0 = math.log(w0)\n            w1 = math.log(w1)\n        ws = torch.linspace(w0, w1, n)\n        if scale=='log':\n            ws = ws.exp()\n        self.register_buffer('fs', 2 * math.pi / ws)\n        self.proj = nn.Linear(n,hidden)\n\n    def forward(self, x):\n        x = x[...,None] * self.fs\n        return self.proj(x.sin())\n</code></pre>"},{"location":"reference/notochord/model/#notochord.model.SineEmbedding.__init__","title":"<code>__init__(n, hidden, w0=0.001, w1=10, scale='log')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>number of sinusoids</p> required <code>hidden</code> <code>int</code> <p>embedding size</p> required <code>w0</code> <code>float</code> <p>minimum wavelength</p> <code>0.001</code> <code>w1</code> <code>float</code> <p>maximum wavelength</p> <code>10</code> <code>scale</code> <code>str</code> <p>if 'log', more wavelengths close to w0</p> <code>'log'</code> Source code in <code>src/notochord/model.py</code> <pre><code>def __init__(self, n, hidden, w0=1e-3, w1=10, scale='log'):\n    \"\"\"\n    Args:\n        n (int): number of sinusoids\n        hidden (int): embedding size\n        w0 (float): minimum wavelength\n        w1 (float): maximum wavelength\n        scale (str): if 'log', more wavelengths close to w0\n    \"\"\"\n    super().__init__()\n    if scale=='log':\n        w0 = math.log(w0)\n        w1 = math.log(w1)\n    ws = torch.linspace(w0, w1, n)\n    if scale=='log':\n        ws = ws.exp()\n    self.register_buffer('fs', 2 * math.pi / ws)\n    self.proj = nn.Linear(n,hidden)\n</code></pre>"},{"location":"reference/notochord/perform/","title":"Perform","text":""},{"location":"reference/notochord/perform/#notochord.perform.MIDIConfig","title":"<code>MIDIConfig</code>","text":"<p>             Bases: <code>dict</code></p> <p>invertible map from MIDI channel: Notochord instrument</p> Source code in <code>src/notochord/perform.py</code> <pre><code>class MIDIConfig(dict):\n    \"\"\"\n    invertible map from MIDI channel: Notochord instrument\n    \"\"\"\n    def __init__(self, *a, **kw):\n        super().__init__(*a, **kw)\n        self.invertible = len(self.channels)==len(self.insts)\n\n    @property\n    def channels(self):\n        \"\"\"set of channels\"\"\"\n        return set(self)\n    @property\n    def insts(self):\n        \"\"\"set of instruments\"\"\"\n        return set(self.values())\n    def inv(self, inst):\n        \"\"\"map from Notochord instrument: MIDI channel\"\"\"\n        if not self.invertible:\n            print('WARNING: MIDIConfig is not invertible')\n        for chan,inst_ in self.items():\n            if inst_==inst:\n                return chan\n        raise KeyError(f\"\"\"\n            instrument {inst} has no channel\n            \"\"\")\n</code></pre>"},{"location":"reference/notochord/perform/#notochord.perform.MIDIConfig.channels","title":"<code>channels</code>  <code>property</code>","text":"<p>set of channels</p>"},{"location":"reference/notochord/perform/#notochord.perform.MIDIConfig.insts","title":"<code>insts</code>  <code>property</code>","text":"<p>set of instruments</p>"},{"location":"reference/notochord/perform/#notochord.perform.MIDIConfig.inv","title":"<code>inv(inst)</code>","text":"<p>map from Notochord instrument: MIDI channel</p> Source code in <code>src/notochord/perform.py</code> <pre><code>def inv(self, inst):\n    \"\"\"map from Notochord instrument: MIDI channel\"\"\"\n    if not self.invertible:\n        print('WARNING: MIDIConfig is not invertible')\n    for chan,inst_ in self.items():\n        if inst_==inst:\n            return chan\n    raise KeyError(f\"\"\"\n        instrument {inst} has no channel\n        \"\"\")\n</code></pre>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance","title":"<code>NotoPerformance</code>","text":"<p>track various quantities of a Notochord performance:</p> event history <ul> <li>wall time</li> <li>nominal dt</li> <li>pitch</li> <li>velocity (0 for noteoff)</li> <li>notochord instrument</li> </ul> query for <ul> <li>instruments present in the last N events</li> <li>number of note_ons by instrument in last N events</li> <li>currently playing notes with user data as {(inst, pitch): Any}</li> <li>currently playing notes as {inst: pitches}</li> </ul> Source code in <code>src/notochord/perform.py</code> <pre><code>class NotoPerformance:\n    \"\"\"\n    track various quantities of a Notochord performance:\n\n    event history:\n        * wall time\n        * nominal dt\n        * pitch\n        * velocity (0 for noteoff)\n        * notochord instrument\n\n    query for:\n        * instruments present in the last N events\n        * number of note_ons by instrument in last N events\n        * currently playing notes with user data as {(inst, pitch): Any}\n        * currently playing notes as {inst: pitches}\n    \"\"\"\n    def __init__(self):\n        self.init()\n        self._notes:Dict[Tuple[int,int,int], Any] = {} \n        self.past_segments:List[pd.DataFrame] = []\n\n    def init(self):\n        self.events = pd.DataFrame(np.array([],dtype=[\n            ('wall_time_ns',np.int64), # actual wall time played in ns\n            ('time',np.float32), # nominal notochord dt in seconds\n            ('inst',np.int16), # notochord instrument\n            ('pitch',np.int16), # MIDI pitch\n            ('vel',np.int8), # MIDI velocity\n            ('channel',np.int8), # MIDI channel\n            ]))\n\n    def push(self):\n        \"\"\"push current events onto a list of past segments,\n            start a fresh history\n        \"\"\"\n        self.past_segments.append(self.events)\n        self.init()\n\n    def feed(self, held_note_data:Any=None, **event):\n        \"\"\"\n        Args:\n            held_note_data: any Python object to be attached to held notes\n                (ignored for note-offs)\n            ('wall_time_ns',np.int64), # actual wall time played in ns\n            ('time',np.float32), # nominal notochord dt in seconds\n            ('inst',np.int16), # notochord instrument\n            ('pitch',np.int16), # MIDI pitch\n            ('vel',np.int8), # MIDI velocity\n            ('channel',np.int8), # MIDI channel\n        \"\"\"\n        if 'wall_time_ns' not in event:\n            event['wall_time_ns'] = time.time_ns()\n        if 'channel' not in event:\n            # use -1 for missing channel to avoid coercion to float\n            event['channel'] = -1 \n        cast_event = {}\n        for k,v in event.items():\n            if k in self.events.columns:\n                cast_event[k] = self.events.dtypes[k].type(v)\n        event = cast_event\n\n        self.events.loc[len(self.events)] = event\n\n        chan = event.get('channel', None)\n        # inst, pitch, vel = event['inst'], event['pitch'], event['vel']\n        # k = (chan, inst, pitch)\n        vel = event['vel']\n        k = Note(chan, event['inst'], event['pitch'])\n\n        if vel &gt; 0:\n            self._notes[k] = held_note_data\n        else:\n            self._notes.pop(k, None)\n\n    def inst_counts(self, n=0, insts=None):\n        \"\"\"instrument counts in last n (default all) note_ons\"\"\"\n        df = self.events\n        df = df.iloc[-min(128,n*16):] # in case of very long history\n        df = df.loc[df.vel &gt; 0]\n        df = df.iloc[-n:]\n        counts = df.inst.value_counts()\n        if insts is not None:\n            for inst in insts:\n                if inst not in counts.index:\n                    counts[inst] = 0\n        return counts\n\n    def held_inst_pitch_map(self, insts=None):\n        \"\"\"held notes as {inst:[pitch]} for given instruments\"\"\"\n        note_map = defaultdict(list)\n        for note in self._notes:\n            if insts is None or note.inst in insts:\n                note_map[note.inst].append(note.pitch)\n        return note_map\n\n    @property\n    def note_pairs(self):\n        \"\"\"\n        held notes as {(inst,pitch)}.\n        returns a new `set`; safe to modify history while iterating\n        \"\"\"\n        return {(note.inst, note.pitch) for note in self._notes}\n\n    @property\n    def note_triples(self):\n        \"\"\"\n        held notes as {(channel,inst,pitch)}.\n        returns a new `set`; safe to modify history while iterating\n        \"\"\"\n        return {(note.chan, note.inst, note.pitch) for note in self._notes}\n\n    @property\n    def notes(self):\n        \"\"\"\n        generic way to access notes, returns set of namedtuples \n        returns a new `set`; safe to modify history while iterating\n        \"\"\"\n        return set(self._notes)\n\n    @property\n    def note_data(self):\n        \"\"\"held notes as {(chan,inst,pitch):held_note_data}.\n        mutable.\n        \"\"\"\n        # NOTE: returned dictionary should be mutable\n        return self._notes\n</code></pre>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.note_data","title":"<code>note_data</code>  <code>property</code>","text":"<p>held notes as {(chan,inst,pitch):held_note_data}. mutable.</p>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.note_pairs","title":"<code>note_pairs</code>  <code>property</code>","text":"<p>held notes as {(inst,pitch)}. returns a new <code>set</code>; safe to modify history while iterating</p>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.note_triples","title":"<code>note_triples</code>  <code>property</code>","text":"<p>held notes as {(channel,inst,pitch)}. returns a new <code>set</code>; safe to modify history while iterating</p>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.notes","title":"<code>notes</code>  <code>property</code>","text":"<p>generic way to access notes, returns set of namedtuples  returns a new <code>set</code>; safe to modify history while iterating</p>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.feed","title":"<code>feed(held_note_data=None, **event)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>held_note_data</code> <code>Any</code> <p>any Python object to be attached to held notes (ignored for note-offs)</p> <code>None</code> Source code in <code>src/notochord/perform.py</code> <pre><code>def feed(self, held_note_data:Any=None, **event):\n    \"\"\"\n    Args:\n        held_note_data: any Python object to be attached to held notes\n            (ignored for note-offs)\n        ('wall_time_ns',np.int64), # actual wall time played in ns\n        ('time',np.float32), # nominal notochord dt in seconds\n        ('inst',np.int16), # notochord instrument\n        ('pitch',np.int16), # MIDI pitch\n        ('vel',np.int8), # MIDI velocity\n        ('channel',np.int8), # MIDI channel\n    \"\"\"\n    if 'wall_time_ns' not in event:\n        event['wall_time_ns'] = time.time_ns()\n    if 'channel' not in event:\n        # use -1 for missing channel to avoid coercion to float\n        event['channel'] = -1 \n    cast_event = {}\n    for k,v in event.items():\n        if k in self.events.columns:\n            cast_event[k] = self.events.dtypes[k].type(v)\n    event = cast_event\n\n    self.events.loc[len(self.events)] = event\n\n    chan = event.get('channel', None)\n    # inst, pitch, vel = event['inst'], event['pitch'], event['vel']\n    # k = (chan, inst, pitch)\n    vel = event['vel']\n    k = Note(chan, event['inst'], event['pitch'])\n\n    if vel &gt; 0:\n        self._notes[k] = held_note_data\n    else:\n        self._notes.pop(k, None)\n</code></pre>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.held_inst_pitch_map","title":"<code>held_inst_pitch_map(insts=None)</code>","text":"<p>held notes as {inst:[pitch]} for given instruments</p> Source code in <code>src/notochord/perform.py</code> <pre><code>def held_inst_pitch_map(self, insts=None):\n    \"\"\"held notes as {inst:[pitch]} for given instruments\"\"\"\n    note_map = defaultdict(list)\n    for note in self._notes:\n        if insts is None or note.inst in insts:\n            note_map[note.inst].append(note.pitch)\n    return note_map\n</code></pre>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.inst_counts","title":"<code>inst_counts(n=0, insts=None)</code>","text":"<p>instrument counts in last n (default all) note_ons</p> Source code in <code>src/notochord/perform.py</code> <pre><code>def inst_counts(self, n=0, insts=None):\n    \"\"\"instrument counts in last n (default all) note_ons\"\"\"\n    df = self.events\n    df = df.iloc[-min(128,n*16):] # in case of very long history\n    df = df.loc[df.vel &gt; 0]\n    df = df.iloc[-n:]\n    counts = df.inst.value_counts()\n    if insts is not None:\n        for inst in insts:\n            if inst not in counts.index:\n                counts[inst] = 0\n    return counts\n</code></pre>"},{"location":"reference/notochord/perform/#notochord.perform.NotoPerformance.push","title":"<code>push()</code>","text":"<p>push current events onto a list of past segments, start a fresh history</p> Source code in <code>src/notochord/perform.py</code> <pre><code>def push(self):\n    \"\"\"push current events onto a list of past segments,\n        start a fresh history\n    \"\"\"\n    self.past_segments.append(self.events)\n    self.init()\n</code></pre>"},{"location":"reference/notochord/rnn/","title":"Rnn","text":""},{"location":"reference/notochord/rnn/#notochord.rnn.GenericRNN","title":"<code>GenericRNN</code>","text":"<p>             Bases: <code>Module</code></p> Source code in <code>src/notochord/rnn.py</code> <pre><code>class GenericRNN(nn.Module):\n    kind_cls = {\n        'gru':GRU,\n        'lstm':LSTM,\n        'elman':RNN,\n        'exprnn':ExpRNN\n        }\n    def __init__(self, kind, *a, **kw):\n        super().__init__()\n        if kw.get('bidirectional'): raise ValueError(\"\"\"\n            bidirectional GenericRNN not supported.\n            \"\"\")\n        cls = GenericRNN.kind_cls[kind]\n        self.kind = kind\n        self.rnn = cls(*a, **kw)\n\n    def __getattr__(self, a):\n        try:\n            return  super().__getattr__(a)\n        except AttributeError:\n            return getattr(self.rnn, a)\n\n    def forward(self, x, initial_state):\n        \"\"\"\n        Args:\n            x: Tensor[batch x time x channel] if batch_first else [time x batch x channel]\n            initial_state: List[Tensor[layers x batch x hidden]]], list of components \n            with 0 being hidden state (e.g. 1 is cell state for LSTM). \n        Returns:\n            hidden: hidden states of top layers Tensor[batch x time x hidden]\n                or [time x batch x hidden]\n            new_states: List[Tensor[layers x batch x hidden]]\n        \"\"\"\n        hidden, final_state = self.rnn.forward(x, initial_state)  #forward or __call__?\n        return hidden, final_state\n</code></pre>"},{"location":"reference/notochord/rnn/#notochord.rnn.GenericRNN.forward","title":"<code>forward(x, initial_state)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>x</code> <p>Tensor[batch x time x channel] if batch_first else [time x batch x channel]</p> required <code>initial_state</code> <p>List[Tensor[layers x batch x hidden]]], list of components </p> required <p>Returns:     hidden: hidden states of top layers Tensor[batch x time x hidden]         or [time x batch x hidden]     new_states: List[Tensor[layers x batch x hidden]]</p> Source code in <code>src/notochord/rnn.py</code> <pre><code>def forward(self, x, initial_state):\n    \"\"\"\n    Args:\n        x: Tensor[batch x time x channel] if batch_first else [time x batch x channel]\n        initial_state: List[Tensor[layers x batch x hidden]]], list of components \n        with 0 being hidden state (e.g. 1 is cell state for LSTM). \n    Returns:\n        hidden: hidden states of top layers Tensor[batch x time x hidden]\n            or [time x batch x hidden]\n        new_states: List[Tensor[layers x batch x hidden]]\n    \"\"\"\n    hidden, final_state = self.rnn.forward(x, initial_state)  #forward or __call__?\n    return hidden, final_state\n</code></pre>"},{"location":"reference/notochord/rnn/#notochord.rnn.rnn_shim","title":"<code>rnn_shim(cls)</code>","text":"<p>LSTM API for GRU and RNN.</p> <p>hidden state is first element of state tuple</p> Source code in <code>src/notochord/rnn.py</code> <pre><code>def rnn_shim(cls):\n    \"\"\"LSTM API for GRU and RNN.\n\n    hidden state is first element of state tuple\"\"\"\n    class shim(cls):\n        def forward(self, input, states=(None,)):\n            assert len(states)==1\n            out, h = super().forward(input, *states)\n            return out, (h,)\n    return shim\n</code></pre>"},{"location":"reference/notochord/train/","title":"Train","text":""},{"location":"reference/notochord/train/#notochord.train.Resumable","title":"<code>Resumable</code>","text":"Source code in <code>src/notochord/train.py</code> <pre><code>class Resumable:\n    def __init__(self, checkpoint=None, resume=True, **kw):\n        \"\"\"\n        Args:\n            checkpoint: path to training checkpoint file\n            resume: if True, retore optimizer states etc\n                otherwise, restore only model weights (for transfer learning)\n        \"\"\"\n        if checkpoint is not None:\n            d = torch.load(checkpoint, map_location=torch.device('cpu'))\n            print(f'loaded checkpoint {checkpoint}')\n            if d['kw'].get('batch_len_schedule') is not None: print(\"\"\"\n            warning: checkpoints don't track `batch_len`. \n            be sure to manually set batch_len if resuming a run \n            using `batch_len_schedule`\n            \"\"\")\n            # merges sub dicts, e.g. model hyperparameters\n            deep_update(d['kw'], kw)\n            self._trainer = Trainer(**d['kw'])\n            self._trainer.load_state(d, resume=resume)\n        else:\n            self._trainer = Trainer(**kw)\n\n    def train(self):\n        self._trainer.train()\n\n    def test(self):\n        self._trainer.test()\n</code></pre>"},{"location":"reference/notochord/train/#notochord.train.Resumable.__init__","title":"<code>__init__(checkpoint=None, resume=True, **kw)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>path to training checkpoint file</p> <code>None</code> <code>resume</code> <p>if True, retore optimizer states etc otherwise, restore only model weights (for transfer learning)</p> <code>True</code> Source code in <code>src/notochord/train.py</code> <pre><code>def __init__(self, checkpoint=None, resume=True, **kw):\n    \"\"\"\n    Args:\n        checkpoint: path to training checkpoint file\n        resume: if True, retore optimizer states etc\n            otherwise, restore only model weights (for transfer learning)\n    \"\"\"\n    if checkpoint is not None:\n        d = torch.load(checkpoint, map_location=torch.device('cpu'))\n        print(f'loaded checkpoint {checkpoint}')\n        if d['kw'].get('batch_len_schedule') is not None: print(\"\"\"\n        warning: checkpoints don't track `batch_len`. \n        be sure to manually set batch_len if resuming a run \n        using `batch_len_schedule`\n        \"\"\")\n        # merges sub dicts, e.g. model hyperparameters\n        deep_update(d['kw'], kw)\n        self._trainer = Trainer(**d['kw'])\n        self._trainer.load_state(d, resume=resume)\n    else:\n        self._trainer = Trainer(**kw)\n</code></pre>"},{"location":"reference/notochord/train/#notochord.train.Trainer","title":"<code>Trainer</code>","text":"Source code in <code>src/notochord/train.py</code> <pre><code>class Trainer:\n    def __init__(self, \n        experiment, # experiment name\n        model_dir,\n        log_dir,\n        data_dir,\n        results_dir,\n        model = None, # dict of model constructor overrides\n        batch_size = 128,\n        batch_len = 64,\n        batch_len_schedule = None,\n        batch_len_max = 512,\n        lr = 3e-4,\n        adam_betas = (0.9, 0.999),\n        adam_eps = 1e-08, \n        weight_decay = 0.01,\n        grad_clip = 1.0,\n        seed = 0, # random seed\n        n_jobs = 1, # for dataloaders\n        device = 'cpu', # 'cuda:0'\n        epoch_size = None, # in iterations, None for whole dataset\n        txala = False,\n        txala_remap = False,\n        txala_permute = False,\n        min_valid = 8,\n        min_test = 8,\n        aug_speed=0.1,\n        aug_transpose=5,\n        aug_remap=True\n        ):\n        \"\"\"TODO: Trainer __init__ docstring\"\"\"\n        kw = locals(); kw.pop('self')\n\n        # store all hyperparams for checkpointing\n        self.kw = kw\n\n        # get model defaults from model class\n        model_cls = Notochord\n        if model is None: model = {}\n        assert isinstance(model, dict), \"\"\"\n            model keywords are not a dict. check shell/fire syntax\n            \"\"\"\n        kw['model'] = model = get_class_defaults(model_cls) | model\n        model['num_pitches'] = 128\n        model['num_instruments'] = 320\n        # model['time_bounds'] = clamp_time\n\n        # assign all arguments to self by default\n        self.__dict__.update(kw)\n        # mutate some arguments:\n        self.model_dir = Path(model_dir) / self.experiment\n        self.log_dir = Path(log_dir) / self.experiment\n        self.results_dir = Path(results_dir) / self.experiment\n        self.data_dir = Path(data_dir)\n        self.device = torch.device(device)\n\n        # filesystem\n        for d in (self.model_dir, self.log_dir, self.results_dir):\n            d.mkdir(parents=True, exist_ok=True)\n\n        # random states\n        self.seed_random()\n\n        # logging\n        self.writer = SummaryWriter(self.log_dir)\n\n        # Trainer state\n        self.iteration = 0\n        self.exposure = 0\n        self.epoch = 0\n\n        # construct model from arguments \n        self.model = model_cls(**model).to(self.device)\n        tqdm.write(repr(self.model))\n\n        # dataset\n        if txala:\n            self.dataset = TxalaDataset(data_dir, self.batch_len, \n                remap=txala_remap, permute=txala_permute)\n        else:\n            self.dataset = MIDIDataset(data_dir, self.batch_len,\n                speed=aug_speed, transpose=aug_transpose, remap_instruments=aug_remap)\n\n        valid_len = max(min_valid, int(len(self.dataset)*0.03))\n        test_len = max(min_test, int(len(self.dataset)*0.02))\n        train_len = len(self.dataset) - valid_len - test_len\n        print(f'{valid_len=} {test_len=} {train_len=}')\n        self.train_dataset, self.valid_dataset, self.test_dataset = torch.utils.data.random_split(\n            self.dataset, [train_len, valid_len, test_len], \n            generator=torch.Generator().manual_seed(0))\n\n        # params = {k:v for k,v in self.model.named_parameters()}\n        # ks = ['projections.3.net.1.weight', 'projections.2.net.1.weight']\n        # slow_params = {k:params.pop(k) for k in ks}\n        # self.opt = torch.optim.AdamW([\n        #     {'params':params.values()},\n        #     {'params':slow_params.values(), 'lr':self.lr*1e-1}], \n        #     self.lr, self.adam_betas, self.adam_eps, self.weight_decay)\n        self.opt = torch.optim.AdamW(self.model.parameters(),\n            self.lr, self.adam_betas, self.adam_eps, self.weight_decay)\n\n    @property\n    def gpu(self):\n        return self.device.type!='cpu'\n\n    def seed_random(self):\n        random.seed(self.seed)\n        np.random.seed(self.seed)\n        torch.manual_seed(self.seed)\n\n    def set_random_state(self, states):\n        # note: GPU rng state not handled\n        std_state, np_state, torch_state = states\n        random.setstate(std_state)\n        np.random.set_state(np_state)\n        torch.set_rng_state(torch_state)\n\n    def save(self, fname):\n        torch.save(dict(\n            kw=self.kw,\n            model_state=self.model.state_dict(),\n            optimizer_state=self.opt.state_dict(),\n            step=(self.exposure, self.iteration, self.epoch),\n            random_state=(random.getstate(), np.random.get_state(), torch.get_rng_state())\n        ), fname)\n\n    def load_state(self, d, resume):\n        d = d if hasattr(d, '__getitem__') else torch.load(d)\n        self.model.load_state_dict(d['model_state'], strict=resume)\n        if resume:\n            print('loading optimizer state, RNG state, step counts')\n            print(\"\"\"\n            warning: optimizer lr, beta etc are restored with optimizer state,\n            even if different values given on the command line, when resume=True\n            \"\"\")\n            self.opt.load_state_dict(d['optimizer_state'])\n            self.exposure, self.iteration, self.epoch = d['step']\n            self.set_random_state(d['random_state'])\n        else:\n            print('fresh run transferring only model weights')\n\n    def log(self, tag, d):\n        # self.writer.add_scalars(tag, d, self.exposure)\n        for k,v in d.items():\n            self.writer.add_scalar(f'{tag}/{k}', v, self.exposure)\n\n    def process_grad(self):\n        r = {}\n        if self.grad_clip is not None:\n            r['grad_l2'] = torch.nn.utils.clip_grad_norm_(\n                self.model.parameters(), self.grad_clip, error_if_nonfinite=True)\n        return r\n\n    def get_loss_components(self, result, mask):\n        def reduce(k):\n            return result[k].masked_select(mask).mean()\n        return {\n            'instrument_nll': -reduce('instrument_log_probs'),\n            'pitch_nll': -reduce('pitch_log_probs'),\n            'time_nll': -reduce('time_log_probs'),\n            'velocity_nll': -reduce('velocity_log_probs'),\n            'end_nll': -reduce('end_log_probs'),\n        }\n\n    def _validate(self, valid_loader, ar_mask=None, testing=False):\n        \"\"\"\"\"\"\n        pops = defaultdict(list)\n        self.model.eval()\n        if testing:\n            self.dataset.testing = True\n        for batch in tqdm(valid_loader, desc=f'validating epoch {self.epoch}'):\n            # print(batch['mask'].shape, batch['mask'].sum())\n            mask = batch['mask'].to(self.device, non_blocking=True)[...,1:]\n            end = batch['end'].to(self.device, non_blocking=True)\n            inst = batch['instrument'].to(self.device, non_blocking=True)\n            pitch = batch['pitch'].to(self.device, non_blocking=True)\n            time = batch['time'].to(self.device, non_blocking=True)\n            vel = batch['velocity'].to(self.device, non_blocking=True)\n            with torch.no_grad():\n                result = self.model(\n                    inst, pitch, time, vel, end, \n                    validation=True, ar_mask=ar_mask)\n                losses = {k:v.item() for k,v in self.get_loss_components(\n                    result, mask).items()}\n                for k,v in losses.items():\n                    pops[k].append(v)\n                pops['loss'].append(sum(losses.values()))\n                pops['instrument_acc'].append(result['instrument_log_probs']\n                    .masked_select(mask).exp().mean().item())\n                pops['pitch_acc'].append(result['pitch_log_probs']\n                    .masked_select(mask).exp().mean().item())\n                pops['time_acc_30ms'].append(result['time_acc_30ms']\n                    .masked_select(mask).mean().item())\n                pops['velocity_acc'].append(result['velocity_log_probs']\n                    .masked_select(mask).exp().mean().item())\n        return {\n            'logs':{k:np.mean(v) for k,v in pops.items()},\n            # 'bootstraps':{\n            #     k:scipy.stats.bootstrap((v,), np.mean).confidence_interval \n            #     for k,v in pops.items()},\n            'pops':pops\n        }\n\n\n    def test(self):\n        \"\"\"Entry point to testing\"\"\"\n        # TODO: should make a test split before doing serious\n        # model comparison.\n        # ds = torch.utils.data.Subset(self.valid_dataset, [0,1,2])\n        ds = self.test_dataset\n        loader = DataLoader(\n            ds, 1,#self.batch_size,\n            shuffle=False, num_workers=self.n_jobs if self.gpu else 0, pin_memory=self.gpu)\n\n        results = []\n        for perm, mask in gen_masks(self.model.note_dim):\n            # TODO: bootstrap CI. need to return all likelihoods, not mean, from _validate\n            r = self._validate(\n                loader, ar_mask=mask.to(self.device, non_blocking=True),\n                testing=True)\n            # print(r['bootstraps'])\n            perm = [['instrument', 'pitch', 'time', 'velocity'][i] for i in perm]\n            results.append((perm, r['pops']))\n        torch.save(results, self.results_dir / f'result-{self.epoch:04d}.pt')\n\n    def train(self):\n        \"\"\"Entry point to model training\"\"\"\n        self.save(self.model_dir / f'{self.epoch:04d}.ckpt')\n\n        train_loader = DataLoader(\n            self.train_dataset, self.batch_size,\n            shuffle=True, num_workers=self.n_jobs, pin_memory=self.gpu)\n\n        valid_loader = DataLoader(\n            self.valid_dataset, self.batch_size,#//4,\n            shuffle=False, num_workers=self.n_jobs, pin_memory=self.gpu,\n            sampler=RandomSampler(\n                self.valid_dataset, \n                num_samples=self.batch_size, replacement=True))\n\n        ##### validation loop\n        def run_validation():\n            self.dataset.batch_len = self.dataset.max_test_len\n            logs = self._validate(valid_loader, testing=False)['logs']\n            self.log('valid', logs)\n\n        epoch_size = self.epoch_size or len(train_loader)\n\n        # validate at initialization\n        run_validation()\n\n        while True:\n            self.epoch += 1\n\n            ##### training loop\n            self.model.train()\n            self.dataset.testing = False\n            self.dataset.batch_len = self.batch_len\n            for batch in tqdm(\n                # itertools incantation to support epoch_size larger than train set\n                it.islice(\n                    it.chain.from_iterable(it.repeat(train_loader)), epoch_size), \n                desc=f'training epoch {self.epoch}', total=epoch_size\n                ):\n                mask = batch['mask'].to(self.device, non_blocking=True)\n                end = batch['end'].to(self.device, non_blocking=True)\n                inst = batch['instrument'].to(self.device, non_blocking=True)\n                pitch = batch['pitch'].to(self.device, non_blocking=True)\n                time = batch['time'].to(self.device, non_blocking=True)\n                vel = batch['velocity'].to(self.device, non_blocking=True)\n\n                self.iteration += 1\n                # TODO: use mask instead of batch dims\n                self.exposure += self.batch_size * self.batch_len\n                logs = {}\n\n                ### forward+backward+optimizer step ###\n                self.opt.zero_grad()\n                result = self.model(inst, pitch, time, vel, end)\n                losses = self.get_loss_components(result, mask[...,1:])\n                loss = sum(losses.values())\n                loss.backward()\n                logs |= self.process_grad()\n                self.opt.step()\n                ########\n\n                # log loss components\n                logs |= {k:v.item() for k,v in losses.items()}\n                # log total loss\n                logs |= {'loss':loss.item()}\n                # log any other returned scalars\n                logs |= {k:v.item() for k,v in result.items() if v.numel()==1}\n                self.log('train', logs)\n\n            run_validation()\n\n            if self.batch_len_schedule is not None:\n                self.batch_len = min(\n                    self.batch_len_max, self.batch_len+self.batch_len_schedule)\n                self.dataset.batch_len = self.batch_len\n\n            self.save(self.model_dir / f'{self.epoch:04d}.ckpt')\n</code></pre>"},{"location":"reference/notochord/train/#notochord.train.Trainer.__init__","title":"<code>__init__(experiment, model_dir, log_dir, data_dir, results_dir, model=None, batch_size=128, batch_len=64, batch_len_schedule=None, batch_len_max=512, lr=0.0003, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.01, grad_clip=1.0, seed=0, n_jobs=1, device='cpu', epoch_size=None, txala=False, txala_remap=False, txala_permute=False, min_valid=8, min_test=8, aug_speed=0.1, aug_transpose=5, aug_remap=True)</code>","text":"<p>TODO: Trainer init docstring</p> Source code in <code>src/notochord/train.py</code> <pre><code>def __init__(self, \n    experiment, # experiment name\n    model_dir,\n    log_dir,\n    data_dir,\n    results_dir,\n    model = None, # dict of model constructor overrides\n    batch_size = 128,\n    batch_len = 64,\n    batch_len_schedule = None,\n    batch_len_max = 512,\n    lr = 3e-4,\n    adam_betas = (0.9, 0.999),\n    adam_eps = 1e-08, \n    weight_decay = 0.01,\n    grad_clip = 1.0,\n    seed = 0, # random seed\n    n_jobs = 1, # for dataloaders\n    device = 'cpu', # 'cuda:0'\n    epoch_size = None, # in iterations, None for whole dataset\n    txala = False,\n    txala_remap = False,\n    txala_permute = False,\n    min_valid = 8,\n    min_test = 8,\n    aug_speed=0.1,\n    aug_transpose=5,\n    aug_remap=True\n    ):\n    \"\"\"TODO: Trainer __init__ docstring\"\"\"\n    kw = locals(); kw.pop('self')\n\n    # store all hyperparams for checkpointing\n    self.kw = kw\n\n    # get model defaults from model class\n    model_cls = Notochord\n    if model is None: model = {}\n    assert isinstance(model, dict), \"\"\"\n        model keywords are not a dict. check shell/fire syntax\n        \"\"\"\n    kw['model'] = model = get_class_defaults(model_cls) | model\n    model['num_pitches'] = 128\n    model['num_instruments'] = 320\n    # model['time_bounds'] = clamp_time\n\n    # assign all arguments to self by default\n    self.__dict__.update(kw)\n    # mutate some arguments:\n    self.model_dir = Path(model_dir) / self.experiment\n    self.log_dir = Path(log_dir) / self.experiment\n    self.results_dir = Path(results_dir) / self.experiment\n    self.data_dir = Path(data_dir)\n    self.device = torch.device(device)\n\n    # filesystem\n    for d in (self.model_dir, self.log_dir, self.results_dir):\n        d.mkdir(parents=True, exist_ok=True)\n\n    # random states\n    self.seed_random()\n\n    # logging\n    self.writer = SummaryWriter(self.log_dir)\n\n    # Trainer state\n    self.iteration = 0\n    self.exposure = 0\n    self.epoch = 0\n\n    # construct model from arguments \n    self.model = model_cls(**model).to(self.device)\n    tqdm.write(repr(self.model))\n\n    # dataset\n    if txala:\n        self.dataset = TxalaDataset(data_dir, self.batch_len, \n            remap=txala_remap, permute=txala_permute)\n    else:\n        self.dataset = MIDIDataset(data_dir, self.batch_len,\n            speed=aug_speed, transpose=aug_transpose, remap_instruments=aug_remap)\n\n    valid_len = max(min_valid, int(len(self.dataset)*0.03))\n    test_len = max(min_test, int(len(self.dataset)*0.02))\n    train_len = len(self.dataset) - valid_len - test_len\n    print(f'{valid_len=} {test_len=} {train_len=}')\n    self.train_dataset, self.valid_dataset, self.test_dataset = torch.utils.data.random_split(\n        self.dataset, [train_len, valid_len, test_len], \n        generator=torch.Generator().manual_seed(0))\n\n    # params = {k:v for k,v in self.model.named_parameters()}\n    # ks = ['projections.3.net.1.weight', 'projections.2.net.1.weight']\n    # slow_params = {k:params.pop(k) for k in ks}\n    # self.opt = torch.optim.AdamW([\n    #     {'params':params.values()},\n    #     {'params':slow_params.values(), 'lr':self.lr*1e-1}], \n    #     self.lr, self.adam_betas, self.adam_eps, self.weight_decay)\n    self.opt = torch.optim.AdamW(self.model.parameters(),\n        self.lr, self.adam_betas, self.adam_eps, self.weight_decay)\n</code></pre>"},{"location":"reference/notochord/train/#notochord.train.Trainer.test","title":"<code>test()</code>","text":"<p>Entry point to testing</p> Source code in <code>src/notochord/train.py</code> <pre><code>def test(self):\n    \"\"\"Entry point to testing\"\"\"\n    # TODO: should make a test split before doing serious\n    # model comparison.\n    # ds = torch.utils.data.Subset(self.valid_dataset, [0,1,2])\n    ds = self.test_dataset\n    loader = DataLoader(\n        ds, 1,#self.batch_size,\n        shuffle=False, num_workers=self.n_jobs if self.gpu else 0, pin_memory=self.gpu)\n\n    results = []\n    for perm, mask in gen_masks(self.model.note_dim):\n        # TODO: bootstrap CI. need to return all likelihoods, not mean, from _validate\n        r = self._validate(\n            loader, ar_mask=mask.to(self.device, non_blocking=True),\n            testing=True)\n        # print(r['bootstraps'])\n        perm = [['instrument', 'pitch', 'time', 'velocity'][i] for i in perm]\n        results.append((perm, r['pops']))\n    torch.save(results, self.results_dir / f'result-{self.epoch:04d}.pt')\n</code></pre>"},{"location":"reference/notochord/train/#notochord.train.Trainer.train","title":"<code>train()</code>","text":"<p>Entry point to model training</p> Source code in <code>src/notochord/train.py</code> <pre><code>def train(self):\n    \"\"\"Entry point to model training\"\"\"\n    self.save(self.model_dir / f'{self.epoch:04d}.ckpt')\n\n    train_loader = DataLoader(\n        self.train_dataset, self.batch_size,\n        shuffle=True, num_workers=self.n_jobs, pin_memory=self.gpu)\n\n    valid_loader = DataLoader(\n        self.valid_dataset, self.batch_size,#//4,\n        shuffle=False, num_workers=self.n_jobs, pin_memory=self.gpu,\n        sampler=RandomSampler(\n            self.valid_dataset, \n            num_samples=self.batch_size, replacement=True))\n\n    ##### validation loop\n    def run_validation():\n        self.dataset.batch_len = self.dataset.max_test_len\n        logs = self._validate(valid_loader, testing=False)['logs']\n        self.log('valid', logs)\n\n    epoch_size = self.epoch_size or len(train_loader)\n\n    # validate at initialization\n    run_validation()\n\n    while True:\n        self.epoch += 1\n\n        ##### training loop\n        self.model.train()\n        self.dataset.testing = False\n        self.dataset.batch_len = self.batch_len\n        for batch in tqdm(\n            # itertools incantation to support epoch_size larger than train set\n            it.islice(\n                it.chain.from_iterable(it.repeat(train_loader)), epoch_size), \n            desc=f'training epoch {self.epoch}', total=epoch_size\n            ):\n            mask = batch['mask'].to(self.device, non_blocking=True)\n            end = batch['end'].to(self.device, non_blocking=True)\n            inst = batch['instrument'].to(self.device, non_blocking=True)\n            pitch = batch['pitch'].to(self.device, non_blocking=True)\n            time = batch['time'].to(self.device, non_blocking=True)\n            vel = batch['velocity'].to(self.device, non_blocking=True)\n\n            self.iteration += 1\n            # TODO: use mask instead of batch dims\n            self.exposure += self.batch_size * self.batch_len\n            logs = {}\n\n            ### forward+backward+optimizer step ###\n            self.opt.zero_grad()\n            result = self.model(inst, pitch, time, vel, end)\n            losses = self.get_loss_components(result, mask[...,1:])\n            loss = sum(losses.values())\n            loss.backward()\n            logs |= self.process_grad()\n            self.opt.step()\n            ########\n\n            # log loss components\n            logs |= {k:v.item() for k,v in losses.items()}\n            # log total loss\n            logs |= {'loss':loss.item()}\n            # log any other returned scalars\n            logs |= {k:v.item() for k,v in result.items() if v.numel()==1}\n            self.log('train', logs)\n\n        run_validation()\n\n        if self.batch_len_schedule is not None:\n            self.batch_len = min(\n                self.batch_len_max, self.batch_len+self.batch_len_schedule)\n            self.dataset.batch_len = self.batch_len\n\n        self.save(self.model_dir / f'{self.epoch:04d}.ckpt')\n</code></pre>"},{"location":"reference/notochord/util/","title":"Util","text":""},{"location":"reference/notochord/util/#notochord.util.arg_to_set","title":"<code>arg_to_set(x)</code>","text":"<p>convert None to empty set, iterable to set, or scalar to set with one item</p> Source code in <code>src/notochord/util.py</code> <pre><code>def arg_to_set(x):\n    \"\"\"convert None to empty set, iterable to set, or scalar to set with one item\"\"\"\n    if x is None:\n        return set()\n    elif not hasattr(x, '__iter__'):\n        return {x}\n    else:\n        return set(x)\n</code></pre>"},{"location":"reference/notochord/util/#notochord.util.deep_update","title":"<code>deep_update(a, b)</code>","text":"<p>in-place update a with contents of b, recursively for nested Mapping objects.</p> Source code in <code>src/notochord/util.py</code> <pre><code>def deep_update(a, b):\n    \"\"\"\n    in-place update a with contents of b, recursively for nested Mapping objects.\n    \"\"\"\n    for k in b:\n        if k in a and isinstance(a[k], Mapping) and isinstance(b[k], Mapping):\n            deep_update(a[k], b[k])\n        else:\n            a[k] = b[k]\n</code></pre>"},{"location":"reference/notochord/util/#notochord.util.gen_masks","title":"<code>gen_masks(n, dtype=torch.float)</code>","text":"<p>yield the autoregressive mask matrices of all permuations of n items</p> Source code in <code>src/notochord/util.py</code> <pre><code>def gen_masks(n, dtype=torch.float):\n    \"\"\"yield the autoregressive mask matrices of all permuations of n items\"\"\"\n    for perm in gen_perms(list(range(n))):\n        m = torch.zeros(n,n,dtype=dtype)\n        for idx,i in enumerate(perm):\n            for j in perm[:idx]:\n                m[j,i] = 1\n        yield perm, m\n</code></pre>"},{"location":"reference/notochord/util/#notochord.util.gen_perms","title":"<code>gen_perms(a)</code>","text":"<p>yield all permutations of the given list</p> Source code in <code>src/notochord/util.py</code> <pre><code>def gen_perms(a):\n    \"\"\"yield all permutations of the given list\"\"\"\n    if len(a)==1:\n        yield a\n    else:\n        # for each position\n        for i in range(len(a)):\n            # for permuations of remaining positions\n            for p in gen_perms(a[:i]+a[i+1:]):  \n                yield a[i:i+1]+p \n</code></pre>"},{"location":"reference/notochord/util/#notochord.util.get_class_defaults","title":"<code>get_class_defaults(cls)</code>","text":"<p>get the default argument values of a class constructor</p> Source code in <code>src/notochord/util.py</code> <pre><code>def get_class_defaults(cls):\n    \"\"\"get the default argument values of a class constructor\"\"\"\n    d = get_function_defaults(getattr(cls, '__init__'))\n    # ignore `self` argument, insist on default values\n    try:\n        d.pop('self')\n    except KeyError:\n        raise ValueError(\"\"\"\n            no `self` argument found in class __init__\n        \"\"\")\n    assert [v is not inspect._empty for v in d.values()], \"\"\"\n            get_class_defaults should be used on constructors with keyword arguments only.\n        \"\"\"\n    return d\n</code></pre>"},{"location":"reference/notochord/util/#notochord.util.get_function_defaults","title":"<code>get_function_defaults(fn)</code>","text":"<p>get dict of name:default for a function's arguments</p> Source code in <code>src/notochord/util.py</code> <pre><code>def get_function_defaults(fn):\n    \"\"\"get dict of name:default for a function's arguments\"\"\"\n    s = inspect.signature(fn)\n    return {k:v.default for k,v in s.parameters.items()}\n</code></pre>"},{"location":"reference/notochord/app/__init__/","title":"init","text":""},{"location":"reference/notochord/app/harmonizer/","title":"Harmonizer","text":"<p>Notochord MIDI harmonizer server. Each note from the player produces a harmonizing note from Notochord.</p> Authors <p>Victor Shepardson Intelligent Instruments Lab 2023</p>"},{"location":"reference/notochord/app/harmonizer/#notochord.app.harmonizer.NotoTUI","title":"<code>NotoTUI</code>","text":"<p>             Bases: <code>TUI</code></p> Source code in <code>src/notochord/app/harmonizer.py</code> <pre><code>class NotoTUI(TUI):\n    CSS_PATH = 'harmonizer.css'\n\n    BINDINGS = [\n        (\"m\", \"mute\", \"Mute Notochord\"),\n        (\"r\", \"reset\", \"Reset Notochord\")]\n\n    def compose(self):\n        \"\"\"Create child widgets for the app.\"\"\"\n        yield Header()\n        yield self.std_log\n        yield NotoLog(id='note')\n        yield NotoControl()\n        yield Footer()\n</code></pre>"},{"location":"reference/notochord/app/harmonizer/#notochord.app.harmonizer.NotoTUI.compose","title":"<code>compose()</code>","text":"<p>Create child widgets for the app.</p> Source code in <code>src/notochord/app/harmonizer.py</code> <pre><code>def compose(self):\n    \"\"\"Create child widgets for the app.\"\"\"\n    yield Header()\n    yield self.std_log\n    yield NotoLog(id='note')\n    yield NotoControl()\n    yield Footer()\n</code></pre>"},{"location":"reference/notochord/app/harmonizer/#notochord.app.harmonizer.main","title":"<code>main(checkpoint='notochord-latest.ckpt', player_channel=1, player_inst=1, noto_config=None, noto_channel=2, noto_inst=1, below=False, above=True, midi_in=None, midi_out=None, thru=False, send_pc=False, use_tui=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>path to notochord model checkpoint.</p> <code>'notochord-latest.ckpt'</code> <code>player_channel</code> <p>MIDI channels for player input.</p> <code>1</code> <code>player_inst</code> <p>Notochord instrument for the player.</p> <code>1</code> <code>noto_config</code> <code>Optional[List[Tuple[int, int, int, int]]]</code> <p>list voices played by Notochord. Each voice is a tuple of: ( MIDI channel indexed from 1, General MIDI instrument from 1, minimum transpose from the performed pitch, maximum transpose ). For example, [(2,1,-12,0), (3,13,0,12)] would play the grand piano on channel 2 in the octave below, and the marimba on channel 3 in the octave above. see https://en.wikipedia.org/wiki/General_MIDI for instrument numbers.</p> <code>None</code> <code>noto_channel</code> <p>alternative to using noto_config for a single voice</p> <code>2</code> <code>noto_inst</code> <p>alternative to using noto_config for a single voice</p> <code>1</code> <code>below</code> <p>alternative to using noto_config for a single voice -- allows harmonizing notes below the performed pitch</p> <code>False</code> <code>above</code> <p>alternative to using noto_config for a single voice -- allows harmonizing notes above the performed pitch</p> <code>True</code> <code>midi_in</code> <code>Optional[str]</code> <p>MIDI ports for player input.  default is to use all input ports. can be comma-separated list of ports.</p> <code>None</code> <code>midi_out</code> <code>Optional[str]</code> <p>MIDI ports for Notochord output.  default is to use only virtual 'From iipyper' port. can be comma-separated list of ports.</p> <code>None</code> <code>thru</code> <p>if True, copy incoming MIDI to output ports. only makes sense if input and output ports are different.</p> <code>False</code> <code>send_pc</code> <p>if True, send MIDI program change messages to set the General MIDI instrument according to player_inst, player_channel and noto_config. useful when using a General MIDI synthesizer like fluidsynth.</p> <code>False</code> <code>use_tui</code> <p>run textual UI.</p> <code>True</code> Source code in <code>src/notochord/app/harmonizer.py</code> <pre><code>def main(\n    checkpoint=\"notochord-latest.ckpt\", # Notochord checkpoint\n\n    player_channel=1, # MIDI channel numbered from 0\n    player_inst=1, # General MIDI numbered from 1 (see Notochord.feed docstring)\n    noto_config:Optional[List[Tuple[int,int,int,int]]]=None, # list of tuples of (channel, instrument, min transpose, max transpose)\n    noto_channel=2, # channel for single notochord voice (overriden by noto_config)\n    noto_inst=1, # instrument for single notochord voice (overridden by noto_config)\n    below=False, # harmonize above (overridden by noto_config)\n    above=True, # harmonize below (overridden by noto_config)\n\n    midi_in:Optional[str]=None, # MIDI port(s) for player input\n    midi_out:Optional[str]=None, # MIDI port(s) for Notochord output\n    thru=False, # copy player input to output\n    send_pc=False, # send program change messages to match player and noto_config (useful if using a General MIDI synth like fluidsynth or hardware)\n\n    use_tui=True,\n    ):\n    \"\"\"\n    Args:\n        checkpoint: path to notochord model checkpoint.\n\n        player_channel: MIDI channels for player input.\n        player_inst: Notochord instrument for the player.\n        noto_config: list voices played by Notochord. Each voice is a tuple of: (\n            MIDI channel indexed from 1,\n            General MIDI instrument from 1,\n            minimum transpose from the performed pitch,\n            maximum transpose\n            ).\n            For example, [(2,1,-12,0), (3,13,0,12)] would play the grand piano on channel 2 in the octave below, and the marimba on channel 3 in the octave above.\n            see https://en.wikipedia.org/wiki/General_MIDI for instrument numbers.\n        noto_channel: alternative to using noto_config for a single voice\n        noto_inst: alternative to using noto_config for a single voice\n        below: alternative to using noto_config for a single voice -- allows\n            harmonizing notes below the performed pitch\n        above: alternative to using noto_config for a single voice -- allows\n            harmonizing notes above the performed pitch\n\n        midi_in: MIDI ports for player input. \n            default is to use all input ports.\n            can be comma-separated list of ports.\n        midi_out: MIDI ports for Notochord output. \n            default is to use only virtual 'From iipyper' port.\n            can be comma-separated list of ports.\n        thru: if True, copy incoming MIDI to output ports.\n            only makes sense if input and output ports are different.\n        send_pc: if True, send MIDI program change messages to set the General MIDI\n            instrument according to player_inst, player_channel and noto_config.\n            useful when using a General MIDI synthesizer like fluidsynth.\n\n        use_tui: run textual UI.\n    \"\"\"\n        # nominal_time: if True, feed Notochord with its own predicted times\n        #     instead of the actual elapsed time.\n        #     May make Notochord more likely to play chords.\n    midi = MIDI(midi_in, midi_out)\n\n    ### Textual UI\n    tui = NotoTUI()\n    print = tui.print\n\n    def display_event(tag, inst, pitch, vel, channel, **kw):\n        \"\"\"print an event to the terminal\"\"\"\n        if tag is None:\n            return\n        s = f'{tag}:\\t {inst=:4d}    {pitch=:4d}    {vel=:4d}    {channel=:3d}'\n        tui(note=s)\n    ###\n\n    if noto_config is None:\n        if not below and not above:\n            raise ValueError\n        noto_config = [[\n            noto_channel-1, noto_inst, -128 if below else 1, 128 if above else -1]]\n    # convert to 0-index\n    player_channel = player_channel-1\n\n    # TODO: per-channel absolute range config\n\n    def warn_inst(i):\n        if i &gt; 128:\n            if i &lt; 257:\n                print(f\"WARNING: drum instrument {i} selected, be sure to select a drum bank in your synthesizer\")\n            else:\n                print(f\"WARNING: instrument {i} is not General MIDI\")\n\n    if send_pc:\n        warn_inst(player_inst)\n        midi.program_change(channel=player_channel, program=(player_inst-1)%128)\n        for (c,i,_,_) in noto_config:\n            warn_inst(i)\n            midi.program_change(channel=c, program=(i-1)%128)\n\n\n    for (_,_,lo,hi) in noto_config:\n        assert lo &lt;= hi, \"\"\"min transpose should be less than max transpose\"\"\"\n\n    noto = Notochord.from_checkpoint(checkpoint)\n    noto.eval()\n\n    history = NotoPerformance()\n    stopwatch = Stopwatch()\n\n    class AppState():\n        def __init__(self):\n            self.muted = False\n    state = AppState()\n\n    def noto_mute():\n        state.muted = not state.muted\n        print('MUTE' if state.muted else 'UNMUTE')\n\n    def noto_reset():\n        \"\"\"reset Notochord and end all of its held notes\"\"\"\n        print('RESET')\n\n        # end Notochord held notes\n        # noto_pairs = {(c,i) for (c,i,_,_) in noto_config}\n        # for (c,i,p) in history.note_triples:\n        #     if (c,i) in noto_pairs:\n        #         midi.note_off(note=p, velocity=0, channel=c)\n\n        # reset stopwatch\n        stopwatch.punch()\n        # reset notochord state\n        noto.reset()\n        # # reset history\n        # history.push()\n\n    @midi.handle(type='control_change', control=0, channel=player_channel)\n    def _(msg):\n        \"\"\"\n        any CC0 message on player channel resets Notochord\n        \"\"\"\n        noto.reset()\n\n    @midi.handle(type=('note_on', 'note_off'), channel=player_channel)\n    def _(msg):\n        \"\"\"\n        MIDI NoteOn events from the player\n        \"\"\"\n\n        pitch = msg.note\n        vel = msg.velocity\n\n        if thru:\n            midi.send(msg)\n\n        noto_range = (0,127) # TODO: config this\n\n        # NoteOn\n        if msg.type=='note_on' and vel &gt; 0:\n            dt = stopwatch.punch()\n            # track\n            event = dict(\n                channel=player_channel,\n                inst=player_inst, pitch=pitch, vel=vel, time=dt)\n            history.feed(**event)\n            # feed in the performed note\n            noto.feed(**event)\n            display_event('PLAYER', **event)\n\n            if state.muted:\n                return\n\n            for noto_channel, noto_inst, min_x, max_x in noto_config:\n\n                already_playing = {p for i,p in history.note_pairs if noto_inst==i}\n\n                lo, hi = noto_range\n                pitch_range = range(max(lo,pitch+min_x), min(hi, pitch+max_x+1))\n                pitches = (\n                    set(pitch_range) - {pitch} - already_playing\n                )\n\n                if len(pitches)==0:\n                    # edge case: no possible pitch\n                    print(f'skipping {noto_channel=}, no pitches available')\n                    print(pitch_range, 'minus', {pitch}, 'minus', already_playing)\n                    continue\n                elif len(pitches)==1:\n                    # edge case: there is exactly one possible pitch\n                    h = dict(\n                        inst=noto_inst, pitch=list(pitches)[0], \n                        time=0, vel=vel)\n                else:\n                    # notochord chooses pitch\n                    h = noto.query(\n                        next_inst=noto_inst, next_time=0, next_vel=vel,\n                        include_pitch=pitches)\n\n                h_inst = h['inst'] # noto_inst\n                h_pitch = h['pitch']\n                h_time = h['time'] # 0\n                h_vel = round(h['vel'])\n\n                # send it\n                midi.note_on(note=h_pitch, velocity=h_vel, channel=noto_channel)\n                # track\n                event = dict(\n                    channel=noto_channel,\n                    inst=h_inst, pitch=h_pitch, time=h_time, vel=h_vel)\n                history.feed(\n                    held_note_data=(player_inst, pitch), \n                    **event)\n                # feed back\n                noto.feed(**event)\n                display_event('NOTO', **event)\n        # NoteOff\n        else:\n            dt = stopwatch.punch()\n            event = dict(\n                channel=player_channel, \n                inst=player_inst, pitch=pitch, time=dt, vel=0)\n            noto.feed(**event)\n            history.feed(**event)\n            display_event('PLAYER', **event)\n\n            dependents = [\n                noto_k\n                for noto_k,player_k \n                in history.note_data.items()\n                if player_k==(player_inst, pitch)\n            ]\n\n            for noto_channel, noto_inst, noto_pitch in dependents:\n                # send harmonizing note offs\n                midi.note_off(\n                    note=noto_pitch, velocity=vel, channel=noto_channel)\n\n                event = dict(\n                    channel=noto_channel, \n                    inst=noto_inst, pitch=noto_pitch, time=dt, vel=0)\n                # TODO: nominal time option?\n                noto.feed(**event)\n                history.feed(**event)\n                display_event('NOTO', **event)\n\n    @cleanup\n    def _():\n        \"\"\"end any remaining notes\"\"\"\n        for (c,_,p) in history.note_triples:\n            midi.note_off(note=p, velocity=0, channel=c)\n\n    @tui.set_action\n    def mute():\n        noto_mute()\n\n    @tui.set_action\n    def reset():\n        noto_reset()\n\n    if use_tui:\n        tui.run()\n</code></pre>"},{"location":"reference/notochord/app/homunculus/","title":"Homunculus","text":"<p>Notochord MIDI co-improviser server. Notochord plays different instruments along with the player.</p> Authors <p>Victor Shepardson Intelligent Instruments Lab 2023</p>"},{"location":"reference/notochord/app/homunculus/#notochord.app.homunculus.NotoTUI","title":"<code>NotoTUI</code>","text":"<p>             Bases: <code>TUI</code></p> Source code in <code>src/notochord/app/homunculus.py</code> <pre><code>class NotoTUI(TUI):\n    CSS_PATH = 'homunculus.css'\n\n    BINDINGS = [\n        (\"m\", \"mute\", \"Mute Notochord\"),\n        (\"s\", \"sustain\", \"Sustain\"),\n        (\"q\", \"query\", \"Re-query Notochord\"),\n        (\"r\", \"reset\", \"Reset Notochord\")]\n\n    def compose(self):\n        \"\"\"Create child widgets for the app.\"\"\"\n        yield Header()\n        yield self.std_log\n        yield NotoLog(id='note')\n        yield NotoPrediction(id='prediction')\n        yield Mixer()\n        yield NotoPresets()\n        yield NotoControl()\n        yield Footer()\n\n    def set_preset(self, idx, name):\n        node = self.query_one('#'+preset_id(idx))\n        node.label = name\n\n    def set_channel(self, chan, cfg):\n        # print(f'set_channel {cfg}')\n        inst_node = self.query_one('#'+inst_id(chan))\n        mode_node = self.query_one('#'+mode_id(chan))\n        mute_node = self.query_one('#'+mute_id(chan))\n\n        if cfg is None:\n            inst_node.variant = 'default'\n            mute_node.variant = 'default'\n            mode_node.variant = 'default'\n            return\n\n        mode = cfg['mode']\n        mute = cfg['mute']\n        inst = cfg['inst']\n\n        inst_node.label = inst_label(inst)\n\n        if mode=='auto':\n            mode_node.label = f\"{chan:02d}\"\n        elif mode=='input':\n            mode_node.label = f\"--&gt;{chan:02d}\"\n        elif mode=='follow':\n            mode_node.label = f\"{cfg['source']:02d}-&gt;{chan:02d}\"\n\n        if mute:\n            mode_node.variant = 'default'\n            inst_node.variant = 'default'\n            mute_node.label = 'UNMUTE'\n            mute_node.variant = 'error'\n        else:\n            mode_node.variant = 'primary'\n            inst_node.variant = 'warning'\n            mute_node.label = 'MUTE'\n            mute_node.variant = 'default'\n</code></pre>"},{"location":"reference/notochord/app/homunculus/#notochord.app.homunculus.NotoTUI.compose","title":"<code>compose()</code>","text":"<p>Create child widgets for the app.</p> Source code in <code>src/notochord/app/homunculus.py</code> <pre><code>def compose(self):\n    \"\"\"Create child widgets for the app.\"\"\"\n    yield Header()\n    yield self.std_log\n    yield NotoLog(id='note')\n    yield NotoPrediction(id='prediction')\n    yield Mixer()\n    yield NotoPresets()\n    yield NotoControl()\n    yield Footer()\n</code></pre>"},{"location":"reference/notochord/app/homunculus/#notochord.app.homunculus.main","title":"<code>main(checkpoint='notochord-latest.ckpt', config=None, initial_mute=False, initial_query=False, midi_in=None, midi_out=None, thru=False, send_pc=False, dump_midi=False, balance_sample=False, n_recent=32, n_margin=8, max_note_len=5, max_time=None, nominal_time=False, osc_port=None, osc_host='', use_tui=True, predict_input=True, predict_follow=False, debug_query=False, testing=False, estimated_latency=0.01, soundfont=None, limit_input=None, thru_vel_offset=None)</code>","text":"<p>This a terminal app for using Notochord interactively with MIDI controllers and synthesizers. Arguments to main can be given on the command line as flags, for example:</p> <p><code>python -m notochord homunculus --initial-query --config '{1:{mode:auto, inst:1}}'</code></p> <p>16 voices correspond to the 16 MIDI channels. Each voice can be in one of three modes:</p> <pre><code>* input (appearing like \"--&gt;01\"), voice 1 comes from MIDI input channel 1.\n* follow (appearing like \"01-&gt;02\"), voice 2 plays whenever voice 1 plays.\n* auto (appearing like just \"03\"), voice 3 plays autonomously.\n</code></pre> <p>Click the top section of each voice to cycle the mode.</p> <p>Each voice is also assigned a General MIDI instrument. Each 'input' and 'auto' voice should have a unique General MIDI instrument, but 'follow' voices can be duplicates of other voices. </p> <p>Click the middle section of each voice to choose a new instrument.</p> <p>The bottom section of each voice allows muting individual voices.</p> <p>Along the bottom, there are global query, sustain, mute and reset buttons. Query manually replaces the next pending note. Sustain stops all auto voices from playing without ending any open notes. Mute ends all open notes and stops auto voices. Reset ends all open notes, forgets all context and sets the Notochord model to its initial state.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>path to notochord model checkpoint.</p> <code>'notochord-latest.ckpt'</code> <code>config</code> <code>Dict[int, Dict[str, Any]]</code> <p>mapping from MIDI channels to voice specs. MIDI channels and General MIDI instruments are indexed from 1. see https://en.wikipedia.org/wiki/General_MIDI for instrument numbers. There are 3 modes of voice: 'auto', 'follow' and 'input'. Example: {     1:{         'mode':'input', 'inst':1     }, # input grand piano on MIDI channel 1     2:{         'mode':'follow', 'source':1, 'inst':1,          'transpose':(-12,12)     }, # harmonize the channel within 1 octave 1 with more piano     3:{         'mode':'auto', 'inst':12, 'range':(36,72)     }, # autonomous vibraphone voice in the MIDI pitch 36-72 range     10:{         'mode':'auto', 'inst':129,     }, # autonomous drums voice     4:{         'mode':'follow', 'source':3, 'inst':10, 'range':(72,96)     }, # harmonize channel 3 within upper registers of the glockenspiel } Notes: no 'input' or 'auto' channels should use the same instrument, but 'follow' channels may have the same as an 'input' or 'auto'</p> <code>None</code> <code>initial_mute</code> <p>start 'auto' voices muted so it won't play with input.</p> <code>False</code> <code>initial_query</code> <p>query Notochord immediately, so 'auto' voices begin playing  without input.</p> <code>False</code> <code>midi_in</code> <code>Optional[str]</code> <p>MIDI ports for input.  default is to use all input ports. can be comma-separated list of ports.</p> <code>None</code> <code>midi_out</code> <code>Optional[str]</code> <p>MIDI ports for output.  default is to use only virtual 'From iipyper' port. can be comma-separated list of ports.</p> <code>None</code> <code>thru</code> <p>if True, copy input MIDI to output ports. only makes sense if input and output ports are different.</p> <code>False</code> <code>send_pc</code> <p>if True, send MIDI program change messages to set the General MIDI instrument on each channel according to player_config and noto_config. useful when using a General MIDI synthesizer like fluidsynth.</p> <code>False</code> <code>dump_midi</code> <p>if True, print all incoming MIDI for debugging purposes</p> <code>False</code> <code>n_recent</code> <p>number of recent note-on events to consider for above</p> <code>32</code> <code>n_margin</code> <p>amount of 'slack' in the balance_sample calculation</p> <code>8</code> <code>max_note_len</code> <p>time in seconds after which to force-release sustained 'auto' notes.</p> <code>5</code> <code>max_time</code> <p>maximum seconds between predicted events for 'auto' voices. default is the Notochord model's maximum (usually 10 seconds).</p> <code>None</code> <code>nominal_time</code> <p>if True, feed Notochord with its own predicted times instead of the actual elapsed time. May make Notochord more likely to play chords.</p> <code>False</code> <code>osc_port</code> <p>optional. if supplied, listen for OSC to set controls</p> <code>None</code> <code>osc_host</code> <p>hostname or IP of OSC sender. leave this as empty string to get all traffic on the port</p> <code>''</code> <code>use_tui</code> <p>run textual UI.</p> <code>True</code> <code>predict_input</code> <p>forecasted next events can be for 'input' voices. generally should be True for manual input; use balance_sample to force 'auto' voices to play.  you might want it False if you have a very busy input.</p> <code>True</code> Source code in <code>src/notochord/app/homunculus.py</code> <pre><code>def main(\n    checkpoint=\"notochord-latest.ckpt\", # Notochord checkpoint\n    config:Dict[int,Dict[str,Any]]=None, # map MIDI channel : GM instrument\n\n    initial_mute=False, # start with Notochord muted\n    initial_query=False, # let Notochord start playing immediately\n\n    midi_in:Optional[str]=None, # MIDI port for player input\n    midi_out:Optional[str]=None, # MIDI port for Notochord output\n    thru=False, # copy player input to output\n    send_pc=False, # send program change messages\n    dump_midi=False, # print all incoming MIDI\n\n    balance_sample=False, # choose instruments which have played less recently\n    n_recent=32, # number of recent note-on events to consider for above\n    n_margin=8, # amount of 'slack' in the balance_sample calculation\n\n    max_note_len=5, # in seconds, to auto-release stuck Notochord notes\n    max_time=None, # max time between events\n    nominal_time=False, #feed Notochord with nominal dt instead of actual\n\n    osc_port=None, # if supplied, listen for OSC to set controls on this port\n    osc_host='', # leave this as empty string to get all traffic on the port\n\n    use_tui=True, # run textual UI\n    predict_input=True, # forecasted next events can be for input (preserves model distribution, but can lead to Notochord deciding not to play)\n    predict_follow=False,\n    debug_query=False, # don't query notochord when there is no pending event.\n    testing=False,\n    estimated_latency=1e-2,\n    soundfont=None,\n    limit_input=None,\n    thru_vel_offset=None\n    ):\n    \"\"\"\n    This a terminal app for using Notochord interactively with MIDI controllers and synthesizers. Arguments to main can be given on the command line as flags, for example:\n\n    `python -m notochord homunculus --initial-query --config '{1:{mode:auto, inst:1}}'`\n\n    16 voices correspond to the 16 MIDI channels. Each voice can be in one of three modes:\n\n        * input (appearing like \"--&gt;01\"), voice 1 comes from MIDI input channel 1.\n        * follow (appearing like \"01-&gt;02\"), voice 2 plays whenever voice 1 plays.\n        * auto (appearing like just \"03\"), voice 3 plays autonomously.\n\n    Click the top section of each voice to cycle the mode.\n\n    Each voice is also assigned a [General MIDI instrument](https://en.wikipedia.org/wiki/General_MIDI#Program_change_events). Each 'input' and 'auto' voice should have a unique General MIDI instrument, but 'follow' voices can be duplicates of other voices. \n\n    Click the middle section of each voice to choose a new instrument.\n\n    The bottom section of each voice allows muting individual voices.\n\n    Along the bottom, there are global query, sustain, mute and reset buttons. Query manually replaces the next pending note. Sustain stops all auto voices from playing without ending any open notes. Mute ends all open notes and stops auto voices. Reset ends all open notes, forgets all context and sets the Notochord model to its initial state.\n\n    Args:\n        checkpoint: path to notochord model checkpoint.\n\n        config: mapping from MIDI channels to voice specs.\n            MIDI channels and General MIDI instruments are indexed from 1.\n            see https://en.wikipedia.org/wiki/General_MIDI for instrument numbers.\n            There are 3 modes of voice: 'auto', 'follow' and 'input'.\n            Example:\n            {\n                1:{\n                    'mode':'input', 'inst':1\n                }, # input grand piano on MIDI channel 1\n                2:{\n                    'mode':'follow', 'source':1, 'inst':1, \n                    'transpose':(-12,12)\n                }, # harmonize the channel within 1 octave 1 with more piano\n                3:{\n                    'mode':'auto', 'inst':12, 'range':(36,72)\n                }, # autonomous vibraphone voice in the MIDI pitch 36-72 range\n                10:{\n                    'mode':'auto', 'inst':129,\n                }, # autonomous drums voice\n                4:{\n                    'mode':'follow', 'source':3, 'inst':10, 'range':(72,96)\n                }, # harmonize channel 3 within upper registers of the glockenspiel\n            }\n            Notes:\n            no 'input' or 'auto' channels should use the same instrument,\n            but 'follow' channels may have the same as an 'input' or 'auto'\n\n        initial_mute: start 'auto' voices muted so it won't play with input.\n        initial_query: query Notochord immediately,\n            so 'auto' voices begin playing  without input.\n\n        midi_in: MIDI ports for input. \n            default is to use all input ports.\n            can be comma-separated list of ports.\n        midi_out: MIDI ports for output. \n            default is to use only virtual 'From iipyper' port.\n            can be comma-separated list of ports.\n        thru: if True, copy input MIDI to output ports.\n            only makes sense if input and output ports are different.\n        send_pc: if True, send MIDI program change messages to set the General MIDI\n            instrument on each channel according to player_config and noto_config.\n            useful when using a General MIDI synthesizer like fluidsynth.\n        dump_midi: if True, print all incoming MIDI for debugging purposes\n\n        balance_sample choose 'auto' voices which have played less recently,\n            ensures that all configured instruments will play.\n        n_recent: number of recent note-on events to consider for above\n        n_margin: amount of 'slack' in the balance_sample calculation\n\n        max_note_len: time in seconds after which to force-release sustained\n            'auto' notes.\n        max_time: maximum seconds between predicted events for 'auto' voices.\n            default is the Notochord model's maximum (usually 10 seconds).\n        nominal_time: if True, feed Notochord with its own predicted times\n            instead of the actual elapsed time.\n            May make Notochord more likely to play chords.\n\n        osc_port: optional. if supplied, listen for OSC to set controls\n        osc_host: hostname or IP of OSC sender.\n            leave this as empty string to get all traffic on the port\n\n        use_tui: run textual UI.\n        predict_input: forecasted next events can be for 'input' voices.\n            generally should be True for manual input;\n            use balance_sample to force 'auto' voices to play. \n            you might want it False if you have a very busy input.\n        debug_query=False, # don't query notochord when there is no pending event.\n    \"\"\"\n    if osc_port is not None:\n        osc = OSC(osc_host, osc_port)\n    midi = MIDI(midi_in, midi_out)\n\n    if soundfont is not None:\n        # attempt to get instrument ranges from the soundfont\n        # assumes first bank is used\n        # not sure if entirely correct\n        from sf2utils.sf2parse import Sf2File\n        from sf2utils.generator import Sf2Gen\n\n        with open(soundfont, 'rb') as file:\n            soundfont = Sf2File(file)\n        sf_presets = {\n            p.preset:p\n            for p in soundfont.presets \n            if hasattr(p,'bank') and p.bank==0}\n\n        def _get_range(i):\n            if i&gt;127:\n                return 0, 127\n            lo, hi = 127,0\n            for b in sf_presets[i-1].bags:\n                if Sf2Gen.OPER_INSTRUMENT not in b.gens: \n                    continue\n                if b.key_range is None: \n                    return 0, 127\n                l,h = b.key_range\n                lo = min(lo, l)\n                hi = max(hi, h)\n            assert lo&lt;hi, (i-1,lo,hi)\n            return lo, hi\n        sf_inst_ranges = {i:_get_range(i) for i in range(1,129)}\n        def get_range(i):\n            return sf_inst_ranges.get(i, (0,127))\n    else:\n        def get_range(i):\n            return 0,127\n\n\n    ### Textual UI\n    tui = NotoTUI()\n    print = notochord.print = iipyper.print = tui.print\n    ###\n\n    with open(Path(__file__).parent / 'preset.json') as f:\n        presets = json.load(f)\n    # convert MIDI channels to int\n    presets = {p:{int(k):v for k,v in d.items()} for p,d in presets.items()}\n\n    if config is None: config = 'ens1'\n    if isinstance(config, str):\n        config = presets[config]\n\n    # defaults\n    config_in = config\n    def default_config_channel():\n        return {'mode':'auto', 'inst':1, 'mute':False, 'mono':False, 'source':1}\n    config = {i:default_config_channel() for i in config_in}\n    for k,v in config_in.items():\n        config[k].update(v)\n\n    def validate_config():\n        assert all(\n            v['source'] in config for v in config.values() if v['mode']=='follow'\n            ), 'ERROR: no source given for follow voice'\n        # TODO: check for follow cycles\n    validate_config()\n\n    # for c,v in config.items():\n    #     tui.set_inst(c, v['inst'])\n\n    def mode_insts(t, allow_muted=True):\n        if isinstance(t, str):\n            t = t,\n        # set of instruments with given mode(s)\n        return {\n            v['inst'] for v in config.values() \n            if v['mode'] in t and (allow_muted or not v['mute'])\n            }\n    def mode_chans(t):\n        if isinstance(t, str):\n            t = t,\n        # list of channels with given mode\n        return [k for k,v in config.items() if v['mode'] in t]\n    def channel_inst(c):\n        return config[c]['inst']\n    def channel_insts():\n        # list of channel,instrument pairs\n        return [(c,channel_inst(c)) for c in config]\n    def inst_ranges(insts):\n        # instruments to sets of allowed MIDI numbers\n        r = {}\n        for v in config.values():\n            i = v['inst']\n            if i in insts:\n                s = set(range(*v.get('range', get_range(i))))\n                if i in r:\n                    r[i] |= s\n                else:\n                    r[i] = s\n        return r\n    def auto_inst_channel(i):\n        for k,v in config.items():\n            if v['inst']==i:\n                return k\n        raise ValueError\n    def channel_followers(chan):\n        # return channel of all 'follow' voices with given source\n        return [\n            k for k,v in config.items() \n            if v['mode']=='follow' \n            and v.get('source', None)==chan]\n\n    if len(mode_insts('input') &amp; mode_insts('auto')):\n        print(\"WARNING: auto and input instruments shouldn't overlap\")\n        print('setting to an anonymous instrument')\n        # TODO: set to anon insts without changing mel/drum\n        # respecting anon insts selected for player\n        raise NotImplementedError\n    # TODO:\n    # check for repeated insts/channels\n\n    def warn_inst(i):\n        if i &gt; 128:\n            if i &lt; 257:\n                print(f\"WARNING: drum instrument {i} selected, be sure to select a drum bank in your synthesizer\")\n            else:\n                print(f\"WARNING: instrument {i} is not General MIDI\")\n\n    def do_send_pc(c, i):\n        warn_inst(i)\n        # convert to 0-index\n        midi.program_change(channel=c-1, program=(i-1)%128)\n\n    if send_pc:\n        for c,i in channel_insts():\n            do_send_pc(c, i)\n\n    # load notochord model\n    try:\n        noto = Notochord.from_checkpoint(checkpoint)\n        noto.eval()\n        noto.reset()\n    except Exception:\n        print(\"\"\"error loading notochord model\"\"\")\n        raise\n\n    # main stopwatch to track time difference between MIDI events\n    stopwatch = Stopwatch()\n\n    # simple class to hold pending event prediction\n    class Prediction:\n        def __init__(self):\n            self.event = None\n            self.gate = not initial_mute\n    pending = Prediction()\n\n    # query parameters controlled via MIDI / OSC\n    controls = {}\n\n    # tracks held notes, recently played instruments, etc\n    history = NotoPerformance()\n\n    follow_status = {'depth':0}\n\n    def display_event(tag, memo, inst, pitch, vel, channel, **kw):\n        \"\"\"print an event to the terminal\"\"\"\n        if tag is None:\n            return\n        s = f'{tag}:\\t {inst=:4d}    {pitch=:4d}    {vel=:4d}    {channel=:3d}'\n        if memo is not None:\n            s += f'    ({memo})'\n        tui(note=s)\n\n    def play_event(\n            event, channel, \n            parent=None, # parent note as (channel, inst, pitch)\n            feed=True, \n            send=True, \n            tag=None, memo=None):\n        \"\"\"realize an event as MIDI, terminal display, and Notochord update\"\"\"\n        # normalize values\n        vel = event['vel'] = math.ceil(event['vel'])\n        dt = stopwatch.punch()\n        if 'time' not in event or not nominal_time:\n            event['time'] = dt\n\n        # send out as MIDI\n        if send:\n            midi.send(\n                'note_on' if vel &gt; 0 else 'note_off', \n                note=event['pitch'], velocity=vel, channel=channel-1)\n\n        # print\n        display_event(tag, memo=memo, channel=channel, **event)\n\n        if feed:\n            # feed to NotoPerformance\n            # put a stopwatch in the held_note_data field for tracking note length\n            history.feed(held_note_data={\n                'duration':Stopwatch(),\n                'parent':parent\n                }, channel=channel, **event)\n            # feed to model\n            noto.feed(**event)\n\n        follow_status['depth'] += 1\n        # print(f'{follow_status=}')\n        follow_event(event, channel)\n        follow_status['depth'] -= 1\n        # print(f'{follow_status=}')\n\n    def follow_event(source_event, source_channel):\n        source_vel = source_event['vel']\n        source_pitch = source_event['pitch']\n        source_inst = source_event['inst']\n        source_k = (source_channel, source_inst, source_pitch)\n\n        # TODO: process events from 'follow' channels\n\n        dt = 0 if nominal_time else estimated_latency\n\n        if source_vel &gt; 0:\n            # NoteOn\n            for noto_channel in channel_followers(source_channel):\n                cfg = config[noto_channel]\n\n                if cfg.get('mute', False): continue\n\n                noto_inst = cfg['inst']\n                min_x, max_x = cfg.get('transpose', (-128,128))\n                lo, hi = cfg.get('range', (0,127))\n\n                # already_playing = {p for i,p in history.note_pairs if noto_inst==i}\n                already_playing = {\n                    note.pitch for note in history.notes if noto_inst==note.inst}\n                # print(f'{already_playing=}')\n\n                pitch_range = range(\n                    max(lo,source_pitch+min_x), min(hi, source_pitch+max_x+1))\n                pitches = (\n                    set(pitch_range) - {source_pitch} - already_playing\n                )\n\n                if len(pitches)==0:\n                    # edge case: no possible pitch\n                    print(f'skipping {noto_channel=}, no pitches available')\n                    print(f'{pitch_range} minus {{source_pitch}} minus {already_playing}')\n                    continue\n                elif len(pitches)==1:\n                    # edge case: there is exactly one possible pitch\n                    h = dict(\n                        inst=noto_inst, pitch=list(pitches)[0], \n                        time=0, vel=source_vel)\n                else:\n                    # notochord chooses pitch\n                    h = noto.query(\n                        next_inst=noto_inst, next_time=dt, next_vel=source_vel,\n                        include_pitch=pitches)\n\n                play_event(h, noto_channel, parent=source_k, tag='NOTO', memo='follow')\n        # NoteOff\n        else:\n            # print(f'{history.note_data=}')\n            dependents = [\n                noto_k # chan, inst, pitch\n                for noto_k, note_data\n                in history.note_data.items()\n                if note_data['parent']==source_k\n            ]\n\n            for noto_channel, noto_inst, noto_pitch in dependents:\n                h = dict(inst=noto_inst, pitch=noto_pitch, time=dt, vel=0)\n                play_event(h, noto_channel,tag='NOTO', memo='follow')\n\n    # @lock\n    def noto_reset():\n        \"\"\"reset Notochord and end all of its held notes\"\"\"\n        print('RESET')\n\n        # cancel pending predictions\n        pending.event = None\n        tui(prediction=pending.event)\n\n        # end Notochord held notes\n        # for (chan,inst,pitch) in history.note_triples:\n        for note in history.notes:\n            if note.inst in mode_insts('auto'):\n                play_event(\n                    dict(inst=note.inst, pitch=note.pitch, vel=0),\n                    channel=note.chan, \n                    feed=False, # skip feeding Notochord since we are resetting it\n                    tag='NOTO', memo='reset')\n        # reset stopwatch\n        stopwatch.punch()\n        # reset notochord state\n        noto.reset()\n        # reset history\n        history.push()\n\n        # TODO: feed note-ons from any held input/follower notes?\n\n        # query the fresh notochord for a new prediction\n        if pending.gate:\n            auto_query()\n\n    # @lock\n    def noto_mute(sustain=False):\n        tui.query_one('#mute').label = 'UNMUTE' if pending.gate else 'MUTE'\n        # if sustain:\n        tui.query_one('#sustain').label = 'END SUSTAIN' if pending.gate else 'SUSTAIN'\n\n        pending.gate = not pending.gate\n\n        if sustain:\n            print('END SUSTAIN' if pending.gate else 'SUSTAIN')\n        else:\n            print('UNMUTE' if pending.gate else 'MUTE')\n        # if unmuting, we're done\n        if pending.gate:\n            if sustain:\n                auto_query()\n            return\n        # cancel pending predictions\n        pending.event = None\n        tui(prediction=pending.event)\n\n        if sustain:\n            return\n\n        # end+feed all held notes\n        # for (chan,inst,pitch) in history.note_triples:\n        for note in history.notes:\n            if note.chan in mode_chans('auto'):\n                play_event(\n                    dict(inst=note.inst, pitch=note.pitch, vel=0), \n                    channel=note.chan, tag='AUTO', memo='mute')\n\n    # query Notochord for a new next event\n    # @lock\n    def auto_query(predict_input=predict_input, predict_follow=predict_follow):\n        # check for stuck notes\n        # and prioritize ending those\n        for (_, inst, pitch), note_data in history.note_data.items():\n            dur = note_data['duration'].read()\n            if (\n                inst in mode_insts('auto') \n                and dur &gt; max_note_len*(.1+controls.get('steer_duration', 1))\n                ):\n                # query for the end of a note with flexible timing\n                # with profile('query', print=print):\n                t = stopwatch.read()\n                pending.event = noto.query(\n                    next_inst=inst, next_pitch=pitch,\n                    next_vel=0, min_time=t, max_time=t+0.5)\n                print(f'END STUCK NOTE {inst=},{pitch=}')\n                tui(prediction=pending.event)\n                return\n\n        # all_insts = mode_insts(('auto', 'input', 'follow'), allow_muted=True)\n        # counts = history.inst_counts(n=n_recent, insts=all_insts)\n        counts = defaultdict(int)\n        for i,c in history.inst_counts(n=n_recent).items():\n            counts[i] = c\n        print(f'{counts=}')\n\n        inst_modes = ['auto']\n        if predict_follow:\n            inst_modes.append('follow')\n        if predict_input:\n            inst_modes.append('input')\n        allowed_insts = mode_insts(inst_modes, allow_muted=False)\n\n        # assert len(allowed_insts - all_insts)==0, (allowed_insts, all_insts)\n\n        # held_notes = history.held_inst_pitch_map(all_insts)\n        held_notes = history.held_inst_pitch_map()\n        print(f'{held_notes=}')\n\n        steer_time = 1-controls.get('steer_rate', 0.5)\n        steer_pitch = controls.get('steer_pitch', 0.5)\n        steer_density = controls.get('steer_density', 0.5)\n\n        tqt = (max(0,steer_time-0.5), min(1, steer_time+0.5))\n        tqp = (max(0,steer_pitch-0.5), min(1, steer_pitch+0.5))\n\n        # if using nominal time,\n        # *subtract* estimated feed latency to min_time; (TODO: really should\n        #   set no min time when querying, use stopwatch when re-querying...)\n        # if using actual time, *add* estimated query latency\n        time_offset = -5e-3 if nominal_time else 10e-3\n        min_time = stopwatch.read()+time_offset\n\n        # idea: maintain an 'instrument presence' quantity\n        # incorporating time since / number of notes was playing\n        # ideally this would distinguish sustained from percussive instruments too\n\n        # balance_sample: note-ons only from instruments which have played less\n        inst_weights = None\n        if balance_sample:\n            inst_weights = {}\n            mc = max(counts.values()) if len(counts) else 0\n            for i in allowed_insts:\n                # if i in counts:\n                inst_weights[i] = np.exp(max(0, mc - counts[i] - n_margin))\n                # else:\n                    # inst_weights[i] = 1.\n\n        print(f'{inst_weights=}')\n\n        # VTIP is better for time interventions,\n        # VIPT is better for instrument interventions\n        if min_time &gt; estimated_latency or abs(tqt) &gt; abs(tqp):\n            query_method = noto.query_vtip\n        else:\n            query_method = noto.query_vipt\n\n        # print(f'considering {insts} for note_on')\n        # use only currently selected instruments\n        inst_pitch_map = inst_ranges(allowed_insts)\n        note_on_map = {\n            i: set(inst_pitch_map[i])-set(held_notes[i]) # exclude held notes\n            for i in allowed_insts#allowed_insts\n            if i in inst_pitch_map\n        }\n        # use any instruments which are currently holding notes\n        note_off_map = {\n            i: set(held_notes[i]) # only held notes\n            for i in allowed_insts\n            if i in held_notes\n        }\n\n        max_t = None if max_time is None else max(max_time, min_time+0.2)\n\n        try:\n            pending.event = query_method(\n                note_on_map, note_off_map,\n                min_time=min_time, max_time=max_t,\n                truncate_quantile_time=tqt,\n                truncate_quantile_pitch=tqp,\n                steer_density=steer_density,\n                inst_weights=inst_weights,\n                no_steer=mode_insts(('input','follow'), allow_muted=False),\n            )\n        except Exception:\n            # print(f'WARNING: query failed. {allowed_insts=} {note_on_map=} {note_off_map=}')\n            pending.event = None\n\n        # display the predicted event\n        tui(prediction=pending.event)\n\n    #### MIDI handling\n\n    # print all incoming MIDI for debugging\n    if dump_midi:\n        @midi.handle\n        def _(msg):\n            print(msg)\n\n    @midi.handle(type='program_change')\n    def _(msg):\n        \"\"\"Program change events set instruments\"\"\"\n        raise NotImplementedError\n\n    @midi.handle(type='pitchwheel')\n    def _(msg):\n        controls['steer_pitch'] = (msg.pitch+8192)/16384\n        # print(controls)\n\n    # very basic CC handling for controls\n    @midi.handle(type='control_change')\n    def _(msg):\n        \"\"\"CC messages on any channel\"\"\"\n\n        if msg.control==1:\n            controls['steer_pitch'] = msg.value/127\n            print(f\"{controls['steer_pitch']=}\")\n        if msg.control==2:\n            controls['steer_density'] = msg.value/127\n            print(f\"{controls['steer_density']=}\")\n        if msg.control==3:\n            controls['steer_rate'] = msg.value/127\n            print(f\"{controls['steer_rate']=}\")\n\n        if msg.control==4:\n            noto_reset()\n        if msg.control==5:\n            auto_query()\n        if msg.control==6:\n            noto_mute()\n\n    # very basic OSC handling for controls\n    if osc_port is not None:\n        @osc.args('/notochord/improviser/*')\n        def _(route, *a):\n            print('OSC:', route, *a)\n            ctrl = route.split['/'][3]\n            if ctrl=='reset':\n                noto_reset()\n            elif ctrl=='query':\n                auto_query()\n            elif ctrl=='mute':\n                noto_mute()\n            else:\n                assert len(a)==0\n                arg = a[0]\n                assert isinstance(arg, Number)\n                controls[ctrl] = arg\n                print(controls)\n\n    input_sw = Stopwatch()\n    dropped = set()# (channel, pitch)\n    input_dts = []\n    @midi.handle(type=('note_on', 'note_off'))\n    def _(msg):\n        \"\"\"MIDI NoteOn events from the player\"\"\"\n        # convert from 0-index\n        channel = msg.channel+1\n\n        if channel not in mode_chans('input'):\n            print(f'WARNING: ignoring MIDI {msg} on non-input channel')\n            return\n\n        if config[channel]['mute']:\n            print(f'WARNING: ignoring MIDI {msg} on muted channel')\n            return\n\n        if thru:\n            if msg.velocity&gt;0 and msg.type=='note_on' and thru_vel_offset is not None:\n                vel = max(1, int(msg.velocity*thru_vel_offset))\n                midi.send(msg.type, note=msg.note, channel=msg.channel, velocity=vel)\n            else:\n                midi.send(msg)\n\n        inst = channel_inst(channel)\n        pitch = msg.note\n        vel = msg.velocity if msg.type=='note_on' else 0\n\n        dt = input_sw.punch()\n        # print(f'EVENT {dt=} {msg}')\n        if len(input_dts) &gt;= 10:\n            input_dts.pop(0)\n        input_dts.append(dt)\n        input_dens = len(input_dts) / sum(input_dts)\n        # TODO: \n        # want to drop input when event density is high,\n        # not just dt is short\n        k = (channel,pitch)\n        if vel==0 and k in dropped:\n            dropped.remove(k)\n            print(f'WARNING: ignoring rate-limited input')\n            return\n        if vel&gt;0 and limit_input and input_dens&gt;limit_input:\n            print(f'WARNING: ignoring rate-limited input {input_dens=}')\n            dropped.add(k)\n            return \n\n        # feed event to Notochord\n        # with profile('feed', print=print):\n        play_event(\n            {'inst':inst, 'pitch':pitch, 'vel':vel}, \n            channel=channel, send=thru, tag='PLAYER')\n\n        # query for new prediction\n        auto_query()\n\n        # send a MIDI reply for latency testing purposes:\n        # if testing: midi.cc(control=3, value=msg.note, channel=15)\n\n    def auto_event():\n        # 'auto' event happens:\n        event = pending.event\n        inst, pitch, vel = event['inst'], event['pitch'], math.ceil(event['vel'])\n        chan = auto_inst_channel(inst)\n\n        # note on which is already playing or note off which is not\n        if (vel&gt;0) == ((inst, pitch) in history.note_pairs): \n            print(f're-query for invalid {vel=}, {inst=}, {pitch=}')\n            auto_query()\n            return\n\n        play_event(event, channel=chan, tag='NOTO')\n\n    @repeat(1e-3, lock=True)\n    def _():\n        \"\"\"Loop, checking if predicted next event happens\"\"\"\n        # check if current prediction has passed\n        dt = pending.event['time'] if pending.event is not None else float('inf')\n        if (\n            follow_status['depth']==0 and\n            not testing and\n            pending.gate and\n            stopwatch.read() &gt; dt\n            ):\n            # if so, check if it is a notochord-controlled instrument\n            if pending.event['inst'] in mode_insts('auto'):\n                # prediction happens\n                auto_event()\n            # query for new prediction\n            if dt &lt; noto.max_dt and not debug_query:\n            # if not debug_query:\n                auto_query()\n\n    @cleanup\n    def _():\n        \"\"\"end any remaining notes\"\"\"\n        # print(f'cleanup: {notes=}')\n        # for (chan,inst,pitch) in history.note_triples:\n        for note in history.notes:\n        # for (inst,pitch) in notes:\n            if note.inst in mode_insts(('auto', 'follow')):\n                midi.note_on(note=note.pitch, velocity=0, channel=note.chan-1)\n\n    ### update_* keeps the UI in sync with the state\n\n    def update_config():\n        # print(config)\n        for c,v in config.items():\n            tui.set_channel(c, v)\n\n    def update_presets():\n        for p,k in enumerate(presets):\n            tui.set_preset(p, k)\n\n    @tui.on\n    def mount():\n        update_config()\n        update_presets()\n\n\n    ### set_* does whatever necessary to change channel properties\n    ### calls update_config() to keep the UI in sync\n\n    def set_mode(c, m, update=True):\n        if c in config:\n            prev_m = config[c]['mode']\n        else:\n            prev_m = None\n        if m==prev_m:\n            return\n\n        if m=='follow':\n            if 'source' not in config[c]:\n                print('WARNING: follower without a source, setting to 1')\n                config[c]['source'] = 1\n\n        config[c]['mode'] = m\n        print(f'set channel {c} from {prev_m} to {m} mode')\n\n        ### NOTE changing a channel with followers to input causes stuck notes\n\n        if prev_m=='follow':\n            # emancipate held notes\n            for (dep_c,_,_), note_data in history.note_data.items():\n                if dep_c==c:\n                    note_data['parent'] = None\n\n        if prev_m=='auto':\n            # release held notes\n            for note in history.notes:\n                if note.chan==c:\n                    play_event(\n                        dict(inst=note.inst, pitch=note.pitch, vel=0),\n                        channel=note.chan, \n                        tag='NOTO', memo='mode change')\n\n        if update:\n            update_config()\n\n    class InstrumentSelect(Screen):\n        \"\"\"Screen with an instrument select dialog.\"\"\"\n        def __init__(self, c):\n            super().__init__()\n            self.channel = c\n\n        def compose(self):\n            yield Grid(\n                *(\n                    Button(s, id='select_'+inst_id(i)) \n                    for i,s in enumerate(gm_names, 1)\n                ), id=\"dialog\",\n            )\n        def on_button_pressed(self, event: Button.Pressed) -&gt; None:\n            # print(event.button.id)\n            # i = 1\n            i = int(event.button.id.split('_')[-1])\n            self.app.pop_screen()\n            set_inst(self.channel, i)\n    # inst_select = InstrumentSelect(None)\n\n    def set_inst(c, i, update=True):\n        print(f'SET INSTRUMENT {i}')\n        if c in config:\n            prev_i = config[c]['inst']\n        else:\n            prev_i = None\n        if prev_i==i:\n            print('SAME INSTRUMENT')\n            return\n        # TODO: warn if instrument already in use?\n\n        # for (chan,inst,pitch) in history.note_triples:\n        for note in history.notes:\n            if note.chan==c and config[note.chan]['mode']!='input':\n                play_event(\n                    dict(inst=note.inst, pitch=note.pitch, vel=0),\n                    channel=note.chan, \n                    tag='NOTO', memo='change instrument')\n        # send pc if appropriate\n        if send_pc:\n            do_send_pc(c, i)\n        # then set config\n        config[c]['inst'] = i\n        # and call:\n        if update:\n            update_config()\n\n    def set_mute(c, b, update=True):\n        if b:\n            print(f'mute channel {c}')\n            # release held notes\n            # for (chan,inst,pitch) in history.note_triples:\n            for note in history.notes:\n                if note.chan==c and config[c]['mode']!='input':\n                    play_event(\n                        dict(inst=note.inst, pitch=note.pitch, vel=0),\n                        channel=note.chan, \n                        tag='NOTO', memo='mute channel')\n        else:\n            print(f'unmute channel {c}')\n\n        config[c]['mute'] = b\n        if update:\n            update_config()\n\n    ### action_* runs on key/button press;\n    ### invokes cycler / picker logic and calls set_*\n\n    # this is pretty awful\n    # need a better way to reconcile iipyper and textual here\n    def action_mode(c):\n        if c not in config: return\n        # TODO: mode picker\n        if config[c]['mode'] == 'auto':\n            set_mode(c, 'input')\n        elif config[c]['mode'] == 'input' and config[c]['source']!=c:\n            # TODO: source picker for follow\n            set_mode(c, 'follow')\n        else:\n            set_mode(c, 'auto')\n\n    def action_inst(c):\n        print(f'inst channel {c}')\n        # TODO: instrument picker\n        tui.push_screen(InstrumentSelect(c))\n        # inst_select.channel = c\n        # tui.push_screen(inst_select)\n        # i = 1\n        # set_inst(c, i)\n\n    def action_mute(c):\n        if i not in config: return\n        set_mute(c, not config[c].get('mute', False))\n\n    def action_preset(p):\n        ks = list(presets.keys())\n        if p &gt;= len(ks):\n            return\n        k = ks[p]\n        preset = presets[k]\n        print(f'load preset: {k}')\n        for c in range(1,17):    \n            if c not in config:\n                config[c] = default_config_channel()\n            if c not in preset:\n                set_mute(c, True, update=False)\n            else:\n                v = preset[c]\n                set_mode(c, v.get('mode', 'auto'), update=False)\n                set_inst(c, v.get('inst', 1), update=False)\n                set_mute(c, v.get('mute', False), update=False)\n                # ugly, this sets config repeatedly...\n                config[c].update(v)\n        update_config()\n\n    ### set actions which have an with index argument\n    ### TODO move this logic into @tui.set_action\n\n    for i in range(1,17):\n        setattr(tui, f'action_mode_{i}', ft.partial(action_mode, i))\n        setattr(tui, f'action_inst_{i}', ft.partial(action_inst, i))\n        setattr(tui, f'action_mute_{i}', ft.partial(action_mute, i))\n\n    for i in range(10):\n        setattr(tui, f'action_preset_{i}', ft.partial(action_preset, i))\n\n    ### additional key/button actions\n\n    @tui.set_action\n    def mute():\n        noto_mute()\n\n    @tui.set_action\n    def sustain():\n        noto_mute(sustain=True)\n\n    @tui.set_action\n    def reset():\n        noto_reset()\n\n    @tui.set_action\n    def query():\n        auto_query()\n\n    if initial_query:\n        auto_query(predict_input=False, predict_follow=False)\n\n    if use_tui:\n        tui.run()\n</code></pre>"},{"location":"reference/notochord/app/improviser-txala/","title":"Improviser txala","text":"<p>Notochord MIDI co-improviser server. Notochord plays different instruments along with the player.</p> Authors <p>Victor Shepardson Intelligent Instruments Lab 2023</p>"},{"location":"reference/notochord/app/improviser-txala/#notochord.app.improviser-txala.NotoTUI","title":"<code>NotoTUI</code>","text":"<p>             Bases: <code>TUI</code></p> Source code in <code>src/notochord/app/improviser-txala.py</code> <pre><code>class NotoTUI(TUI):\n    CSS_PATH = 'improviser.css'\n\n    BINDINGS = [\n        (\"m\", \"mute\", \"Mute Notochord\"),\n        (\"q\", \"query\", \"Re-query Notochord\"),\n        (\"r\", \"reset\", \"Reset Notochord\")]\n\n    def compose(self):\n        \"\"\"Create child widgets for the app.\"\"\"\n        yield Header()\n        yield self.std_log\n        yield NotoLog(id='note')\n        yield NotoPrediction(id='prediction')\n        yield NotoControl()\n        yield Footer()\n</code></pre>"},{"location":"reference/notochord/app/improviser-txala/#notochord.app.improviser-txala.NotoTUI.compose","title":"<code>compose()</code>","text":"<p>Create child widgets for the app.</p> Source code in <code>src/notochord/app/improviser-txala.py</code> <pre><code>def compose(self):\n    \"\"\"Create child widgets for the app.\"\"\"\n    yield Header()\n    yield self.std_log\n    yield NotoLog(id='note')\n    yield NotoPrediction(id='prediction')\n    yield NotoControl()\n    yield Footer()\n</code></pre>"},{"location":"reference/notochord/app/improviser-txala/#notochord.app.improviser-txala.main","title":"<code>main(checkpoint='artifacts/noto-txala-011-0020.ckpt', player_config=None, noto_config=None, pitch_set=(41, 43, 45), initial_mute=False, initial_query=False, midi_in=None, midi_out=None, thru=False, send_pc=False, dump_midi=False, input_latency=0.02, rhythm_temp=0.9, timing_temp=0.2, steer_rate=None, auto_reset=True, start_after=2, max_run=5, n_recent=16, n_margin=5, max_time=None, nominal_time=False, backoff_time=0.001, osc_port=None, osc_host='', use_tui=True, predict_player=True, auto_query=True, testing=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>path to notochord model checkpoint.</p> <code>'artifacts/noto-txala-011-0020.ckpt'</code> <code>player_config</code> <code>Dict[int, int]</code> <p>mapping from MIDI channels to MIDI instruments controlled by the player.</p> <code>None</code> <code>noto_config</code> <code>Dict[int, int]</code> <p>mapping from MIDI channels to MIDI instruments controlled by notochord. Both indexed from 1. instruments should be different from the player instruments. channels should be different unless different ports are used. MIDI channels and General MIDI instruments are indexed from 1.</p> <code>None</code> <code>pitch_set</code> <p>collection of MIDI pitches for the txalaparta boards</p> <code>(41, 43, 45)</code> <code>initial_mute</code> <p>start Notochord muted so it won't play with input.</p> <code>False</code> <code>initial_query</code> <p>query Notochord immediately so it plays even without input.</p> <code>False</code> <code>midi_in</code> <code>Optional[str]</code> <p>MIDI ports for player input.  default is to use all input ports. can be comma-separated list of ports.</p> <code>None</code> <code>midi_out</code> <code>Optional[str]</code> <p>MIDI ports for Notochord output.  default is to use only virtual 'From iipyper' port. can be comma-separated list of ports.</p> <code>None</code> <code>thru</code> <p>if True, copy incoming MIDI to output ports. only makes sense if input and output ports are different.</p> <code>False</code> <code>send_pc</code> <p>if True, send MIDI program change messages to set the General MIDI instrument on each channel according to player_config and noto_config. useful when using a General MIDI synthesizer like fluidsynth.</p> <code>False</code> <code>dump_midi</code> <p>if True, print all incoming MIDI for debugging purposes</p> <code>False</code> <code>n_recent</code> <p>number of recent note-on events to consider for above</p> <code>16</code> <code>n_margin</code> <p>amount of 'slack' in the balance_sample calculation</p> <code>5</code> <code>max_time</code> <p>maximum time in seconds between predicted events. default is the Notochord model's maximum (usually 10 seconds).</p> <code>None</code> <code>nominal_time</code> <p>if True, feed Notochord with its own predicted times instead of the actual elapsed time. May make Notochord more likely to play chords.</p> <code>False</code> <code>osc_port</code> <p>optional. if supplied, listen for OSC to set controls</p> <code>None</code> <code>osc_host</code> <p>hostname or IP of OSC sender. leave this as empty string to get all traffic on the port</p> <code>''</code> <code>use_tui</code> <p>run textual UI.</p> <code>True</code> <code>predict_player</code> <p>forecasted next events can be for player. generally should be True; instead use balance_sample to force Notochord to play.</p> <code>True</code> <code>auto_query</code> <p>query notochord whenever it is unmuted and there is no pending event. generally should be True unless debugging.</p> <code>True</code> Source code in <code>src/notochord/app/improviser-txala.py</code> <pre><code>def main(\n    checkpoint=\"artifacts/noto-txala-011-0020.ckpt\", # Notochord checkpoint\n    player_config:Dict[int,int]=None, # map MIDI channel : GM instrument\n    noto_config:Dict[int,int]=None, # map MIDI channel : GM instrument\n    pitch_set=(41,43,45), # MIDI pitches used\n\n    initial_mute=False, # start with Notochord muted\n    initial_query=False, # let Notochord start playing immediately\n\n    midi_in:Optional[str]=None, # MIDI port for player input\n    midi_out:Optional[str]=None, # MIDI port for Notochord output\n    thru=False, # copy player input to output\n    send_pc=False, # send program change messages\n    dump_midi=False, # print all incoming MIDI\n\n    input_latency=0.02,\n    rhythm_temp=0.9,\n    timing_temp=0.2,\n    steer_rate=None,\n\n    auto_reset=True,\n\n    start_after=2, # don't sample notochord until this many total events\n    max_run=5,\n    # balance_sample=True, # choose instruments which have played less recently\n    n_recent=16, # number of recent note-on events to consider for above\n    n_margin=5, # amount of 'slack' in the balance_sample calculation\n\n    max_time=None, # max time between events\n    nominal_time=False, #feed Notochord with nominal dt instead of actual\n    backoff_time=1e-3, #time to wait when a predicted player event doesn't happen\n\n    osc_port=None, # if supplied, listen for OSC to set controls on this port\n    osc_host='', # leave this as empty string to get all traffic on the port\n\n    use_tui=True, # run textual UI\n    predict_player=True, # forecasted next events can be for player (preserves model distribution, but can lead to Notochord deciding not to play)\n    auto_query=True, # query notochord whenever it is unmuted and there is no pending event. generally should be True except for testing purposes.\n    testing=False\n    ):\n    \"\"\"\n    Args:\n        checkpoint: path to notochord model checkpoint.\n\n        player_config: mapping from MIDI channels to MIDI instruments controlled\n            by the player.\n        noto_config: mapping from MIDI channels to MIDI instruments controlled\n            by notochord. Both indexed from 1.\n            instruments should be different from the player instruments.\n            channels should be different unless different ports are used.\n            MIDI channels and General MIDI instruments are indexed from 1.\n\n        pitch_set: collection of MIDI pitches for the txalaparta boards\n\n        initial_mute: start Notochord muted so it won't play with input.\n        initial_query: query Notochord immediately so it plays even without input.\n\n        midi_in: MIDI ports for player input. \n            default is to use all input ports.\n            can be comma-separated list of ports.\n        midi_out: MIDI ports for Notochord output. \n            default is to use only virtual 'From iipyper' port.\n            can be comma-separated list of ports.\n        thru: if True, copy incoming MIDI to output ports.\n            only makes sense if input and output ports are different.\n        send_pc: if True, send MIDI program change messages to set the General MIDI\n            instrument on each channel according to player_config and noto_config.\n            useful when using a General MIDI synthesizer like fluidsynth.\n        dump_midi: if True, print all incoming MIDI for debugging purposes\n\n        balance_sample choose instruments which have played less recently\n            ensures that all configured instruments will play.\n        n_recent: number of recent note-on events to consider for above\n        n_margin: amount of 'slack' in the balance_sample calculation\n\n        max_time: maximum time in seconds between predicted events.\n            default is the Notochord model's maximum (usually 10 seconds).\n        nominal_time: if True, feed Notochord with its own predicted times\n            instead of the actual elapsed time.\n            May make Notochord more likely to play chords.\n\n        osc_port: optional. if supplied, listen for OSC to set controls\n        osc_host: hostname or IP of OSC sender.\n            leave this as empty string to get all traffic on the port\n\n        use_tui: run textual UI.\n        predict_player: forecasted next events can be for player.\n            generally should be True;\n            instead use balance_sample to force Notochord to play.\n        auto_query: query notochord whenever it is unmuted and there is no pending event. generally should be True unless debugging.\n    \"\"\"\n    if osc_port is not None:\n        osc = OSC(osc_host, osc_port)\n    midi = MIDI(midi_in, midi_out)\n\n    ### Textual UI\n    tui = NotoTUI()\n    print = tui.print\n    ###\n\n    # default channel:instrument mappings\n    if player_config is None:\n        # player_config = {1:265,2:266}\n        player_config = {1:290,2:291}\n    if noto_config is None:\n        # noto_config = {3:267,4:268}\n        noto_config = {3:292,4:293}\n\n    state = {\n        'run_length': 0,\n        'last_side': None\n    }\n\n    # convert 1-indexed MIDI channels to 0-indexed here\n    player_map = MIDIConfig({k-1:v for k,v in player_config.items()})\n    noto_map = MIDIConfig({k-1:v for k,v in noto_config.items()})\n\n    if len(player_map.insts &amp; noto_map.insts):\n        print(\"WARNING: Notochord and Player instruments shouldn't overlap\")\n        print('setting to an anonymous instrument')\n        # TODO: set to anon insts without changing mel/drum\n        # respecting anon insts selected for player\n        raise NotImplementedError\n    # TODO:\n    # check for repeated insts/channels\n\n    def warn_inst(i):\n        if i &gt; 128:\n            if i &lt; 257:\n                print(f\"WARNING: drum instrument {i} selected, be sure to select a drum bank in your synthesizer\")\n            else:\n                print(f\"WARNING: instrument {i} is not General MIDI\")\n\n    if send_pc:\n        for c,i in (player_map | noto_map).items():\n            warn_inst(i)\n            midi.program_change(channel=c, program=(i-1)%128)\n\n    # load notochord model\n    try:\n        noto = Notochord.from_checkpoint(checkpoint)\n        noto.eval()\n        noto.reset()\n    except Exception:\n        print(\"\"\"error loading notochord model\"\"\")\n        raise\n\n    # main stopwatch to track time difference between MIDI events\n    stopwatch = Stopwatch()\n\n    # simple class to hold pending event prediction\n    class Prediction:\n        def __init__(self):\n            self.event = None\n            self.gate = not initial_mute\n    pending = Prediction()\n\n    # query parameters controlled via MIDI / OSC\n    controls = {}\n    if steer_rate is not None:\n        controls['steer_rate'] = steer_rate\n\n    # tracks held notes, recently played instruments, etc\n    history = NotoPerformance()\n\n    def display_event(tag, memo, inst, pitch, vel, channel, **kw):\n        \"\"\"print an event to the terminal\"\"\"\n        if tag is None:\n            return\n        s = f'{tag}:\\t {inst=:4d}    {pitch=:4d}    {vel=:4d}    {channel=:3d}'\n        if memo is not None:\n            s += f'    ({memo})'\n        tui(note=s)\n\n    def play_event(event, channel, feed=True, send=True, tag=None, memo=None):\n        \"\"\"realize an event as MIDI, terminal display, and Notochord update\"\"\"\n        # normalize values\n        vel = event['vel'] = round(event['vel'])\n        dt = stopwatch.punch(latency=input_latency if tag=='PLAYER' else 0)\n        # dt = stopwatch.punch()\n        # if tag=='PLAYER':\n            # dt = max(0.001, dt - input_latency)\n            # print(f'latency corrected: {dt}')\n        if 'time' not in event or not nominal_time:\n            event['time'] = dt\n\n        side = int(event['inst']//2)\n        if side==state['last_side']:\n            state['run_length'] += 1\n        else:\n            state['run_length'] = 1\n\n        state['last_side'] = side\n        print(f'{state[\"run_length\"]=}')\n\n        # send out as MIDI\n        if send:\n            midi.send(\n                'note_on' if vel &gt; 0 else 'note_off', \n                note=event['pitch'], velocity=vel, channel=channel)\n\n        # feed to NotoPerformance\n        # put a stopwatch in the held_note_data field for tracking note length\n        history.feed(held_note_data=Stopwatch(), channel=channel, **event)\n\n        # print\n        display_event(tag, memo=memo, channel=channel, **event)\n\n        # feed to Notochord\n        if feed:\n            noto.feed(**event)\n\n    # @lock\n    def noto_reset(query=True):\n        \"\"\"reset Notochord and end all of its held notes\"\"\"\n        print('RESET')\n\n        # cancel pending predictions\n        pending.event = None\n        tui(prediction=pending.event)\n\n        # reset stopwatch\n        stopwatch.punch()\n        # reset notochord state\n        noto.reset()\n        # reset history\n        history.push()\n        # query the fresh notochord for a new prediction\n        if pending.gate and query:\n            noto_query()\n\n    # @lock\n    def noto_mute():\n        pending.gate = not pending.gate\n        print('UNMUTE' if pending.gate else 'MUTE')\n        # if unmuting, we're done\n        if pending.gate:\n            return\n        # cancel pending predictions\n        pending.event = None\n        tui(prediction=pending.event)\n\n    # query Notochord for a new next event\n    # @lock\n    def noto_query(delay=0):\n        counts = history.inst_counts(\n            n=n_recent, insts=noto_map.insts | player_map.insts)\n        # print(counts)\n        player_count = sum(counts[i] for i in player_map.insts)\n        noto_count = sum(counts[i] for i in noto_map.insts)\n        print(f'player: {player_count}')\n        print(f'noto: {noto_count}')\n        total_count = player_count + noto_count\n\n        all_insts = noto_map.insts \n        if predict_player:\n            all_insts = all_insts | player_map.insts\n\n        steer_time = 1-controls.get('steer_rate', 0.5)\n        tqt = (max(0,steer_time-0.5), min(1, steer_time+0.5))\n\n        print(tqt)\n\n        # if using nominal time,\n        # *subtract* estimated feed latency to min_time; (TODO: really should\n        #   set no min time when querying, use stopwatch when re-querying...)\n        # if using actual time, *add* estimated query latency\n        time_offset = -5e-3 if nominal_time else 10e-3\n        min_time = stopwatch.read()+time_offset+delay\n\n        if total_count &lt; start_after:\n            insts = player_map.insts\n        else:\n            insts = all_insts\n            if state['run_length'] &gt;= max_run:\n                s = int(state['last_side']*2)\n                insts = insts - {s, s+1}\n            # balance_sample: note-ons only from entity which has played less\n            # if balance_sample:                \n            #     if player_count &lt;= noto_count - n_margin:\n            #         insts = player_map.insts\n            #     elif noto_count &lt;= player_count - n_margin:\n            #         insts = noto_map.insts\n\n        if len(insts)==0:\n            insts = all_insts\n\n        print(f'{insts=}')\n\n        # bal_insts = set(counts.index[counts &lt;= counts.min()+n_margin])\n        # if balance_sample and len(bal_insts)&gt;0:\n        #     insts = bal_insts\n        # else:\n        #     insts = all_insts\n\n        # query_method = noto.query_tipv_onsets\n\n        if len(insts) &gt; 2:\n            # in this case *only* time is messed with,\n            # so if we sample time first,\n            # the rest can be properly conditioned on it\n            query_method = noto.query_tipv_onsets\n        else:\n            # in this case, instrument and time have both been constrained,\n            # and we can't sample the true joint distribution,\n            # but we sample instrument first\n            # under the assumption that the instrument constraint is\n            # 'stronger' than the time constraint\n            query_method = noto.query_itpv_onsets\n\n        max_t = None if max_time is None else max(max_time, min_time+0.2)\n\n        print(min_time, max_t)\n\n        pending.event = query_method(\n            include_pitch=pitch_set,\n            include_inst=list(insts),\n            min_time=min_time, max_time=max_t,\n            truncate_quantile_time=tqt,\n            min_vel=80, max_vel=120,\n            rhythm_temp=rhythm_temp,\n            timing_temp=timing_temp,\n        )\n        # display the predicted event\n        tui(prediction=pending.event)\n\n    #### MIDI handling\n\n    # print all incoming MIDI for debugging\n    if dump_midi:\n        @midi.handle\n        def _(msg):\n            print(msg)\n\n    @midi.handle(type='program_change')\n    def _(msg):\n        \"\"\"Program change events set instruments\"\"\"\n        if msg.channel in player_map:\n            player_map[msg.channel] = msg.program\n        if msg.channel in noto_map:\n            noto_map[msg.channel] = msg.program\n\n    @midi.handle(type='pitchwheel')\n    def _(msg):\n        controls['steer_pitch'] = (msg.pitch+8192)/16384\n        # print(controls)\n\n    # very basic CC handling for controls\n    @midi.handle(type='control_change')\n    def _(msg):\n        \"\"\"CC messages on any channel\"\"\"\n\n        # if msg.control==1:\n        #     controls['steer_pitch'] = msg.value/127\n        #     print(f\"{controls['steer_pitch']=}\")\n        # if msg.control==2:\n        #     controls['steer_density'] = msg.value/127\n        #     print(f\"{controls['steer_density']=}\")\n        if msg.control==3:\n            controls['steer_rate'] = msg.value/127\n            print(f\"{controls['steer_rate']=}\")\n\n        if msg.control==4:\n            noto_reset()\n        if msg.control==5:\n            noto_query()\n        if msg.control==6:\n            noto_mute()\n\n    # very basic OSC handling for controls\n    if osc_port is not None:\n        @osc.args('/notochord/improviser/*')\n        def _(route, *a):\n            print('OSC:', route, *a)\n            ctrl = route.split['/'][3]\n            if ctrl=='reset':\n                noto_reset()\n            elif ctrl=='query':\n                noto_query()\n            elif ctrl=='mute':\n                noto_mute()\n            else:\n                assert len(a)==0\n                arg = a[0]\n                assert isinstance(arg, Number)\n                controls[ctrl] = arg\n                print(controls)\n\n    @midi.handle(type=('note_on', 'note_off'))\n    def _(msg):\n        \"\"\"MIDI NoteOn events from the player\"\"\"\n        # if thru and msg.channel not in noto_map.channels:\n            # midi.send(msg)\n\n\n        if msg.channel not in player_map.channels:\n            return\n\n        inst = player_map[msg.channel]\n        pitch = msg.note\n        vel = msg.velocity if msg.type=='note_on' else 0\n\n        # feed event to Notochord\n        # with profile('feed', print=print):\n        play_event(\n            {'inst':inst, 'pitch':pitch, 'vel':vel}, \n            channel=msg.channel, send=thru, tag='PLAYER')\n\n        # query for new prediction\n        noto_query()\n\n        # send a MIDI reply for latency testing purposes:\n        # if testing: midi.cc(control=3, value=msg.note, channel=15)\n\n    def noto_event():\n        # notochord event happens:\n        event = pending.event\n        inst, pitch, vel = event['inst'], event['pitch'], round(event['vel'])\n\n        # note on which is already playing or note off which is not\n        # if (vel&gt;0) == ((inst, pitch) in history.note_pairs): \n        #     print(f're-query for invalid {vel=}, {inst=}, {pitch=}')\n        #     noto_query()\n        #     return\n\n        chan = noto_map.inv(inst)\n        play_event(event, channel=chan, tag='NOTO')\n\n    @repeat(1e-3, lock=True)\n    def _():\n        \"\"\"Loop, checking if predicted next event happens\"\"\"\n        # check if current prediction has passed\n        if (\n            not testing and\n            pending.gate and\n            pending.event is not None and\n            stopwatch.read() &gt; pending.event['time']\n            ):\n            e = pending.event\n            if e['time'] &gt;= noto.time_dist.hi.item():\n                if auto_reset:\n                    noto_reset(query=False)\n            # if so, check if it is a notochord-controlled instrument\n            if e['inst'] in noto_map.insts:\n                # prediction happens\n                noto_event()\n                delay = 0\n            else:\n                delay = backoff_time\n            # query for new prediction\n            # print(pending.event)\n            pending.event = None\n            if ('end' in e and random.random() &lt; e['end']):\n                print('END')\n                if auto_reset:\n                    noto_reset(query=False)\n            elif auto_query:\n                noto_query(delay=delay)\n\n    @cleanup\n    def _():\n        \"\"\"\"\"\"\n        pass\n        # print(f'cleanup: {notes=}')\n        # for (chan,inst,pitch) in history.note_triples:\n        # # for (inst,pitch) in notes:\n        #     if inst in noto_map.insts:\n        #         midi.note_on(note=pitch, velocity=0, channel=chan)\n\n    @tui.set_action\n    def mute():\n        noto_mute()\n\n    @tui.set_action\n    def reset():\n        noto_reset()\n\n    @tui.set_action\n    def query():\n        noto_query()\n\n    if initial_query:\n        noto_query()\n\n    if use_tui:\n        tui.run()\n</code></pre>"},{"location":"reference/notochord/app/improviser/","title":"Improviser","text":"<p>Notochord MIDI co-improviser server. Notochord plays different instruments along with the player.</p> Authors <p>Victor Shepardson Intelligent Instruments Lab 2023</p>"},{"location":"reference/notochord/app/improviser/#notochord.app.improviser.NotoTUI","title":"<code>NotoTUI</code>","text":"<p>             Bases: <code>TUI</code></p> Source code in <code>src/notochord/app/improviser.py</code> <pre><code>class NotoTUI(TUI):\n    CSS_PATH = 'improviser.css'\n\n    BINDINGS = [\n        (\"m\", \"mute\", \"Mute Notochord\"),\n        (\"s\", \"sustain\", \"Mute without ending notes\"),\n        (\"q\", \"query\", \"Re-query Notochord\"),\n        (\"r\", \"reset\", \"Reset Notochord\")]\n\n    def compose(self):\n        \"\"\"Create child widgets for the app.\"\"\"\n        yield Header()\n        yield self.std_log\n        yield NotoLog(id='note')\n        yield NotoPrediction(id='prediction')\n        yield NotoControl()\n        yield Footer()\n</code></pre>"},{"location":"reference/notochord/app/improviser/#notochord.app.improviser.NotoTUI.compose","title":"<code>compose()</code>","text":"<p>Create child widgets for the app.</p> Source code in <code>src/notochord/app/improviser.py</code> <pre><code>def compose(self):\n    \"\"\"Create child widgets for the app.\"\"\"\n    yield Header()\n    yield self.std_log\n    yield NotoLog(id='note')\n    yield NotoPrediction(id='prediction')\n    yield NotoControl()\n    yield Footer()\n</code></pre>"},{"location":"reference/notochord/app/improviser/#notochord.app.improviser.main","title":"<code>main(checkpoint='notochord-latest.ckpt', player_config=None, noto_config=None, initial_mute=False, initial_query=False, midi_in=None, midi_out=None, thru=False, send_pc=False, dump_midi=False, balance_sample=False, n_recent=64, n_margin=8, max_note_len=5, max_time=None, nominal_time=False, osc_port=None, osc_host='', use_tui=True, predict_player=True, auto_query=True, testing=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>path to notochord model checkpoint.</p> <code>'notochord-latest.ckpt'</code> <code>player_config</code> <code>Dict[int, int]</code> <p>mapping from MIDI channels to MIDI instruments controlled by the player.</p> <code>None</code> <code>noto_config</code> <code>Dict[int, int]</code> <p>mapping from MIDI channels to MIDI instruments controlled by notochord. Both indexed from 1. instruments should be different from the player instruments. channels should be different unless different ports are used. MIDI channels and General MIDI instruments are indexed from 1.</p> <code>None</code> <code>initial_mute</code> <p>start Notochord muted so it won't play with input.</p> <code>False</code> <code>initial_query</code> <p>query Notochord immediately so it plays even without input.</p> <code>False</code> <code>midi_in</code> <code>Optional[str]</code> <p>MIDI ports for player input.  default is to use all input ports. can be comma-separated list of ports.</p> <code>None</code> <code>midi_out</code> <code>Optional[str]</code> <p>MIDI ports for Notochord output.  default is to use only virtual 'From iipyper' port. can be comma-separated list of ports.</p> <code>None</code> <code>thru</code> <p>if True, copy incoming MIDI to output ports. only makes sense if input and output ports are different.</p> <code>False</code> <code>send_pc</code> <p>if True, send MIDI program change messages to set the General MIDI instrument on each channel according to player_config and noto_config. useful when using a General MIDI synthesizer like fluidsynth.</p> <code>False</code> <code>dump_midi</code> <p>if True, print all incoming MIDI for debugging purposes</p> <code>False</code> <code>balance_sample</code> <p>choose instruments which have played less recently ensures that all configured instruments will play.</p> <code>False</code> <code>n_recent</code> <p>number of recent note-on events to consider for above</p> <code>64</code> <code>n_margin</code> <p>amount of 'slack' in the balance_sample calculation</p> <code>8</code> <code>max_note_len</code> <p>time in seconds after which to force-release sustained notochord notes.</p> <code>5</code> <code>max_time</code> <p>maximum time in seconds between predicted events. default is the Notochord model's maximum (usually 10 seconds).</p> <code>None</code> <code>nominal_time</code> <p>if True, feed Notochord with its own predicted times instead of the actual elapsed time. May make Notochord more likely to play chords.</p> <code>False</code> <code>osc_port</code> <p>optional. if supplied, listen for OSC to set controls</p> <code>None</code> <code>osc_host</code> <p>hostname or IP of OSC sender. leave this as empty string to get all traffic on the port</p> <code>''</code> <code>use_tui</code> <p>run textual UI.</p> <code>True</code> <code>predict_player</code> <p>forecasted next events can be for player. generally should be true, use balance_sample to force Notochord to play.</p> <code>True</code> Source code in <code>src/notochord/app/improviser.py</code> <pre><code>def main(\n    checkpoint=\"notochord-latest.ckpt\", # Notochord checkpoint\n    player_config:Dict[int,int]=None, # map MIDI channel : GM instrument\n    noto_config:Dict[int,int]=None, # map MIDI channel : GM instrument\n\n    initial_mute=False, # start with Notochord muted\n    initial_query=False, # let Notochord start playing immediately\n\n    midi_in:Optional[str]=None, # MIDI port for player input\n    midi_out:Optional[str]=None, # MIDI port for Notochord output\n    thru=False, # copy player input to output\n    send_pc=False, # send program change messages\n    dump_midi=False, # print all incoming MIDI\n\n    balance_sample=False, # choose instruments which have played less recently\n    n_recent=64, # number of recent note-on events to consider for above\n    n_margin=8, # amount of 'slack' in the balance_sample calculation\n\n    max_note_len=5, # in seconds, to auto-release stuck Notochord notes\n    max_time=None, # max time between events\n    nominal_time=False, #feed Notochord with nominal dt instead of actual\n\n    osc_port=None, # if supplied, listen for OSC to set controls on this port\n    osc_host='', # leave this as empty string to get all traffic on the port\n\n    use_tui=True, # run textual UI\n    predict_player=True, # forecasted next events can be for player (preserves model distribution, but can lead to Notochord deciding not to play)\n    auto_query=True, # query notochord whenever it is unmuted and there is no pending event. generally should be True except for testing purposes.\n    testing=False\n    ):\n    \"\"\"\n    Args:\n        checkpoint: path to notochord model checkpoint.\n\n        player_config: mapping from MIDI channels to MIDI instruments controlled\n            by the player.\n        noto_config: mapping from MIDI channels to MIDI instruments controlled\n            by notochord. Both indexed from 1.\n            instruments should be different from the player instruments.\n            channels should be different unless different ports are used.\n            MIDI channels and General MIDI instruments are indexed from 1.\n\n        initial_mute: start Notochord muted so it won't play with input.\n        initial_query: query Notochord immediately so it plays even without input.\n\n        midi_in: MIDI ports for player input. \n            default is to use all input ports.\n            can be comma-separated list of ports.\n        midi_out: MIDI ports for Notochord output. \n            default is to use only virtual 'From iipyper' port.\n            can be comma-separated list of ports.\n        thru: if True, copy incoming MIDI to output ports.\n            only makes sense if input and output ports are different.\n        send_pc: if True, send MIDI program change messages to set the General MIDI\n            instrument on each channel according to player_config and noto_config.\n            useful when using a General MIDI synthesizer like fluidsynth.\n        dump_midi: if True, print all incoming MIDI for debugging purposes\n\n        balance_sample: choose instruments which have played less recently\n            ensures that all configured instruments will play.\n        n_recent: number of recent note-on events to consider for above\n        n_margin: amount of 'slack' in the balance_sample calculation\n\n        max_note_len: time in seconds after which to force-release sustained\n            notochord notes.\n        max_time: maximum time in seconds between predicted events.\n            default is the Notochord model's maximum (usually 10 seconds).\n        nominal_time: if True, feed Notochord with its own predicted times\n            instead of the actual elapsed time.\n            May make Notochord more likely to play chords.\n\n        osc_port: optional. if supplied, listen for OSC to set controls\n        osc_host: hostname or IP of OSC sender.\n            leave this as empty string to get all traffic on the port\n\n        use_tui: run textual UI.\n        predict_player: forecasted next events can be for player.\n            generally should be true, use balance_sample to force Notochord to\n            play.\n        auto_query=True, # query notochord whenever it is unmuted and there is no pending event. generally should be True unless debugging.\n    \"\"\"\n    if osc_port is not None:\n        osc = OSC(osc_host, osc_port)\n    midi = MIDI(midi_in, midi_out)\n\n    ### Textual UI\n    tui = NotoTUI()\n    print = tui.print\n    ###\n\n    # default channel:instrument mappings\n    if player_config is None:\n        player_config = {1:1} # channel 1: grand piano\n    if noto_config is None:\n        noto_config = {2:257} # channel 2: anon\n\n    # convert 1-indexed MIDI channels to 0-indexed here\n    player_map = MIDIConfig({k-1:v for k,v in player_config.items()})\n    noto_map = MIDIConfig({k-1:v for k,v in noto_config.items()})\n\n    if len(player_map.insts &amp; noto_map.insts):\n        print(\"WARNING: Notochord and Player instruments shouldn't overlap\")\n        print('setting to an anonymous instrument')\n        # TODO: set to anon insts without changing mel/drum\n        # respecting anon insts selected for player\n        raise NotImplementedError\n    # TODO:\n    # check for repeated insts/channels\n\n    def warn_inst(i):\n        if i &gt; 128:\n            if i &lt; 257:\n                print(f\"WARNING: drum instrument {i} selected, be sure to select a drum bank in your synthesizer\")\n            else:\n                print(f\"WARNING: instrument {i} is not General MIDI\")\n\n    if send_pc:\n        for c,i in (player_map | noto_map).items():\n            warn_inst(i)\n            midi.program_change(channel=c, program=(i-1)%128)\n\n    # TODO: add arguments for this,\n    # and sensible defaults for drums etc\n    inst_pitch_map = {i: range(128) for i in noto_map.insts | player_map.insts}\n\n    # load notochord model\n    try:\n        noto = Notochord.from_checkpoint(checkpoint)\n        noto.eval()\n        noto.reset()\n    except Exception:\n        print(\"\"\"error loading notochord model\"\"\")\n        raise\n\n    # main stopwatch to track time difference between MIDI events\n    stopwatch = Stopwatch()\n\n    # simple class to hold pending event prediction\n    class Prediction:\n        def __init__(self):\n            self.event = None\n            self.gate = not initial_mute\n    pending = Prediction()\n\n    # query parameters controlled via MIDI / OSC\n    controls = {}\n\n    # tracks held notes, recently played instruments, etc\n    history = NotoPerformance()\n\n    def display_event(tag, memo, inst, pitch, vel, channel, **kw):\n        \"\"\"print an event to the terminal\"\"\"\n        if tag is None:\n            return\n        s = f'{tag}:\\t {inst=:4d}    {pitch=:4d}    {vel=:4d}    {channel=:3d}'\n        if memo is not None:\n            s += f'    ({memo})'\n        tui(note=s)\n\n    def play_event(event, channel, feed=True, send=True, tag=None, memo=None):\n        \"\"\"realize an event as MIDI, terminal display, and Notochord update\"\"\"\n        # normalize values\n        vel = event['vel'] = round(event['vel'])\n        dt = stopwatch.punch()\n        if 'time' not in event or not nominal_time:\n            event['time'] = dt\n\n        # send out as MIDI\n        if send:\n            midi.send(\n                'note_on' if vel &gt; 0 else 'note_off', \n                note=event['pitch'], velocity=vel, channel=channel)\n\n        # feed to NotoPerformance\n        # put a stopwatch in the held_note_data field for tracking note length\n        history.feed(held_note_data=Stopwatch(), channel=channel, **event)\n\n        # print\n        display_event(tag, memo=memo, channel=channel, **event)\n\n        # feed to Notochord\n        if feed:\n            noto.feed(**event)\n\n    # @lock\n    def noto_reset():\n        \"\"\"reset Notochord and end all of its held notes\"\"\"\n        print('RESET')\n\n        # cancel pending predictions\n        pending.event = None\n        tui(prediction=pending.event)\n\n        # end Notochord held notes\n        for (chan,inst,pitch) in history.note_triples:\n            if inst in noto_map.insts:\n                play_event(\n                    dict(inst=inst, pitch=pitch, vel=0),\n                    channel=chan, \n                    feed=False, # skip feeding Notochord since we are resetting it\n                    tag='NOTO', memo='reset')\n        # reset stopwatch\n        stopwatch.punch()\n        # reset notochord state\n        noto.reset()\n        # reset history\n        history.push()\n        # query the fresh notochord for a new prediction\n        if pending.gate:\n            noto_query()\n\n    # @lock\n    def noto_mute(sustain=False):\n        tui.query_one('#mute').label = 'UNMUTE' if pending.gate else 'MUTE'\n        # if sustain:\n        tui.query_one('#sustain').label = 'END SUSTAIN' if pending.gate else 'SUSTAIN'\n\n        pending.gate = not pending.gate\n\n        if sustain:\n            print('END SUSTAIN' if pending.gate else 'SUSTAIN')\n        else:\n            print('UNMUTE' if pending.gate else 'MUTE')\n        # if unmuting, we're done\n        if pending.gate:\n            if sustain:\n                noto_query()\n            return\n        # cancel pending predictions\n        pending.event = None\n        tui(prediction=pending.event)\n\n        if sustain:\n            return\n\n        # end+feed all held notes\n        for (chan,inst,pitch) in history.note_triples:\n            if chan in noto_map:\n                play_event(\n                    dict(inst=inst, pitch=pitch, vel=0), \n                    channel=chan, tag='NOTO', memo='mute')\n\n    # query Notochord for a new next event\n    # @lock\n    def noto_query():\n        # check for stuck notes\n        # and prioritize ending those\n        for (_, inst, pitch), sw in history.note_data.items():\n            if (\n                inst in noto_map.insts \n                and sw.read() &gt; max_note_len*(.1+controls.get('steer_duration', 1))\n                ):\n                # query for the end of a note with flexible timing\n                # with profile('query', print=print):\n                t = stopwatch.read()\n                pending.event = noto.query(\n                    next_inst=inst, next_pitch=pitch,\n                    next_vel=0, min_time=t, max_time=t+0.5)\n                print(f'END STUCK NOTE {inst=},{pitch=}')\n                return\n\n        counts = history.inst_counts(\n            n=n_recent, insts=noto_map.insts | player_map.insts)\n        print(counts)\n\n        all_insts = noto_map.insts \n        if predict_player:\n            all_insts = all_insts | player_map.insts\n\n        held_notes = history.held_inst_pitch_map(all_insts)\n\n        steer_time = 1-controls.get('steer_rate', 0.5)\n        steer_pitch = controls.get('steer_pitch', 0.5)\n        steer_density = controls.get('steer_density', 0.5)\n\n        tqt = (max(0,steer_time-0.5), min(1, steer_time+0.5))\n        tqp = (max(0,steer_pitch-0.5), min(1, steer_pitch+0.5))\n\n        # if using nominal time,\n        # *subtract* estimated feed latency to min_time; (TODO: really should\n        #   set no min time when querying, use stopwatch when re-querying...)\n        # if using actual time, *add* estimated query latency\n        time_offset = -5e-3 if nominal_time else 10e-3\n        min_time = stopwatch.read()+time_offset\n\n        # balance_sample: note-ons only from instruments which have played less\n        bal_insts = set(counts.index[counts &lt;= counts.min()+n_margin])\n        if balance_sample and len(bal_insts)&gt;0:\n            insts = bal_insts\n        else:\n            insts = all_insts\n\n        # VTIP is better for time interventions,\n        # VIPT is better for instrument interventions\n        # could decide probabilistically based on value of controls + insts...\n        if insts==all_insts:\n            query_method = noto.query_vtip\n        else:\n            query_method = noto.query_vipt\n\n        # print(f'considering {insts} for note_on')\n        # use only currently selected instruments\n        note_on_map = {\n            i: set(inst_pitch_map[i])-set(held_notes[i]) # exclude held notes\n            for i in insts\n        }\n        # use any instruments which are currently holding notes\n        note_off_map = {\n            i: set(ps)&amp;set(held_notes[i]) # only held notes\n            for i,ps in inst_pitch_map.items()\n        }\n\n        max_t = None if max_time is None else max(max_time, min_time+0.2)\n\n        pending.event = query_method(\n            note_on_map, note_off_map,\n            min_time=min_time, max_time=max_t,\n            truncate_quantile_time=tqt,\n            truncate_quantile_pitch=tqp,\n            steer_density=steer_density,\n        )\n\n        # display the predicted event\n        tui(prediction=pending.event)\n\n    #### MIDI handling\n\n    # print all incoming MIDI for debugging\n    if dump_midi:\n        @midi.handle\n        def _(msg):\n            print(msg)\n\n    @midi.handle(type='program_change')\n    def _(msg):\n        \"\"\"Program change events set instruments\"\"\"\n        if msg.channel in player_map:\n            player_map[msg.channel] = msg.program\n        if msg.channel in noto_map:\n            noto_map[msg.channel] = msg.program\n\n    @midi.handle(type='pitchwheel')\n    def _(msg):\n        controls['steer_pitch'] = (msg.pitch+8192)/16384\n        # print(controls)\n\n    # very basic CC handling for controls\n    @midi.handle(type='control_change')\n    def _(msg):\n        \"\"\"CC messages on any channel\"\"\"\n\n        if msg.control==1:\n            controls['steer_pitch'] = msg.value/127\n            print(f\"{controls['steer_pitch']=}\")\n        if msg.control==2:\n            controls['steer_density'] = msg.value/127\n            print(f\"{controls['steer_density']=}\")\n        if msg.control==3:\n            controls['steer_rate'] = msg.value/127\n            print(f\"{controls['steer_rate']=}\")\n\n        if msg.control==4:\n            noto_reset()\n        if msg.control==5:\n            noto_query()\n        if msg.control==6:\n            noto_mute()\n\n    # very basic OSC handling for controls\n    if osc_port is not None:\n        @osc.args('/notochord/improviser/*')\n        def _(route, *a):\n            print('OSC:', route, *a)\n            ctrl = route.split['/'][3]\n            if ctrl=='reset':\n                noto_reset()\n            elif ctrl=='query':\n                noto_query()\n            elif ctrl=='mute':\n                noto_mute()\n            else:\n                assert len(a)==0\n                arg = a[0]\n                assert isinstance(arg, Number)\n                controls[ctrl] = arg\n                print(controls)\n\n    @midi.handle(type=('note_on', 'note_off'))\n    def _(msg):\n        \"\"\"MIDI NoteOn events from the player\"\"\"\n        # if thru and msg.channel not in noto_map.channels:\n            # midi.send(msg)\n\n        if msg.channel not in player_map.channels:\n            return\n\n        inst = player_map[msg.channel]\n        pitch = msg.note\n        vel = msg.velocity if msg.type=='note_on' else 0\n\n        # feed event to Notochord\n        # with profile('feed', print=print):\n        play_event(\n            {'inst':inst, 'pitch':pitch, 'vel':vel}, \n            channel=msg.channel, send=thru, tag='PLAYER')\n\n        # query for new prediction\n        noto_query()\n\n        # send a MIDI reply for latency testing purposes:\n        # if testing: midi.cc(control=3, value=msg.note, channel=15)\n\n    def noto_event():\n        # notochord event happens:\n        event = pending.event\n        inst, pitch, vel = event['inst'], event['pitch'], round(event['vel'])\n\n        # note on which is already playing or note off which is not\n        if (vel&gt;0) == ((inst, pitch) in history.note_pairs): \n            print(f're-query for invalid {vel=}, {inst=}, {pitch=}')\n            noto_query()\n            return\n\n        chan = noto_map.inv(inst)\n        play_event(event, channel=chan, tag='NOTO')\n\n    @repeat(1e-3, lock=True)\n    def _():\n        \"\"\"Loop, checking if predicted next event happens\"\"\"\n        # check if current prediction has passed\n        if (\n            not testing and\n            pending.gate and\n            pending.event is not None and\n            stopwatch.read() &gt; pending.event['time']\n            ):\n            # if so, check if it is a notochord-controlled instrument\n            if pending.event['inst'] in noto_map.insts:\n                # prediction happens\n                noto_event()\n            # query for new prediction\n            if auto_query:\n                noto_query()\n\n    @cleanup\n    def _():\n        \"\"\"end any remaining notes\"\"\"\n        # print(f'cleanup: {notes=}')\n        for (chan,inst,pitch) in history.note_triples:\n        # for (inst,pitch) in notes:\n            if inst in noto_map.insts:\n                midi.note_on(note=pitch, velocity=0, channel=chan)\n\n    @tui.set_action\n    def mute():\n        noto_mute()\n\n    @tui.set_action\n    def sustain():\n        noto_mute(sustain=True)\n\n    @tui.set_action\n    def reset():\n        noto_reset()\n\n    @tui.set_action\n    def query():\n        noto_query()\n\n    if initial_query:\n        noto_query()\n\n    if use_tui:\n        tui.run()\n</code></pre>"},{"location":"reference/notochord/app/server/","title":"Server","text":"Authors <p>Victor Shepardson Jack Armitage Intelligent Instruments Lab 2022</p>"},{"location":"reference/notochord/app/simple_harmonizer/","title":"Simple harmonizer","text":"<p>Notochord MIDI harmonizer server. Each note from the player produces a harmonizing note from Notochord.</p> Authors <p>Victor Shepardson Intelligent Instruments Lab 2023</p>"}]}